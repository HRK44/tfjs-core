{"dependencies":[{"name":"/usr/local/google/home/nsthorat/deeplearnjs-clients/float16/tfjs-core/test/package.json","includedInParent":true,"mtime":1528810356568},{"name":"/usr/local/google/home/nsthorat/deeplearnjs-clients/float16/tfjs-core/test/.babelrc","includedInParent":true,"mtime":1525096773813},{"name":"/usr/local/google/home/nsthorat/deeplearnjs-clients/float16/tfjs-core/tsconfig.json","includedInParent":true,"mtime":1528810356568},{"name":"../ops/array_ops","loc":{"line":38,"column":26}},{"name":"../util","loc":{"line":39,"column":21}},{"name":"./types","loc":{"line":40,"column":22}}],"generated":{"js":"\"use strict\";\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = y[op[0] & 2 ? \"return\" : op[0] ? \"throw\" : \"next\"]) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [0, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar array_ops_1 = require(\"../ops/array_ops\");\nvar util_1 = require(\"../util\");\nvar types_1 = require(\"./types\");\nfunction encodeWeights(tensors) {\n    return __awaiter(this, void 0, void 0, function () {\n        var specs, dataPromises, name, t, tensorValues;\n        return __generator(this, function (_a) {\n            switch (_a.label) {\n                case 0:\n                    specs = [];\n                    dataPromises = [];\n                    for (name in tensors) {\n                        t = tensors[name];\n                        if (t.dtype !== 'float32' && t.dtype !== 'int32' && t.dtype !== 'bool') {\n                            throw new Error(\"Unsupported dtype in weight '\" + name + \"': \" + t.dtype);\n                        }\n                        specs.push({ name: name, shape: t.shape, dtype: t.dtype });\n                        dataPromises.push(t.data());\n                    }\n                    return [4, Promise.all(dataPromises)];\n                case 1:\n                    tensorValues = _a.sent();\n                    return [2, { data: concatenateTypedArrays(tensorValues), specs: specs }];\n            }\n        });\n    });\n}\nexports.encodeWeights = encodeWeights;\nfunction decodeWeights(buffer, specs) {\n    var out = {};\n    var offset = 0;\n    for (var _i = 0, specs_1 = specs; _i < specs_1.length; _i++) {\n        var spec = specs_1[_i];\n        var name = spec.name;\n        var dtype = spec.dtype;\n        var shape = spec.shape;\n        if (spec.quantization != null) {\n            throw new Error(\"decodeWeights does not support quantization yet, but encountered \" +\n                (\"weight '\" + name + \" with quantization.'\"));\n        }\n        var size = util_1.sizeFromShape(shape);\n        var value = void 0;\n        if (dtype === 'float32') {\n            value = array_ops_1.ArrayOps.tensor(new Float32Array(buffer, offset, size), shape, 'float32');\n        }\n        else if (dtype === 'int32') {\n            value =\n                array_ops_1.ArrayOps.tensor(new Int32Array(buffer, offset, size), shape, 'int32');\n        }\n        else if (dtype === 'bool') {\n            value =\n                array_ops_1.ArrayOps.tensor(new Uint8Array(buffer, offset, size), shape, 'bool');\n        }\n        else {\n            throw new Error(\"Unsupported dtype in weight '\" + name + \"': \" + dtype);\n        }\n        out[name] = value;\n        offset += size * types_1.DTYPE_VALUE_SIZE_MAP[dtype];\n    }\n    return out;\n}\nexports.decodeWeights = decodeWeights;\nfunction concatenateTypedArrays(xs) {\n    if (xs === null) {\n        throw new Error(\"Invalid input value: \" + JSON.stringify(xs));\n    }\n    var totalByteLength = 0;\n    xs.forEach(function (x) {\n        if (x instanceof Float32Array || x instanceof Int32Array) {\n            totalByteLength += x.length * 4;\n        }\n        else if (x instanceof Uint8Array) {\n            totalByteLength += x.length;\n        }\n        else {\n            throw new Error(\"Unsupported TypedArray subtype: \" + x.constructor.name);\n        }\n    });\n    var y = new Uint8Array(totalByteLength);\n    var offset = 0;\n    xs.forEach(function (x) {\n        y.set(new Uint8Array(x.buffer), offset);\n        if (x instanceof Float32Array || x instanceof Int32Array) {\n            offset += x.length * 4;\n        }\n        else {\n            offset += x.length;\n        }\n    });\n    return y.buffer;\n}\nexports.concatenateTypedArrays = concatenateTypedArrays;\nfunction stringByteLength(str) {\n    return new Blob([str]).size;\n}\nexports.stringByteLength = stringByteLength;\nfunction arrayBufferToBase64String(buffer) {\n    return btoa(String.fromCharCode.apply(null, new Uint8Array(buffer)));\n}\nexports.arrayBufferToBase64String = arrayBufferToBase64String;\nfunction base64StringToArrayBuffer(str) {\n    var s = atob(str);\n    var buffer = new Uint8Array(s.length);\n    for (var i = 0; i < s.length; ++i) {\n        buffer.set([s.charCodeAt(i)], i);\n    }\n    return buffer.buffer;\n}\nexports.base64StringToArrayBuffer = base64StringToArrayBuffer;\nfunction concatenateArrayBuffers(buffers) {\n    var totalByteLength = 0;\n    buffers.forEach(function (buffer) {\n        totalByteLength += buffer.byteLength;\n    });\n    var temp = new Uint8Array(totalByteLength);\n    var offset = 0;\n    buffers.forEach(function (buffer) {\n        temp.set(new Uint8Array(buffer), offset);\n        offset += buffer.byteLength;\n    });\n    return temp.buffer;\n}\nexports.concatenateArrayBuffers = concatenateArrayBuffers;\nfunction basename(path) {\n    var SEPARATOR = '/';\n    path = path.trim();\n    while (path.endsWith(SEPARATOR)) {\n        path = path.slice(0, path.length - 1);\n    }\n    var items = path.split(SEPARATOR);\n    return items[items.length - 1];\n}\nexports.basename = basename;\nfunction getModelArtifactsInfoForJSON(modelArtifacts) {\n    if (modelArtifacts.modelTopology instanceof ArrayBuffer) {\n        throw new Error('Expected JSON model topology, received ArrayBuffer.');\n    }\n    return {\n        dateSaved: new Date(),\n        modelTopologyType: 'JSON',\n        modelTopologyBytes: modelArtifacts.modelTopology == null ?\n            0 :\n            stringByteLength(JSON.stringify(modelArtifacts.modelTopology)),\n        weightSpecsBytes: modelArtifacts.weightSpecs == null ?\n            0 :\n            stringByteLength(JSON.stringify(modelArtifacts.weightSpecs)),\n        weightDataBytes: modelArtifacts.weightData == null ?\n            0 :\n            modelArtifacts.weightData.byteLength,\n    };\n}\nexports.getModelArtifactsInfoForJSON = getModelArtifactsInfoForJSON;\n","map":{"version":3,"file":"io_utils.js","sourceRoot":"","sources":["../src/io/io_utils.ts"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAiBA,8CAA0C;AAG1C,gCAAsC;AAGtC,iCAAuG;AAkBvG,uBAAoC,OAAuB;;;;;;oBAGnD,KAAK,GAA2B,EAAE,CAAC;oBACnC,YAAY,GAA+B,EAAE,CAAC;oBACpD,GAAG,CAAC,CAAO,IAAI,IAAI,OAAO,CAAC,CAAC,CAAC;wBACrB,CAAC,GAAG,OAAO,CAAC,IAAI,CAAC,CAAC;wBAExB,EAAE,CAAC,CAAC,CAAC,CAAC,KAAK,KAAK,SAAS,IAAI,CAAC,CAAC,KAAK,KAAK,OAAO,IAAI,CAAC,CAAC,KAAK,KAAK,MAAM,CAAC,CAAC,CAAC;4BACvE,MAAM,IAAI,KAAK,CAAC,kCAAgC,IAAI,WAAM,CAAC,CAAC,KAAO,CAAC,CAAC;wBACvE,CAAC;wBACD,KAAK,CAAC,IAAI,CAAC,EAAC,IAAI,MAAA,EAAE,KAAK,EAAE,CAAC,CAAC,KAAK,EAAE,KAAK,EAAE,CAAC,CAAC,KAAK,EAAC,CAAC,CAAC;wBACnD,YAAY,CAAC,IAAI,CAAC,CAAC,CAAC,IAAI,EAAE,CAAC,CAAC;oBAC9B,CAAC;oBACoB,WAAM,OAAO,CAAC,GAAG,CAAC,YAAY,CAAC,EAAA;;oBAA9C,YAAY,GAAG,SAA+B;oBACpD,WAAO,EAAC,IAAI,EAAE,sBAAsB,CAAC,YAAY,CAAC,EAAE,KAAK,OAAA,EAAC,EAAC;;;;CAC5D;AAhBD,sCAgBC;AAiBD,uBACI,MAAmB,EAAE,KAA6B;IAEpD,IAAM,GAAG,GAAmB,EAAE,CAAC;IAC/B,IAAI,MAAM,GAAG,CAAC,CAAC;IACf,GAAG,CAAC,CAAe,UAAK,EAAL,eAAK,EAAL,mBAAK,EAAL,IAAK;QAAnB,IAAM,IAAI,cAAA;QACb,IAAM,IAAI,GAAG,IAAI,CAAC,IAAI,CAAC;QACvB,IAAM,KAAK,GAAG,IAAI,CAAC,KAAK,CAAC;QACzB,IAAM,KAAK,GAAG,IAAI,CAAC,KAAK,CAAC;QAEzB,EAAE,CAAC,CAAC,IAAI,CAAC,YAAY,IAAI,IAAI,CAAC,CAAC,CAAC;YAC9B,MAAM,IAAI,KAAK,CACX,mEAAmE;iBACnE,aAAW,IAAI,yBAAsB,CAAA,CAAC,CAAC;QAC7C,CAAC;QAED,IAAM,IAAI,GAAG,oBAAa,CAAC,KAAK,CAAC,CAAC;QAClC,IAAI,KAAK,SAAQ,CAAC;QAClB,EAAE,CAAC,CAAC,KAAK,KAAK,SAAS,CAAC,CAAC,CAAC;YACxB,KAAK,GAAG,oBAAQ,CAAC,MAAM,CACnB,IAAI,YAAY,CAAC,MAAM,EAAE,MAAM,EAAE,IAAI,CAAC,EAAE,KAAK,EAAE,SAAS,CAAC,CAAC;QAChE,CAAC;QAAC,IAAI,CAAC,EAAE,CAAC,CAAC,KAAK,KAAK,OAAO,CAAC,CAAC,CAAC;YAC7B,KAAK;gBACD,oBAAQ,CAAC,MAAM,CAAC,IAAI,UAAU,CAAC,MAAM,EAAE,MAAM,EAAE,IAAI,CAAC,EAAE,KAAK,EAAE,OAAO,CAAC,CAAC;QAC5E,CAAC;QAAC,IAAI,CAAC,EAAE,CAAC,CAAC,KAAK,KAAK,MAAM,CAAC,CAAC,CAAC;YAC5B,KAAK;gBACD,oBAAQ,CAAC,MAAM,CAAC,IAAI,UAAU,CAAC,MAAM,EAAE,MAAM,EAAE,IAAI,CAAC,EAAE,KAAK,EAAE,MAAM,CAAC,CAAC;QAC3E,CAAC;QAAC,IAAI,CAAC,CAAC;YACN,MAAM,IAAI,KAAK,CAAC,kCAAgC,IAAI,WAAM,KAAO,CAAC,CAAC;QACrE,CAAC;QACD,GAAG,CAAC,IAAI,CAAC,GAAG,KAAK,CAAC;QAElB,MAAM,IAAI,IAAI,GAAG,4BAAoB,CAAC,KAAK,CAAC,CAAC;KAC9C;IACD,MAAM,CAAC,GAAG,CAAC;AACb,CAAC;AAnCD,sCAmCC;AAKD,gCAAuC,EAAgB;IAErD,EAAE,CAAC,CAAC,EAAE,KAAK,IAAI,CAAC,CAAC,CAAC;QAChB,MAAM,IAAI,KAAK,CAAC,0BAAwB,IAAI,CAAC,SAAS,CAAC,EAAE,CAAG,CAAC,CAAC;IAChE,CAAC;IAED,IAAI,eAAe,GAAG,CAAC,CAAC;IACxB,EAAE,CAAC,OAAO,CAAC,UAAA,CAAC;QAEV,EAAE,CAAC,CAAC,CAAQ,YAAY,YAAY,IAAI,CAAQ,YAAY,UAAU,CAAC,CAAC,CAAC;YACvE,eAAe,IAAI,CAAC,CAAC,MAAM,GAAG,CAAC,CAAC;QAElC,CAAC;QAAC,IAAI,CAAC,EAAE,CAAC,CAAC,CAAQ,YAAY,UAAU,CAAC,CAAC,CAAC;YAC1C,eAAe,IAAI,CAAC,CAAC,MAAM,CAAC;QAC9B,CAAC;QAAC,IAAI,CAAC,CAAC;YACN,MAAM,IAAI,KAAK,CAAC,qCAAmC,CAAC,CAAC,WAAW,CAAC,IAAM,CAAC,CAAC;QAC3E,CAAC;IACH,CAAC,CAAC,CAAC;IAEH,IAAM,CAAC,GAAG,IAAI,UAAU,CAAC,eAAe,CAAC,CAAC;IAC1C,IAAI,MAAM,GAAG,CAAC,CAAC;IACf,EAAE,CAAC,OAAO,CAAC,UAAA,CAAC;QACV,CAAC,CAAC,GAAG,CAAC,IAAI,UAAU,CAAC,CAAC,CAAC,MAAM,CAAC,EAAE,MAAM,CAAC,CAAC;QACxC,EAAE,CAAC,CAAC,CAAC,YAAY,YAAY,IAAI,CAAC,YAAY,UAAU,CAAC,CAAC,CAAC;YACzD,MAAM,IAAI,CAAC,CAAC,MAAM,GAAG,CAAC,CAAC;QACzB,CAAC;QAAC,IAAI,CAAC,CAAC;YACN,MAAM,IAAI,CAAC,CAAC,MAAM,CAAC;QACrB,CAAC;IACH,CAAC,CAAC,CAAC;IAEH,MAAM,CAAC,CAAC,CAAC,MAAM,CAAC;AAClB,CAAC;AA/BD,wDA+BC;AAWD,0BAAiC,GAAW;IAC1C,MAAM,CAAC,IAAI,IAAI,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,IAAI,CAAC;AAC9B,CAAC;AAFD,4CAEC;AAQD,mCAA0C,MAAmB;IAC3D,MAAM,CAAC,IAAI,CAAC,MAAM,CAAC,YAAY,CAAC,KAAK,CAAC,IAAI,EAAE,IAAI,UAAU,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC;AACvE,CAAC;AAFD,8DAEC;AAQD,mCAA0C,GAAW;IACnD,IAAM,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC;IACpB,IAAM,MAAM,GAAG,IAAI,UAAU,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC;IACxC,GAAG,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,CAAC,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE,CAAC;QAClC,MAAM,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;IACnC,CAAC;IACD,MAAM,CAAC,MAAM,CAAC,MAAM,CAAC;AACvB,CAAC;AAPD,8DAOC;AAQD,iCAAwC,OAAsB;IAC5D,IAAI,eAAe,GAAG,CAAC,CAAC;IACxB,OAAO,CAAC,OAAO,CAAC,UAAA,MAAM;QACpB,eAAe,IAAI,MAAM,CAAC,UAAU,CAAC;IACvC,CAAC,CAAC,CAAC;IAEH,IAAM,IAAI,GAAG,IAAI,UAAU,CAAC,eAAe,CAAC,CAAC;IAC7C,IAAI,MAAM,GAAG,CAAC,CAAC;IACf,OAAO,CAAC,OAAO,CAAC,UAAA,MAAM;QACpB,IAAI,CAAC,GAAG,CAAC,IAAI,UAAU,CAAC,MAAM,CAAC,EAAE,MAAM,CAAC,CAAC;QACzC,MAAM,IAAI,MAAM,CAAC,UAAU,CAAC;IAC9B,CAAC,CAAC,CAAC;IACH,MAAM,CAAC,IAAI,CAAC,MAAM,CAAC;AACrB,CAAC;AAbD,0DAaC;AASD,kBAAyB,IAAY;IACnC,IAAM,SAAS,GAAG,GAAG,CAAC;IACtB,IAAI,GAAG,IAAI,CAAC,IAAI,EAAE,CAAC;IACnB,OAAO,IAAI,CAAC,QAAQ,CAAC,SAAS,CAAC,EAAE,CAAC;QAChC,IAAI,GAAG,IAAI,CAAC,KAAK,CAAC,CAAC,EAAE,IAAI,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC;IACxC,CAAC;IACD,IAAM,KAAK,GAAG,IAAI,CAAC,KAAK,CAAC,SAAS,CAAC,CAAC;IACpC,MAAM,CAAC,KAAK,CAAC,KAAK,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC;AACjC,CAAC;AARD,4BAQC;AAOD,sCAA6C,cAA8B;IAEzE,EAAE,CAAC,CAAC,cAAc,CAAC,aAAa,YAAY,WAAW,CAAC,CAAC,CAAC;QACxD,MAAM,IAAI,KAAK,CAAC,qDAAqD,CAAC,CAAC;IACzE,CAAC;IAED,MAAM,CAAC;QACL,SAAS,EAAE,IAAI,IAAI,EAAE;QACrB,iBAAiB,EAAE,MAAM;QACzB,kBAAkB,EAAE,cAAc,CAAC,aAAa,IAAI,IAAI,CAAC,CAAC;YACtD,CAAC,CAAC,CAAC;YACH,gBAAgB,CAAC,IAAI,CAAC,SAAS,CAAC,cAAc,CAAC,aAAa,CAAC,CAAC;QAClE,gBAAgB,EAAE,cAAc,CAAC,WAAW,IAAI,IAAI,CAAC,CAAC;YAClD,CAAC,CAAC,CAAC;YACH,gBAAgB,CAAC,IAAI,CAAC,SAAS,CAAC,cAAc,CAAC,WAAW,CAAC,CAAC;QAChE,eAAe,EAAE,cAAc,CAAC,UAAU,IAAI,IAAI,CAAC,CAAC;YAChD,CAAC,CAAC,CAAC;YACH,cAAc,CAAC,UAAU,CAAC,UAAU;KACzC,CAAC;AACJ,CAAC;AAnBD,oEAmBC","sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ArrayOps} from '../ops/array_ops';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap, TypedArray} from '../types';\nimport {sizeFromShape} from '../util';\n\n// tslint:disable-next-line:max-line-length\nimport {DTYPE_VALUE_SIZE_MAP, ModelArtifacts, ModelArtifactsInfo, WeightsManifestEntry} from './types';\n\n/**\n * Encode a map from names to weight values as an ArrayBuffer, along with an\n * `Array` of `WeightsManifestEntry` as specification of the encoded weights.\n *\n * This function does not perform sharding.\n *\n * This function is the reverse of `decodeWeights`.\n *\n * @param tensors A map (\"dict\") from names to tensors.\n * @returns A `Promise` of\n *   - A flat `ArrayBuffer` with all the binary values of the `Tensor`s\n *     concatenated.\n *   - An `Array` of `WeightManifestEntry`s, carrying information including\n *     tensor names, `dtype`s and shapes.\n * @throws Error: on unsupported tensor `dtype`.\n */\nexport async function encodeWeights(tensors: NamedTensorMap):\n    Promise<{data: ArrayBuffer, specs: WeightsManifestEntry[]}> {\n  // TODO(adarob, cais): Support quantization.\n  const specs: WeightsManifestEntry[] = [];\n  const dataPromises: Array<Promise<TypedArray>> = [];\n  for (const name in tensors) {\n    const t = tensors[name];\n\n    if (t.dtype !== 'float32' && t.dtype !== 'int32' && t.dtype !== 'bool') {\n      throw new Error(`Unsupported dtype in weight '${name}': ${t.dtype}`);\n    }\n    specs.push({name, shape: t.shape, dtype: t.dtype});\n    dataPromises.push(t.data());\n  }\n  const tensorValues = await Promise.all(dataPromises);\n  return {data: concatenateTypedArrays(tensorValues), specs};\n}\n\n/**\n * Decode flat ArrayBuffer as weights.\n *\n * This function does not handle sharding.\n *\n * This function is the reverse of `encodeWeights`.\n *\n * @param buffer A flat ArrayBuffer carrying the binary values of the tensors\n *   concatenated in the order specified in `specs`.\n * @param specs Specifications of the names, dtypes and shapes of the tensors\n *   whose value are encoded by `buffer`.\n * @return A map from tensor name to tensor value, with the names corresponding\n *   to names in `specs`.\n * @throws Error, if any of the tensors has unsupported dtype.\n */\nexport function decodeWeights(\n    buffer: ArrayBuffer, specs: WeightsManifestEntry[]): NamedTensorMap {\n  // TODO(adarob, cais): Support quantization.\n  const out: NamedTensorMap = {};\n  let offset = 0;\n  for (const spec of specs) {\n    const name = spec.name;\n    const dtype = spec.dtype;\n    const shape = spec.shape;\n\n    if (spec.quantization != null) {\n      throw new Error(\n          `decodeWeights does not support quantization yet, but encountered ` +\n          `weight '${name} with quantization.'`);\n    }\n\n    const size = sizeFromShape(shape);\n    let value: Tensor;\n    if (dtype === 'float32') {\n      value = ArrayOps.tensor(\n          new Float32Array(buffer, offset, size), shape, 'float32');\n    } else if (dtype === 'int32') {\n      value =\n          ArrayOps.tensor(new Int32Array(buffer, offset, size), shape, 'int32');\n    } else if (dtype === 'bool') {\n      value =\n          ArrayOps.tensor(new Uint8Array(buffer, offset, size), shape, 'bool');\n    } else {\n      throw new Error(`Unsupported dtype in weight '${name}': ${dtype}`);\n    }\n    out[name] = value;\n\n    offset += size * DTYPE_VALUE_SIZE_MAP[dtype];\n  }\n  return out;\n}\n\n/**\n * Concatenate TypedArrays into an ArrayBuffer.\n */\nexport function concatenateTypedArrays(xs: TypedArray[]): ArrayBuffer {\n  // TODO(adarob, cais): Support quantization.\n  if (xs === null) {\n    throw new Error(`Invalid input value: ${JSON.stringify(xs)}`);\n  }\n\n  let totalByteLength = 0;\n  xs.forEach(x => {\n    // tslint:disable-next-line:no-any\n    if (x as any instanceof Float32Array || x as any instanceof Int32Array) {\n      totalByteLength += x.length * 4;\n      // tslint:disable-next-line:no-any\n    } else if (x as any instanceof Uint8Array) {\n      totalByteLength += x.length;\n    } else {\n      throw new Error(`Unsupported TypedArray subtype: ${x.constructor.name}`);\n    }\n  });\n\n  const y = new Uint8Array(totalByteLength);\n  let offset = 0;\n  xs.forEach(x => {\n    y.set(new Uint8Array(x.buffer), offset);\n    if (x instanceof Float32Array || x instanceof Int32Array) {\n      offset += x.length * 4;\n    } else {\n      offset += x.length;\n    }\n  });\n\n  return y.buffer;\n}\n\n/**\n * Calculate the byte length of a JavaScript string.\n *\n * Note that a JavaScript string can contain wide characters, therefore the\n * length of the string is not necessarily equal to the byte length.\n *\n * @param str Input string.\n * @returns Byte length.\n */\nexport function stringByteLength(str: string): number {\n  return new Blob([str]).size;\n}\n\n/**\n * Encode an ArrayBuffer as a base64 encoded string.\n *\n * @param buffer `ArrayBuffer` to be converted.\n * @returns A string that base64-encodes `buffer`.\n */\nexport function arrayBufferToBase64String(buffer: ArrayBuffer): string {\n  return btoa(String.fromCharCode.apply(null, new Uint8Array(buffer)));\n}\n\n/**\n * Decode a base64 string as an ArrayBuffer.\n *\n * @param str Base64 string.\n * @returns Decoded `ArrayBuffer`.\n */\nexport function base64StringToArrayBuffer(str: string): ArrayBuffer {\n  const s = atob(str);\n  const buffer = new Uint8Array(s.length);\n  for (let i = 0; i < s.length; ++i) {\n    buffer.set([s.charCodeAt(i)], i);\n  }\n  return buffer.buffer;\n}\n\n/**\n * Concatenate a number of ArrayBuffers into one.\n *\n * @param buffers A number of array buffers to concatenate.\n * @returns Result of concatenating `buffers` in order.\n */\nexport function concatenateArrayBuffers(buffers: ArrayBuffer[]): ArrayBuffer {\n  let totalByteLength = 0;\n  buffers.forEach(buffer => {\n    totalByteLength += buffer.byteLength;\n  });\n\n  const temp = new Uint8Array(totalByteLength);\n  let offset = 0;\n  buffers.forEach(buffer => {\n    temp.set(new Uint8Array(buffer), offset);\n    offset += buffer.byteLength;\n  });\n  return temp.buffer;\n}\n\n/**\n * Get the basename of a path.\n *\n * Behaves in a way analogous to Linux's basename command.\n *\n * @param path\n */\nexport function basename(path: string): string {\n  const SEPARATOR = '/';\n  path = path.trim();\n  while (path.endsWith(SEPARATOR)) {\n    path = path.slice(0, path.length - 1);\n  }\n  const items = path.split(SEPARATOR);\n  return items[items.length - 1];\n}\n\n/**\n * Populate ModelArtifactsInfo fields for a model with JSON topology.\n * @param modelArtifacts\n * @returns A ModelArtifactsInfo object.\n */\nexport function getModelArtifactsInfoForJSON(modelArtifacts: ModelArtifacts):\n    ModelArtifactsInfo {\n  if (modelArtifacts.modelTopology instanceof ArrayBuffer) {\n    throw new Error('Expected JSON model topology, received ArrayBuffer.');\n  }\n\n  return {\n    dateSaved: new Date(),\n    modelTopologyType: 'JSON',\n    modelTopologyBytes: modelArtifacts.modelTopology == null ?\n        0 :\n        stringByteLength(JSON.stringify(modelArtifacts.modelTopology)),\n    weightSpecsBytes: modelArtifacts.weightSpecs == null ?\n        0 :\n        stringByteLength(JSON.stringify(modelArtifacts.weightSpecs)),\n    weightDataBytes: modelArtifacts.weightData == null ?\n        0 :\n        modelArtifacts.weightData.byteLength,\n  };\n}\n"]}},"hash":"98bb57ae3b080470c5d4b3b4870333ef","cacheData":{"env":{}}}