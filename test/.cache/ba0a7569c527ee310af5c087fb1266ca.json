{"dependencies":[{"name":"/usr/local/google/home/nsthorat/deeplearnjs-clients/float16/tfjs-core/test/package.json","includedInParent":true,"mtime":1528810356568},{"name":"/usr/local/google/home/nsthorat/deeplearnjs-clients/float16/tfjs-core/test/.babelrc","includedInParent":true,"mtime":1525096773813},{"name":"/usr/local/google/home/nsthorat/deeplearnjs-clients/float16/tfjs-core/tsconfig.json","includedInParent":true,"mtime":1528810356568},{"name":"./optimizers/adadelta_optimizer","loc":{"line":3,"column":35}},{"name":"./optimizers/adagrad_optimizer","loc":{"line":4,"column":34}},{"name":"./optimizers/adam_optimizer","loc":{"line":5,"column":31}},{"name":"./optimizers/adamax_optimizer","loc":{"line":6,"column":33}},{"name":"./optimizers/momentum_optimizer","loc":{"line":7,"column":35}},{"name":"./optimizers/optimizer_constructors","loc":{"line":8,"column":39}},{"name":"./optimizers/rmsprop_optimizer","loc":{"line":9,"column":34}},{"name":"./optimizers/sgd_optimizer","loc":{"line":10,"column":30}}],"generated":{"js":"\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar adadelta_optimizer_1 = require(\"./optimizers/adadelta_optimizer\");\nvar adagrad_optimizer_1 = require(\"./optimizers/adagrad_optimizer\");\nvar adam_optimizer_1 = require(\"./optimizers/adam_optimizer\");\nvar adamax_optimizer_1 = require(\"./optimizers/adamax_optimizer\");\nvar momentum_optimizer_1 = require(\"./optimizers/momentum_optimizer\");\nvar optimizer_constructors_1 = require(\"./optimizers/optimizer_constructors\");\nvar rmsprop_optimizer_1 = require(\"./optimizers/rmsprop_optimizer\");\nvar sgd_optimizer_1 = require(\"./optimizers/sgd_optimizer\");\n[momentum_optimizer_1.MomentumOptimizer, sgd_optimizer_1.SGDOptimizer, adadelta_optimizer_1.AdadeltaOptimizer, adagrad_optimizer_1.AdagradOptimizer,\n    rmsprop_optimizer_1.RMSPropOptimizer, adamax_optimizer_1.AdamaxOptimizer, adam_optimizer_1.AdamOptimizer];\nexports.train = {\n    sgd: optimizer_constructors_1.OptimizerConstructors.sgd,\n    momentum: optimizer_constructors_1.OptimizerConstructors.momentum,\n    adadelta: optimizer_constructors_1.OptimizerConstructors.adadelta,\n    adagrad: optimizer_constructors_1.OptimizerConstructors.adagrad,\n    rmsprop: optimizer_constructors_1.OptimizerConstructors.rmsprop,\n    adamax: optimizer_constructors_1.OptimizerConstructors.adamax,\n    adam: optimizer_constructors_1.OptimizerConstructors.adam\n};\n","map":{"version":3,"file":"train.js","sourceRoot":"","sources":["../src/train.ts"],"names":[],"mappings":";;AAkBA,sEAAkE;AAClE,oEAAgE;AAChE,8DAA0D;AAC1D,kEAA8D;AAC9D,sEAAkE;AAClE,8EAA0E;AAC1E,oEAAgE;AAChE,4DAAwD;AAGxD,CAAC,sCAAiB,EAAE,4BAAY,EAAE,sCAAiB,EAAE,oCAAgB;IACpE,oCAAgB,EAAE,kCAAe,EAAE,8BAAa,CAAC,CAAC;AAEtC,QAAA,KAAK,GAAG;IACnB,GAAG,EAAE,8CAAqB,CAAC,GAAG;IAC9B,QAAQ,EAAE,8CAAqB,CAAC,QAAQ;IACxC,QAAQ,EAAE,8CAAqB,CAAC,QAAQ;IACxC,OAAO,EAAE,8CAAqB,CAAC,OAAO;IACtC,OAAO,EAAE,8CAAqB,CAAC,OAAO;IACtC,MAAM,EAAE,8CAAqB,CAAC,MAAM;IACpC,IAAI,EAAE,8CAAqB,CAAC,IAAI;CACjC,CAAC","sourcesContent":["/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// So typings can propagate.\nimport {AdadeltaOptimizer} from './optimizers/adadelta_optimizer';\nimport {AdagradOptimizer} from './optimizers/adagrad_optimizer';\nimport {AdamOptimizer} from './optimizers/adam_optimizer';\nimport {AdamaxOptimizer} from './optimizers/adamax_optimizer';\nimport {MomentumOptimizer} from './optimizers/momentum_optimizer';\nimport {OptimizerConstructors} from './optimizers/optimizer_constructors';\nimport {RMSPropOptimizer} from './optimizers/rmsprop_optimizer';\nimport {SGDOptimizer} from './optimizers/sgd_optimizer';\n\n// tslint:disable-next-line:no-unused-expression\n[MomentumOptimizer, SGDOptimizer, AdadeltaOptimizer, AdagradOptimizer,\n RMSPropOptimizer, AdamaxOptimizer, AdamOptimizer];\n\nexport const train = {\n  sgd: OptimizerConstructors.sgd,\n  momentum: OptimizerConstructors.momentum,\n  adadelta: OptimizerConstructors.adadelta,\n  adagrad: OptimizerConstructors.adagrad,\n  rmsprop: OptimizerConstructors.rmsprop,\n  adamax: OptimizerConstructors.adamax,\n  adam: OptimizerConstructors.adam\n};\n"]}},"hash":"1cbf44ab8f5146a8b2bd0cec571ddaae","cacheData":{"env":{}}}