{"dependencies":[{"name":"/usr/local/google/home/nsthorat/deeplearnjs-clients/float16/tfjs-core/test/package.json","includedInParent":true,"mtime":1528810356568},{"name":"/usr/local/google/home/nsthorat/deeplearnjs-clients/float16/tfjs-core/test/.babelrc","includedInParent":true,"mtime":1525096773813},{"name":"/usr/local/google/home/nsthorat/deeplearnjs-clients/float16/tfjs-core/tsconfig.json","includedInParent":true,"mtime":1528810356568}],"generated":{"js":"\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar DType;\n(function (DType) {\n    DType[\"float32\"] = \"float32\";\n    DType[\"int32\"] = \"int32\";\n    DType[\"bool\"] = \"bool\";\n})(DType = exports.DType || (exports.DType = {}));\nvar Rank;\n(function (Rank) {\n    Rank[\"R0\"] = \"R0\";\n    Rank[\"R1\"] = \"R1\";\n    Rank[\"R2\"] = \"R2\";\n    Rank[\"R3\"] = \"R3\";\n    Rank[\"R4\"] = \"R4\";\n    Rank[\"R5\"] = \"R5\";\n})(Rank = exports.Rank || (exports.Rank = {}));\nvar UpcastInt32AndMap;\n(function (UpcastInt32AndMap) {\n    UpcastInt32AndMap[\"float32\"] = \"float32\";\n    UpcastInt32AndMap[\"int32\"] = \"int32\";\n    UpcastInt32AndMap[\"bool\"] = \"int32\";\n})(UpcastInt32AndMap || (UpcastInt32AndMap = {}));\nvar UpcastBoolAndMap;\n(function (UpcastBoolAndMap) {\n    UpcastBoolAndMap[\"float32\"] = \"float32\";\n    UpcastBoolAndMap[\"int32\"] = \"int32\";\n    UpcastBoolAndMap[\"bool\"] = \"bool\";\n})(UpcastBoolAndMap || (UpcastBoolAndMap = {}));\nvar UpcastFloat32AndMap;\n(function (UpcastFloat32AndMap) {\n    UpcastFloat32AndMap[\"float32\"] = \"float32\";\n    UpcastFloat32AndMap[\"int32\"] = \"float32\";\n    UpcastFloat32AndMap[\"bool\"] = \"float32\";\n})(UpcastFloat32AndMap || (UpcastFloat32AndMap = {}));\nvar upcastTypeMap = {\n    float32: UpcastFloat32AndMap,\n    int32: UpcastInt32AndMap,\n    bool: UpcastBoolAndMap\n};\nfunction upcastType(typeA, typeB) {\n    return upcastTypeMap[typeA][typeB];\n}\nexports.upcastType = upcastType;\nfunction sumOutType(type) {\n    return upcastType(type, 'int32');\n}\nexports.sumOutType = sumOutType;\n","map":{"version":3,"file":"types.js","sourceRoot":"","sources":["../src/types.ts"],"names":[],"mappings":";;AAmBA,IAAY,KAIX;AAJD,WAAY,KAAK;IACf,4BAAmB,CAAA;IACnB,wBAAe,CAAA;IACf,sBAAa,CAAA;AACf,CAAC,EAJW,KAAK,GAAL,aAAK,KAAL,aAAK,QAIhB;AAsBD,IAAY,IAOX;AAPD,WAAY,IAAI;IACd,iBAAS,CAAA;IACT,iBAAS,CAAA;IACT,iBAAS,CAAA;IACT,iBAAS,CAAA;IACT,iBAAS,CAAA;IACT,iBAAS,CAAA;AACX,CAAC,EAPW,IAAI,GAAJ,YAAI,KAAJ,YAAI,QAOf;AAwCD,IAAK,iBAIJ;AAJD,WAAK,iBAAiB;IACpB,wCAAmB,CAAA;IACnB,oCAAe,CAAA;IACf,mCAAc,CAAA;AAChB,CAAC,EAJI,iBAAiB,KAAjB,iBAAiB,QAIrB;AAED,IAAK,gBAIJ;AAJD,WAAK,gBAAgB;IACnB,uCAAmB,CAAA;IACnB,mCAAe,CAAA;IACf,iCAAa,CAAA;AACf,CAAC,EAJI,gBAAgB,KAAhB,gBAAgB,QAIpB;AAED,IAAK,mBAIJ;AAJD,WAAK,mBAAmB;IACtB,0CAAmB,CAAA;IACnB,wCAAiB,CAAA;IACjB,uCAAgB,CAAA;AAClB,CAAC,EAJI,mBAAmB,KAAnB,mBAAmB,QAIvB;AAED,IAAM,aAAa,GAAG;IACpB,OAAO,EAAE,mBAAmB;IAC5B,KAAK,EAAE,iBAAiB;IACxB,IAAI,EAAE,gBAAgB;CACvB,CAAC;AAEF,oBAA2B,KAAe,EAAE,KAAe;IACzD,MAAM,CAAC,aAAa,CAAC,KAAK,CAAC,CAAC,KAAK,CAAC,CAAC;AACrC,CAAC;AAFD,gCAEC;AAGD,oBAA2B,IAAc;IACvC,MAAM,CAAC,UAAU,CAAC,IAAI,EAAE,OAAO,CAAC,CAAC;AACnC,CAAC;AAFD,gCAEC","sourcesContent":["/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor, Variable} from './tensor';\n\nexport enum DType {\n  float32 = 'float32',\n  int32 = 'int32',\n  bool = 'bool'\n}\n\n/** @docalias number[] */\nexport interface ShapeMap {\n  R0: number[];\n  R1: [number];\n  R2: [number, number];\n  R3: [number, number, number];\n  R4: [number, number, number, number];\n  R5: [number, number, number, number, number];\n}\n\n/** @hidden */\nexport interface DataTypeMap {\n  float32: Float32Array;\n  int32: Int32Array;\n  bool: Uint8Array;\n}\n/** @docalias 'float32'|'int32'|'bool' */\nexport type DataType = keyof DataTypeMap;\nexport type TypedArray = DataTypeMap[DataType];\n\nexport enum Rank {\n  R0 = 'R0',\n  R1 = 'R1',\n  R2 = 'R2',\n  R3 = 'R3',\n  R4 = 'R4',\n  R5 = 'R5'\n}\n\n/** @docalias TypedArray|Array */\nexport type TensorLike =\n    TypedArray|number|boolean|number[]|number[][]|number[][][]|number[][][][]|\n              number[][][][][]|boolean[]|boolean[][]|boolean[][][]|\n              boolean[][][][]|boolean[][][][][];\n/** @docalias TypedArray|Array */\nexport type TensorLike1D = TypedArray|number[]|boolean[];\n/** @docalias TypedArray|Array */\nexport type TensorLike2D = TypedArray|number[]|number[][]|boolean[]|boolean[][];\n/** @docalias TypedArray|Array */\nexport type TensorLike3D =\n    TypedArray|number[]|number[][][]|boolean[]|boolean[][][];\n/** @docalias TypedArray|Array */\nexport type TensorLike4D =\n    TypedArray|number[]|number[][][][]|boolean[]|boolean[][][][];\n/** @docalias TypedArray|Array */\nexport type TensorLike5D =\n    TypedArray|number[]|number[][][][][]|boolean[]|boolean[][][][][];\n\nexport type FlatVector = boolean[]|number[]|TypedArray;\nexport type RegularArray<T> = T[]|T[][]|T[][][]|T[][][][]|T[][][][][];\nexport type ArrayData<D extends DataType> =\n    DataTypeMap[D]|RegularArray<number>|RegularArray<boolean>;\n\n// tslint:disable-next-line:no-any\nexport interface RecursiveArray<T extends any> {\n  [index: number]: T|RecursiveArray<T>;\n}\n\n/** @docalias {[name: string]: Tensor} */\nexport type NamedTensorMap = {\n  [name: string]: Tensor\n};\n\nexport type NamedVariableMap = {\n  [name: string]: Variable;\n};\n\nenum UpcastInt32AndMap {\n  float32 = 'float32',\n  int32 = 'int32',\n  bool = 'int32'\n}\n\nenum UpcastBoolAndMap {\n  float32 = 'float32',\n  int32 = 'int32',\n  bool = 'bool'\n}\n\nenum UpcastFloat32AndMap {\n  float32 = 'float32',\n  int32 = 'float32',\n  bool = 'float32'\n}\n\nconst upcastTypeMap = {\n  float32: UpcastFloat32AndMap,\n  int32: UpcastInt32AndMap,\n  bool: UpcastBoolAndMap\n};\n\nexport function upcastType(typeA: DataType, typeB: DataType): DataType {\n  return upcastTypeMap[typeA][typeB];\n}\n\n/** Returns the output type after summation. */\nexport function sumOutType(type: DataType) {\n  return upcastType(type, 'int32');\n}\n\n/**\n * @docalias void|number|string|Tensor|Tensor[]|{[key:\n * string]:Tensor|number|string}\n */\nexport type TensorContainer = void|Tensor|string|number|boolean|\n    TensorContainerObject|TensorContainerArray;\nexport interface TensorContainerObject {\n  [x: string]: TensorContainer;\n}\nexport interface TensorContainerArray extends Array<TensorContainer> {}\n\nexport interface ModelPredictConfig {\n  /**\n   * Optional. Batch size (Integer). If unspecified, it will default to 32.\n   */\n  batchSize?: number;\n\n  /**\n   * Optional. Verbosity mode. Defaults to false.\n   */\n  verbose?: boolean;\n}\n\n/**\n * Common interface for a machine learning model that can do inference.\n */\nexport interface InferenceModel {\n  /**\n   * Execute the inference for the input tensors.\n   *\n   * @param input The input tensors, when there is single input for the model,\n   * inputs param should be a Tensor. For models with mutliple inputs, inputs\n   * params should be in either Tensor[] if the input order is fixed, or\n   * otherwise NamedTensorMap format.\n   * For batch inference execution, the tensors for each input need to be\n   * concatenated together. For example with mobilenet, the required input shape\n   * is [1, 244, 244, 3], which represents the [batch, height, width, channel].\n   * If we are provide a batched data of 100 images, the input tensor should be\n   * in the shape of [100, 244, 244, 3].\n   *\n   * @param config Prediction configuration for specifying the batch size.\n   *\n   * @returns Inference result tensors. The output would be single Tensor if\n   * model has single output node, otherwise Tensor[] or NamedTensorMap[] will\n   * be returned for model with multiple outputs.\n   */\n  predict(inputs: Tensor|Tensor[]|NamedTensorMap, config: ModelPredictConfig):\n      Tensor|Tensor[]|NamedTensorMap;\n\n  /**\n   * Single Execute the inference for the input tensors and return activation\n   * values for specified output node names without batching.\n   *\n   * @param input The input tensors, when there is single input for the model,\n   * inputs param should be a Tensor. For models with mutliple inputs, inputs\n   * params should be in either Tensor[] if the input order is fixed, or\n   * otherwise NamedTensorMap format.\n   *\n   * @param outputs string|string[]. List of output node names to retrieve\n   * activation from.\n   *\n   * @returns Activation values for the output nodes result tensors. The return\n   * type matches specified parameter outputs type. The output would be single\n   * Tensor if single output is specified, otherwise Tensor[] for multiple\n   * outputs.\n   */\n  execute(inputs: Tensor|Tensor[]|NamedTensorMap, outputs: string|string[]):\n      Tensor|Tensor[];\n}\n"]}},"hash":"3f2f2ebc3cb0655c70c4f601fbed2894","cacheData":{"env":{}}}