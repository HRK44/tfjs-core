{"dependencies":[{"name":"/usr/local/google/home/nsthorat/deeplearnjs-clients/float16/tfjs-core/test/package.json","includedInParent":true,"mtime":1528810356568},{"name":"/usr/local/google/home/nsthorat/deeplearnjs-clients/float16/tfjs-core/test/.babelrc","includedInParent":true,"mtime":1525096773813},{"name":"/usr/local/google/home/nsthorat/deeplearnjs-clients/float16/tfjs-core/tsconfig.json","includedInParent":true,"mtime":1528810356568},{"name":"./doc","loc":{"line":54,"column":20}},{"name":"./environment","loc":{"line":55,"column":28}},{"name":"./ops/ops","loc":{"line":56,"column":18}},{"name":"./tensor_util","loc":{"line":57,"column":26}},{"name":"./util","loc":{"line":58,"column":19}}],"generated":{"js":"\"use strict\";\nvar __extends = (this && this.__extends) || (function () {\n    var extendStatics = Object.setPrototypeOf ||\n        ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n        function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; };\n    return function (d, b) {\n        extendStatics(d, b);\n        function __() { this.constructor = d; }\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n    };\n})();\nvar __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {\n    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;\n    if (typeof Reflect === \"object\" && typeof Reflect.decorate === \"function\") r = Reflect.decorate(decorators, target, key, desc);\n    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;\n    return c > 3 && r && Object.defineProperty(target, key, r), r;\n};\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = y[op[0] & 2 ? \"return\" : op[0] ? \"throw\" : \"next\"]) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [0, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar doc_1 = require(\"./doc\");\nvar environment_1 = require(\"./environment\");\nvar ops = require(\"./ops/ops\");\nvar tensor_util = require(\"./tensor_util\");\nvar util = require(\"./util\");\nvar TensorBuffer = (function () {\n    function TensorBuffer(shape, dtype, values) {\n        this.dtype = dtype;\n        if (values != null) {\n            var n = values.length;\n            var size = util.sizeFromShape(shape);\n            util.assert(n === size, \"Length of values '\" + n + \"' does not match the size \" +\n                (\"inferred by the shape '\" + size + \"'\"));\n        }\n        this.shape = shape.slice();\n        this.values =\n            values || util.getTypedArrayFromDType(dtype, util.sizeFromShape(shape));\n        this.strides = computeStrides(shape);\n        this.size = util.sizeFromShape(shape);\n    }\n    TensorBuffer.prototype.set = function (value) {\n        var locs = [];\n        for (var _i = 1; _i < arguments.length; _i++) {\n            locs[_i - 1] = arguments[_i];\n        }\n        if (locs.length === 0) {\n            locs = [0];\n        }\n        util.assert(locs.length === this.rank, \"The number of provided coordinates (\" + locs.length + \") must \" +\n            (\"match the rank (\" + this.rank + \")\"));\n        var index = this.locToIndex(locs);\n        this.values[index] = value;\n    };\n    TensorBuffer.prototype.get = function () {\n        var locs = [];\n        for (var _i = 0; _i < arguments.length; _i++) {\n            locs[_i] = arguments[_i];\n        }\n        if (locs.length === 0) {\n            locs = [0];\n        }\n        var index = locs[locs.length - 1];\n        for (var i = 0; i < locs.length - 1; ++i) {\n            index += this.strides[i] * locs[i];\n        }\n        return this.values[index];\n    };\n    TensorBuffer.prototype.locToIndex = function (locs) {\n        if (this.rank === 0) {\n            return 0;\n        }\n        else if (this.rank === 1) {\n            return locs[0];\n        }\n        var index = locs[locs.length - 1];\n        for (var i = 0; i < locs.length - 1; ++i) {\n            index += this.strides[i] * locs[i];\n        }\n        return index;\n    };\n    TensorBuffer.prototype.indexToLoc = function (index) {\n        if (this.rank === 0) {\n            return [];\n        }\n        else if (this.rank === 1) {\n            return [index];\n        }\n        var locs = new Array(this.shape.length);\n        for (var i = 0; i < locs.length - 1; ++i) {\n            locs[i] = Math.floor(index / this.strides[i]);\n            index -= locs[i] * this.strides[i];\n        }\n        locs[locs.length - 1] = index;\n        return locs;\n    };\n    Object.defineProperty(TensorBuffer.prototype, \"rank\", {\n        get: function () {\n            return this.shape.length;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    TensorBuffer.prototype.toTensor = function () {\n        return Tensor.make(this.shape, { values: this.values }, this.dtype);\n    };\n    __decorate([\n        doc_1.doc({ heading: 'Tensors', subheading: 'Creation' })\n    ], TensorBuffer.prototype, \"set\", null);\n    __decorate([\n        doc_1.doc({ heading: 'Tensors', subheading: 'Creation' })\n    ], TensorBuffer.prototype, \"get\", null);\n    __decorate([\n        doc_1.doc({ heading: 'Tensors', subheading: 'Creation' })\n    ], TensorBuffer.prototype, \"toTensor\", null);\n    TensorBuffer = __decorate([\n        doc_1.doc({ heading: 'Tensors', subheading: 'Classes' })\n    ], TensorBuffer);\n    return TensorBuffer;\n}());\nexports.TensorBuffer = TensorBuffer;\nvar Tensor = (function () {\n    function Tensor(shape, dtype, values, dataId) {\n        this.isDisposedInternal = false;\n        this.size = util.sizeFromShape(shape);\n        if (values != null) {\n            util.assert(this.size === values.length, \"Constructing tensor of shape (\" + this.size + \") should match the \" +\n                (\"length of values (\" + values.length + \")\"));\n        }\n        this.shape = shape.slice();\n        this.dtype = dtype || 'float32';\n        this.strides = computeStrides(shape);\n        this.dataId = dataId != null ? dataId : {};\n        this.id = Tensor_1.nextId++;\n        this.rankType = (this.rank < 5 ? this.rank.toString() : 'higher');\n        environment_1.ENV.engine.registerTensor(this);\n        if (values != null) {\n            environment_1.ENV.engine.write(this.dataId, values);\n        }\n    }\n    Tensor_1 = Tensor;\n    Tensor.make = function (shape, data, dtype) {\n        return new Tensor_1(shape, dtype, data.values, data.dataId);\n    };\n    Tensor.prototype.flatten = function () {\n        this.throwIfDisposed();\n        return this.as1D();\n    };\n    Tensor.prototype.asScalar = function () {\n        this.throwIfDisposed();\n        util.assert(this.size === 1, 'The array must have only 1 element.');\n        return this.reshape([]);\n    };\n    Tensor.prototype.as1D = function () {\n        this.throwIfDisposed();\n        return this.reshape([this.size]);\n    };\n    Tensor.prototype.as2D = function (rows, columns) {\n        this.throwIfDisposed();\n        return this.reshape([rows, columns]);\n    };\n    Tensor.prototype.as3D = function (rows, columns, depth) {\n        this.throwIfDisposed();\n        return this.reshape([rows, columns, depth]);\n    };\n    Tensor.prototype.as4D = function (rows, columns, depth, depth2) {\n        this.throwIfDisposed();\n        return this.reshape([rows, columns, depth, depth2]);\n    };\n    Tensor.prototype.asType = function (dtype) {\n        this.throwIfDisposed();\n        return ops.cast(this, dtype);\n    };\n    Object.defineProperty(Tensor.prototype, \"rank\", {\n        get: function () {\n            return this.shape.length;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Tensor.prototype.get = function () {\n        var locs = [];\n        for (var _i = 0; _i < arguments.length; _i++) {\n            locs[_i] = arguments[_i];\n        }\n        util.assert(locs.length === this.rank, 'Number of coordinates in get() must match the rank of the tensor');\n        this.throwIfDisposed();\n        if (locs.length === 0) {\n            locs = [0];\n        }\n        var index = locs[locs.length - 1];\n        for (var i = 0; i < locs.length - 1; ++i) {\n            index += this.strides[i] * locs[i];\n        }\n        return this.dataSync()[index];\n    };\n    Tensor.prototype.buffer = function () {\n        return ops.buffer(this.shape, this.dtype, this.dataSync());\n    };\n    Tensor.prototype.data = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            return __generator(this, function (_a) {\n                this.throwIfDisposed();\n                return [2, environment_1.ENV.engine.read(this.dataId)];\n            });\n        });\n    };\n    Tensor.prototype.dataSync = function () {\n        this.throwIfDisposed();\n        return environment_1.ENV.engine.readSync(this.dataId);\n    };\n    Tensor.prototype.dispose = function () {\n        if (this.isDisposed) {\n            return;\n        }\n        environment_1.ENV.engine.disposeTensor(this);\n        this.isDisposedInternal = true;\n    };\n    Object.defineProperty(Tensor.prototype, \"isDisposed\", {\n        get: function () {\n            return this.isDisposedInternal;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Tensor.prototype.throwIfDisposed = function () {\n        if (this.isDisposed) {\n            throw new Error(\"Tensor is disposed.\");\n        }\n    };\n    Tensor.prototype.toFloat = function () {\n        return this.asType('float32');\n    };\n    Tensor.prototype.toInt = function () {\n        return this.asType('int32');\n    };\n    Tensor.prototype.toBool = function () {\n        return this.asType('bool');\n    };\n    Tensor.prototype.print = function (verbose) {\n        if (verbose === void 0) { verbose = false; }\n        return ops.print(this, verbose);\n    };\n    Tensor.prototype.reshape = function (newShape) {\n        this.throwIfDisposed();\n        return ops.reshape(this, newShape);\n    };\n    Tensor.prototype.reshapeAs = function (x) {\n        this.throwIfDisposed();\n        return this.reshape(x.shape);\n    };\n    Tensor.prototype.expandDims = function (axis) {\n        if (axis === void 0) { axis = 0; }\n        return ops.expandDims(this, axis);\n    };\n    Tensor.prototype.cumsum = function (axis, exclusive, reverse) {\n        if (axis === void 0) { axis = 0; }\n        if (exclusive === void 0) { exclusive = false; }\n        if (reverse === void 0) { reverse = false; }\n        return ops.cumsum(this, axis, exclusive, reverse);\n    };\n    Tensor.prototype.squeeze = function (axis) {\n        this.throwIfDisposed();\n        return ops.squeeze(this, axis);\n    };\n    Tensor.prototype.clone = function () {\n        this.throwIfDisposed();\n        return ops.clone(this);\n    };\n    Tensor.prototype.toString = function (verbose) {\n        if (verbose === void 0) { verbose = false; }\n        return tensor_util.tensorToString(this, verbose);\n    };\n    Tensor.prototype.tile = function (reps) {\n        this.throwIfDisposed();\n        return ops.tile(this, reps);\n    };\n    Tensor.prototype.gather = function (indices, axis) {\n        if (axis === void 0) { axis = 0; }\n        this.throwIfDisposed();\n        return ops.gather(this, indices, axis);\n    };\n    Tensor.prototype.matMul = function (b, transposeA, transposeB) {\n        if (transposeA === void 0) { transposeA = false; }\n        if (transposeB === void 0) { transposeB = false; }\n        this.throwIfDisposed();\n        return ops.matMul(this, b, transposeA, transposeB);\n    };\n    Tensor.prototype.dot = function (b) {\n        this.throwIfDisposed();\n        return ops.dot(this, b);\n    };\n    Tensor.prototype.norm = function (ord, axis, keepDims) {\n        if (ord === void 0) { ord = 'euclidean'; }\n        if (axis === void 0) { axis = null; }\n        if (keepDims === void 0) { keepDims = false; }\n        this.throwIfDisposed();\n        return ops.norm(this, ord, axis, keepDims);\n    };\n    Tensor.prototype.slice = function (begin, size) {\n        this.throwIfDisposed();\n        return ops.slice(this, begin, size);\n    };\n    Tensor.prototype.reverse = function (axis) {\n        this.throwIfDisposed();\n        return ops.reverse(this, axis);\n    };\n    Tensor.prototype.concat = function (x, axis) {\n        if (axis === void 0) { axis = 0; }\n        this.throwIfDisposed();\n        return ops.concat([this, x], axis);\n    };\n    Tensor.prototype.stack = function (x, axis) {\n        if (axis === void 0) { axis = 0; }\n        return ops.stack([this, x], axis);\n    };\n    Tensor.prototype.unstack = function (x, axis) {\n        if (axis === void 0) { axis = 0; }\n        return ops.unstack(this, axis);\n    };\n    Tensor.prototype.pad = function (paddings, constantValue) {\n        if (constantValue === void 0) { constantValue = 0; }\n        return ops.pad(this, paddings, constantValue);\n    };\n    Tensor.prototype.batchNormalization = function (mean, variance, varianceEpsilon, scale, offset) {\n        if (varianceEpsilon === void 0) { varianceEpsilon = .001; }\n        this.throwIfDisposed();\n        return ops.batchNormalization(this, mean, variance, varianceEpsilon, scale, offset);\n    };\n    Tensor.prototype.logSumExp = function (axis, keepDims) {\n        if (axis === void 0) { axis = null; }\n        if (keepDims === void 0) { keepDims = false; }\n        this.throwIfDisposed();\n        return ops.logSumExp(this, axis, keepDims);\n    };\n    Tensor.prototype.sum = function (axis, keepDims) {\n        if (axis === void 0) { axis = null; }\n        if (keepDims === void 0) { keepDims = false; }\n        this.throwIfDisposed();\n        return ops.sum(this, axis, keepDims);\n    };\n    Tensor.prototype.mean = function (axis, keepDims) {\n        if (axis === void 0) { axis = null; }\n        if (keepDims === void 0) { keepDims = false; }\n        this.throwIfDisposed();\n        return ops.mean(this, axis, keepDims);\n    };\n    Tensor.prototype.min = function (axis, keepDims) {\n        if (axis === void 0) { axis = null; }\n        if (keepDims === void 0) { keepDims = false; }\n        this.throwIfDisposed();\n        return ops.min(this, axis, keepDims);\n    };\n    Tensor.prototype.max = function (axis, keepDims) {\n        if (axis === void 0) { axis = null; }\n        if (keepDims === void 0) { keepDims = false; }\n        this.throwIfDisposed();\n        return ops.max(this, axis, keepDims);\n    };\n    Tensor.prototype.argMin = function (axis) {\n        if (axis === void 0) { axis = null; }\n        this.throwIfDisposed();\n        return ops.argMin(this, axis);\n    };\n    Tensor.prototype.argMax = function (axis) {\n        if (axis === void 0) { axis = null; }\n        this.throwIfDisposed();\n        return ops.argMax(this, axis);\n    };\n    Tensor.prototype.cast = function (dtype) {\n        this.throwIfDisposed();\n        return ops.cast(this, dtype);\n    };\n    Tensor.prototype.add = function (x) {\n        this.throwIfDisposed();\n        return ops.add(this, x);\n    };\n    Tensor.prototype.addStrict = function (x) {\n        this.throwIfDisposed();\n        return ops.addStrict(this, x);\n    };\n    Tensor.prototype.sub = function (x) {\n        this.throwIfDisposed();\n        return ops.sub(this, x);\n    };\n    Tensor.prototype.subStrict = function (x) {\n        this.throwIfDisposed();\n        return ops.subStrict(this, x);\n    };\n    Tensor.prototype.pow = function (exp) {\n        this.throwIfDisposed();\n        return ops.pow(this, exp);\n    };\n    Tensor.prototype.powStrict = function (exp) {\n        this.throwIfDisposed();\n        return ops.powStrict(this, exp);\n    };\n    Tensor.prototype.mul = function (x) {\n        this.throwIfDisposed();\n        return ops.mul(this, x);\n    };\n    Tensor.prototype.mulStrict = function (x) {\n        this.throwIfDisposed();\n        return ops.mulStrict(this, x);\n    };\n    Tensor.prototype.div = function (x) {\n        this.throwIfDisposed();\n        return ops.div(this, x);\n    };\n    Tensor.prototype.floorDiv = function (x) {\n        this.throwIfDisposed();\n        return ops.floorDiv(this, x);\n    };\n    Tensor.prototype.divStrict = function (x) {\n        this.throwIfDisposed();\n        return ops.divStrict(this, x);\n    };\n    Tensor.prototype.minimum = function (x) {\n        this.throwIfDisposed();\n        return ops.minimum(this, x);\n    };\n    Tensor.prototype.minimumStrict = function (x) {\n        this.throwIfDisposed();\n        return ops.minimumStrict(this, x);\n    };\n    Tensor.prototype.maximum = function (x) {\n        this.throwIfDisposed();\n        return ops.maximum(this, x);\n    };\n    Tensor.prototype.maximumStrict = function (x) {\n        this.throwIfDisposed();\n        return ops.maximumStrict(this, x);\n    };\n    Tensor.prototype.mod = function (x) {\n        this.throwIfDisposed();\n        return ops.mod(this, x);\n    };\n    Tensor.prototype.modStrict = function (x) {\n        this.throwIfDisposed();\n        return ops.modStrict(this, x);\n    };\n    Tensor.prototype.squaredDifference = function (x) {\n        this.throwIfDisposed();\n        return ops.squaredDifference(this, x);\n    };\n    Tensor.prototype.squaredDifferenceStrict = function (x) {\n        this.throwIfDisposed();\n        return ops.squaredDifferenceStrict(this, x);\n    };\n    Tensor.prototype.transpose = function (perm) {\n        this.throwIfDisposed();\n        return ops.transpose(this, perm);\n    };\n    Tensor.prototype.notEqual = function (x) {\n        this.throwIfDisposed();\n        return ops.notEqual(this, x);\n    };\n    Tensor.prototype.notEqualStrict = function (x) {\n        this.throwIfDisposed();\n        return ops.notEqualStrict(this, x);\n    };\n    Tensor.prototype.less = function (x) {\n        this.throwIfDisposed();\n        return ops.less(this, x);\n    };\n    Tensor.prototype.lessStrict = function (x) {\n        this.throwIfDisposed();\n        return ops.lessStrict(this, x);\n    };\n    Tensor.prototype.equal = function (x) {\n        this.throwIfDisposed();\n        return ops.equal(this, x);\n    };\n    Tensor.prototype.equalStrict = function (x) {\n        this.throwIfDisposed();\n        return ops.equalStrict(this, x);\n    };\n    Tensor.prototype.lessEqual = function (x) {\n        this.throwIfDisposed();\n        return ops.lessEqual(this, x);\n    };\n    Tensor.prototype.lessEqualStrict = function (x) {\n        this.throwIfDisposed();\n        return ops.lessEqualStrict(this, x);\n    };\n    Tensor.prototype.greater = function (x) {\n        this.throwIfDisposed();\n        return ops.greater(this, x);\n    };\n    Tensor.prototype.greaterStrict = function (x) {\n        this.throwIfDisposed();\n        return ops.greaterStrict(this, x);\n    };\n    Tensor.prototype.greaterEqual = function (x) {\n        this.throwIfDisposed();\n        return ops.greaterEqual(this, x);\n    };\n    Tensor.prototype.greaterEqualStrict = function (x) {\n        this.throwIfDisposed();\n        return ops.greaterEqualStrict(this, x);\n    };\n    Tensor.prototype.logicalAnd = function (x) {\n        this.throwIfDisposed();\n        return ops.logicalAnd(this, x);\n    };\n    Tensor.prototype.logicalOr = function (x) {\n        this.throwIfDisposed();\n        return ops.logicalOr(this, x);\n    };\n    Tensor.prototype.logicalNot = function () {\n        this.throwIfDisposed();\n        return ops.logicalNot(this);\n    };\n    Tensor.prototype.logicalXor = function (x) {\n        this.throwIfDisposed();\n        return ops.logicalXor(this, x);\n    };\n    Tensor.prototype.where = function (condition, x) {\n        this.throwIfDisposed();\n        return ops.where(condition, this, x);\n    };\n    Tensor.prototype.neg = function () {\n        this.throwIfDisposed();\n        return ops.neg(this);\n    };\n    Tensor.prototype.ceil = function () {\n        this.throwIfDisposed();\n        return ops.ceil(this);\n    };\n    Tensor.prototype.floor = function () {\n        this.throwIfDisposed();\n        return ops.floor(this);\n    };\n    Tensor.prototype.sign = function () {\n        this.throwIfDisposed();\n        return ops.sign(this);\n    };\n    Tensor.prototype.exp = function () {\n        this.throwIfDisposed();\n        return ops.exp(this);\n    };\n    Tensor.prototype.expm1 = function () {\n        this.throwIfDisposed();\n        return ops.expm1(this);\n    };\n    Tensor.prototype.log = function () {\n        this.throwIfDisposed();\n        return ops.log(this);\n    };\n    Tensor.prototype.log1p = function () {\n        this.throwIfDisposed();\n        return ops.log1p(this);\n    };\n    Tensor.prototype.sqrt = function () {\n        this.throwIfDisposed();\n        return ops.sqrt(this);\n    };\n    Tensor.prototype.rsqrt = function () {\n        this.throwIfDisposed();\n        return ops.rsqrt(this);\n    };\n    Tensor.prototype.square = function () {\n        this.throwIfDisposed();\n        return ops.square(this);\n    };\n    Tensor.prototype.reciprocal = function () {\n        this.throwIfDisposed();\n        return ops.reciprocal(this);\n    };\n    Tensor.prototype.abs = function () {\n        this.throwIfDisposed();\n        return ops.abs(this);\n    };\n    Tensor.prototype.clipByValue = function (min, max) {\n        this.throwIfDisposed();\n        return ops.clipByValue(this, min, max);\n    };\n    Tensor.prototype.relu = function () {\n        this.throwIfDisposed();\n        return ops.relu(this);\n    };\n    Tensor.prototype.elu = function () {\n        this.throwIfDisposed();\n        return ops.elu(this);\n    };\n    Tensor.prototype.selu = function () {\n        this.throwIfDisposed();\n        return ops.selu(this);\n    };\n    Tensor.prototype.leakyRelu = function (alpha) {\n        if (alpha === void 0) { alpha = 0.2; }\n        this.throwIfDisposed();\n        return ops.leakyRelu(this, alpha);\n    };\n    Tensor.prototype.prelu = function (alpha) {\n        this.throwIfDisposed();\n        return ops.prelu(this, alpha);\n    };\n    Tensor.prototype.sigmoid = function () {\n        this.throwIfDisposed();\n        return ops.sigmoid(this);\n    };\n    Tensor.prototype.logSigmoid = function () {\n        this.throwIfDisposed();\n        return ops.logSigmoid(this);\n    };\n    Tensor.prototype.softplus = function () {\n        this.throwIfDisposed();\n        return ops.softplus(this);\n    };\n    Tensor.prototype.sin = function () {\n        this.throwIfDisposed();\n        return ops.sin(this);\n    };\n    Tensor.prototype.cos = function () {\n        this.throwIfDisposed();\n        return ops.cos(this);\n    };\n    Tensor.prototype.tan = function () {\n        this.throwIfDisposed();\n        return ops.tan(this);\n    };\n    Tensor.prototype.asin = function () {\n        this.throwIfDisposed();\n        return ops.asin(this);\n    };\n    Tensor.prototype.acos = function () {\n        this.throwIfDisposed();\n        return ops.acos(this);\n    };\n    Tensor.prototype.atan = function () {\n        this.throwIfDisposed();\n        return ops.atan(this);\n    };\n    Tensor.prototype.sinh = function () {\n        this.throwIfDisposed();\n        return ops.sinh(this);\n    };\n    Tensor.prototype.cosh = function () {\n        this.throwIfDisposed();\n        return ops.cosh(this);\n    };\n    Tensor.prototype.tanh = function () {\n        this.throwIfDisposed();\n        return ops.tanh(this);\n    };\n    Tensor.prototype.asinh = function () {\n        this.throwIfDisposed();\n        return ops.asinh(this);\n    };\n    Tensor.prototype.acosh = function () {\n        this.throwIfDisposed();\n        return ops.acosh(this);\n    };\n    Tensor.prototype.atanh = function () {\n        this.throwIfDisposed();\n        return ops.atanh(this);\n    };\n    Tensor.prototype.erf = function () {\n        this.throwIfDisposed();\n        return ops.erf(this);\n    };\n    Tensor.prototype.round = function () {\n        this.throwIfDisposed();\n        return ops.round(this);\n    };\n    Tensor.prototype.step = function (alpha) {\n        if (alpha === void 0) { alpha = 0.0; }\n        this.throwIfDisposed();\n        return ops.step(this, alpha);\n    };\n    Tensor.prototype.softmax = function (dim) {\n        if (dim === void 0) { dim = -1; }\n        this.throwIfDisposed();\n        return ops.softmax(this, dim);\n    };\n    Tensor.prototype.resizeBilinear = function (newShape2D, alignCorners) {\n        if (alignCorners === void 0) { alignCorners = false; }\n        this.throwIfDisposed();\n        return ops.image.resizeBilinear(this, newShape2D, alignCorners);\n    };\n    Tensor.prototype.resizeNearestNeighbor = function (newShape2D, alignCorners) {\n        if (alignCorners === void 0) { alignCorners = false; }\n        this.throwIfDisposed();\n        return ops.image.resizeNearestNeighbor(this, newShape2D, alignCorners);\n    };\n    Tensor.prototype.conv1d = function (filter, stride, pad, dataFormat, dilation, dimRoundingMode) {\n        if (dataFormat === void 0) { dataFormat = 'NWC'; }\n        if (dilation === void 0) { dilation = 1; }\n        this.throwIfDisposed();\n        return ops.conv1d(this, filter, stride, pad, dataFormat, dilation, dimRoundingMode);\n    };\n    Tensor.prototype.conv2d = function (filter, strides, pad, dataFormat, dilations, dimRoundingMode) {\n        if (dataFormat === void 0) { dataFormat = 'NHWC'; }\n        if (dilations === void 0) { dilations = [1, 1]; }\n        this.throwIfDisposed();\n        return ops.conv2d(this, filter, strides, pad, dataFormat, dilations, dimRoundingMode);\n    };\n    Tensor.prototype.conv2dTranspose = function (filter, outputShape, strides, pad, dimRoundingMode) {\n        this.throwIfDisposed();\n        return ops.conv2dTranspose(this, filter, outputShape, strides, pad, dimRoundingMode);\n    };\n    Tensor.prototype.depthwiseConv2D = function (filter, strides, pad, dataFormat, dilations, dimRoundingMode) {\n        if (dataFormat === void 0) { dataFormat = 'NHWC'; }\n        if (dilations === void 0) { dilations = [1, 1]; }\n        this.throwIfDisposed();\n        return ops.depthwiseConv2d(this, filter, strides, pad, dataFormat, dilations, dimRoundingMode);\n    };\n    Tensor.prototype.avgPool = function (filterSize, strides, pad, dimRoundingMode) {\n        this.throwIfDisposed();\n        return ops.avgPool(this, filterSize, strides, pad, dimRoundingMode);\n    };\n    Tensor.prototype.maxPool = function (filterSize, strides, pad, dimRoundingMode) {\n        this.throwIfDisposed();\n        return ops.maxPool(this, filterSize, strides, pad, dimRoundingMode);\n    };\n    Tensor.prototype.localResponseNormalization = function (radius, bias, alpha, beta) {\n        if (radius === void 0) { radius = 5; }\n        if (bias === void 0) { bias = 1; }\n        if (alpha === void 0) { alpha = 1; }\n        if (beta === void 0) { beta = 0.5; }\n        return ops.localResponseNormalization(this, radius, bias, alpha, beta);\n    };\n    Tensor.prototype.variable = function (trainable, name, dtype) {\n        if (trainable === void 0) { trainable = true; }\n        this.throwIfDisposed();\n        return Variable.variable(this, trainable, name, dtype);\n    };\n    Tensor.prototype.unsortedSegmentSum = function (segmentIds, numSegments) {\n        this.throwIfDisposed();\n        return ops.unsortedSegmentSum(this, segmentIds, numSegments);\n    };\n    Tensor.nextId = 0;\n    __decorate([\n        doc_1.doc({ heading: 'Tensors', subheading: 'Classes' })\n    ], Tensor.prototype, \"flatten\", null);\n    __decorate([\n        doc_1.doc({ heading: 'Tensors', subheading: 'Classes' })\n    ], Tensor.prototype, \"asScalar\", null);\n    __decorate([\n        doc_1.doc({ heading: 'Tensors', subheading: 'Classes' })\n    ], Tensor.prototype, \"as1D\", null);\n    __decorate([\n        doc_1.doc({ heading: 'Tensors', subheading: 'Classes' })\n    ], Tensor.prototype, \"as2D\", null);\n    __decorate([\n        doc_1.doc({ heading: 'Tensors', subheading: 'Classes' })\n    ], Tensor.prototype, \"as3D\", null);\n    __decorate([\n        doc_1.doc({ heading: 'Tensors', subheading: 'Classes' })\n    ], Tensor.prototype, \"as4D\", null);\n    __decorate([\n        doc_1.doc({ heading: 'Tensors', subheading: 'Classes' })\n    ], Tensor.prototype, \"asType\", null);\n    __decorate([\n        doc_1.doc({ heading: 'Tensors', subheading: 'Classes' })\n    ], Tensor.prototype, \"buffer\", null);\n    __decorate([\n        doc_1.doc({ heading: 'Tensors', subheading: 'Classes' })\n    ], Tensor.prototype, \"data\", null);\n    __decorate([\n        doc_1.doc({ heading: 'Tensors', subheading: 'Classes' })\n    ], Tensor.prototype, \"dataSync\", null);\n    __decorate([\n        doc_1.doc({ heading: 'Tensors', subheading: 'Classes' })\n    ], Tensor.prototype, \"dispose\", null);\n    __decorate([\n        doc_1.doc({ heading: 'Tensors', subheading: 'Classes' })\n    ], Tensor.prototype, \"toFloat\", null);\n    __decorate([\n        doc_1.doc({ heading: 'Tensors', subheading: 'Classes' })\n    ], Tensor.prototype, \"toInt\", null);\n    __decorate([\n        doc_1.doc({ heading: 'Tensors', subheading: 'Classes' })\n    ], Tensor.prototype, \"toBool\", null);\n    __decorate([\n        doc_1.doc({ heading: 'Tensors', subheading: 'Classes' })\n    ], Tensor.prototype, \"print\", null);\n    __decorate([\n        doc_1.doc({ heading: 'Tensors', subheading: 'Classes' })\n    ], Tensor.prototype, \"reshape\", null);\n    __decorate([\n        doc_1.doc({ heading: 'Tensors', subheading: 'Classes' })\n    ], Tensor.prototype, \"reshapeAs\", null);\n    __decorate([\n        doc_1.doc({ heading: 'Tensors', subheading: 'Classes' })\n    ], Tensor.prototype, \"expandDims\", null);\n    __decorate([\n        doc_1.doc({ heading: 'Tensors', subheading: 'Classes' })\n    ], Tensor.prototype, \"cumsum\", null);\n    __decorate([\n        doc_1.doc({ heading: 'Tensors', subheading: 'Classes' })\n    ], Tensor.prototype, \"squeeze\", null);\n    __decorate([\n        doc_1.doc({ heading: 'Tensors', subheading: 'Classes' })\n    ], Tensor.prototype, \"clone\", null);\n    __decorate([\n        doc_1.doc({ heading: 'Tensors', subheading: 'Classes' })\n    ], Tensor.prototype, \"toString\", null);\n    Tensor = Tensor_1 = __decorate([\n        doc_1.doc({ heading: 'Tensors', subheading: 'Classes' })\n    ], Tensor);\n    return Tensor;\n    var Tensor_1;\n}());\nexports.Tensor = Tensor;\nvar Variable = (function (_super) {\n    __extends(Variable, _super);\n    function Variable(initialValue, trainable, name) {\n        if (trainable === void 0) { trainable = true; }\n        var _this = _super.call(this, initialValue.shape, initialValue.dtype, null, initialValue.dataId) || this;\n        _this.trainable = trainable;\n        _this.name = name;\n        if (_this.name == null) {\n            _this.name = Variable_1.nextVarId.toString();\n            Variable_1.nextVarId++;\n        }\n        environment_1.ENV.engine.registerVariable(_this);\n        return _this;\n    }\n    Variable_1 = Variable;\n    Variable.variable = function (initialValue, trainable, name, dtype) {\n        if (trainable === void 0) { trainable = true; }\n        if (dtype != null && dtype !== initialValue.dtype) {\n            initialValue = initialValue.asType(dtype);\n        }\n        return new Variable_1(initialValue, trainable, name);\n    };\n    Variable.prototype.assign = function (newValue) {\n        if (newValue.dtype !== this.dtype) {\n            throw new Error(\"dtype of the new value (\" + newValue.dtype + \") and \" +\n                (\"previous value (\" + this.dtype + \") must match\"));\n        }\n        if (!util.arraysEqual(newValue.shape, this.shape)) {\n            throw new Error(\"shape of the new value (\" + newValue.shape + \") and \" +\n                (\"previous value (\" + this.shape + \") must match\"));\n        }\n        environment_1.ENV.engine.disposeTensor(this);\n        this.dataId = newValue.dataId;\n        environment_1.ENV.engine.registerTensor(this);\n    };\n    Variable.nextVarId = 0;\n    __decorate([\n        doc_1.doc({ heading: 'Tensors', subheading: 'Classes' })\n    ], Variable.prototype, \"assign\", null);\n    __decorate([\n        doc_1.doc({ heading: 'Tensors', subheading: 'Creation' })\n    ], Variable, \"variable\", null);\n    Variable = Variable_1 = __decorate([\n        doc_1.doc({ heading: 'Tensors', subheading: 'Classes' })\n    ], Variable);\n    return Variable;\n    var Variable_1;\n}(Tensor));\nexports.Variable = Variable;\nvar variable = Variable.variable;\nexports.variable = variable;\nfunction computeStrides(shape) {\n    var rank = shape.length;\n    if (rank < 2) {\n        return [];\n    }\n    var strides = new Array(rank - 1);\n    strides[rank - 2] = shape[rank - 1];\n    for (var i = rank - 3; i >= 0; --i) {\n        strides[i] = strides[i + 1] * shape[i + 1];\n    }\n    return strides;\n}\n","map":{"version":3,"file":"tensor.js","sourceRoot":"","sources":["../src/tensor.ts"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAiBA,6BAA0B;AAC1B,6CAAkC;AAClC,+BAAiC;AACjC,2CAA6C;AAE7C,6BAA+B;AAe/B;IAME,sBAAY,KAAkB,EAAS,KAAe,EAAE,MAAkB;QAAnC,UAAK,GAAL,KAAK,CAAU;QACpD,EAAE,CAAC,CAAC,MAAM,IAAI,IAAI,CAAC,CAAC,CAAC;YACnB,IAAM,CAAC,GAAG,MAAM,CAAC,MAAM,CAAC;YACxB,IAAM,IAAI,GAAG,IAAI,CAAC,aAAa,CAAC,KAAK,CAAC,CAAC;YACvC,IAAI,CAAC,MAAM,CACP,CAAC,KAAK,IAAI,EACV,uBAAqB,CAAC,+BAA4B;iBAC9C,4BAA0B,IAAI,MAAG,CAAA,CAAC,CAAC;QAC7C,CAAC;QACD,IAAI,CAAC,KAAK,GAAG,KAAK,CAAC,KAAK,EAAE,CAAC;QAC3B,IAAI,CAAC,MAAM;YACP,MAAM,IAAI,IAAI,CAAC,sBAAsB,CAAC,KAAK,EAAE,IAAI,CAAC,aAAa,CAAC,KAAK,CAAC,CAAC,CAAC;QAC5E,IAAI,CAAC,OAAO,GAAG,cAAc,CAAC,KAAK,CAAC,CAAC;QACrC,IAAI,CAAC,IAAI,GAAG,IAAI,CAAC,aAAa,CAAC,KAAK,CAAC,CAAC;IACxC,CAAC;IASD,0BAAG,GAAH,UAAI,KAAa;QAAE,cAAiB;aAAjB,UAAiB,EAAjB,qBAAiB,EAAjB,IAAiB;YAAjB,6BAAiB;;QAClC,EAAE,CAAC,CAAC,IAAI,CAAC,MAAM,KAAK,CAAC,CAAC,CAAC,CAAC;YACtB,IAAI,GAAG,CAAC,CAAC,CAAC,CAAC;QACb,CAAC;QACD,IAAI,CAAC,MAAM,CACP,IAAI,CAAC,MAAM,KAAK,IAAI,CAAC,IAAI,EACzB,yCAAuC,IAAI,CAAC,MAAM,YAAS;aACvD,qBAAmB,IAAI,CAAC,IAAI,MAAG,CAAA,CAAC,CAAC;QACzC,IAAM,KAAK,GAAG,IAAI,CAAC,UAAU,CAAC,IAAI,CAAC,CAAC;QACpC,IAAI,CAAC,MAAM,CAAC,KAAK,CAAC,GAAG,KAAK,CAAC;IAC7B,CAAC;IAQD,0BAAG,GAAH;QAAI,cAAiB;aAAjB,UAAiB,EAAjB,qBAAiB,EAAjB,IAAiB;YAAjB,yBAAiB;;QACnB,EAAE,CAAC,CAAC,IAAI,CAAC,MAAM,KAAK,CAAC,CAAC,CAAC,CAAC;YACtB,IAAI,GAAG,CAAC,CAAC,CAAC,CAAC;QACb,CAAC;QACD,IAAI,KAAK,GAAG,IAAI,CAAC,IAAI,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC;QAClC,GAAG,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,IAAI,CAAC,MAAM,GAAG,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC;YACzC,KAAK,IAAI,IAAI,CAAC,OAAO,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,CAAC,CAAC,CAAC;QACrC,CAAC;QACD,MAAM,CAAC,IAAI,CAAC,MAAM,CAAC,KAAK,CAAC,CAAC;IAC5B,CAAC;IAED,iCAAU,GAAV,UAAW,IAAc;QACvB,EAAE,CAAC,CAAC,IAAI,CAAC,IAAI,KAAK,CAAC,CAAC,CAAC,CAAC;YACpB,MAAM,CAAC,CAAC,CAAC;QACX,CAAC;QAAC,IAAI,CAAC,EAAE,CAAC,CAAC,IAAI,CAAC,IAAI,KAAK,CAAC,CAAC,CAAC,CAAC;YAC3B,MAAM,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;QACjB,CAAC;QACD,IAAI,KAAK,GAAG,IAAI,CAAC,IAAI,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC;QAClC,GAAG,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,IAAI,CAAC,MAAM,GAAG,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC;YACzC,KAAK,IAAI,IAAI,CAAC,OAAO,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,CAAC,CAAC,CAAC;QACrC,CAAC;QACD,MAAM,CAAC,KAAK,CAAC;IACf,CAAC;IAED,iCAAU,GAAV,UAAW,KAAa;QACtB,EAAE,CAAC,CAAC,IAAI,CAAC,IAAI,KAAK,CAAC,CAAC,CAAC,CAAC;YACpB,MAAM,CAAC,EAAE,CAAC;QACZ,CAAC;QAAC,IAAI,CAAC,EAAE,CAAC,CAAC,IAAI,CAAC,IAAI,KAAK,CAAC,CAAC,CAAC,CAAC;YAC3B,MAAM,CAAC,CAAC,KAAK,CAAC,CAAC;QACjB,CAAC;QACD,IAAM,IAAI,GAAa,IAAI,KAAK,CAAC,IAAI,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC;QACpD,GAAG,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,IAAI,CAAC,MAAM,GAAG,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC;YACzC,IAAI,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,KAAK,CAAC,KAAK,GAAG,IAAI,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC;YAC9C,KAAK,IAAI,IAAI,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACrC,CAAC;QACD,IAAI,CAAC,IAAI,CAAC,MAAM,GAAG,CAAC,CAAC,GAAG,KAAK,CAAC;QAC9B,MAAM,CAAC,IAAI,CAAC;IACd,CAAC;IAED,sBAAI,8BAAI;aAAR;YACE,MAAM,CAAC,IAAI,CAAC,KAAK,CAAC,MAAM,CAAC;QAC3B,CAAC;;;OAAA;IAMD,+BAAQ,GAAR;QACE,MAAM,CAAC,MAAM,CAAC,IAAI,CAAC,IAAI,CAAC,KAAK,EAAE,EAAC,MAAM,EAAE,IAAI,CAAC,MAAM,EAAC,EAAE,IAAI,CAAC,KAAK,CAAC,CAAC;IACpE,CAAC;IAnED;QADC,SAAG,CAAC,EAAC,OAAO,EAAE,SAAS,EAAE,UAAU,EAAE,UAAU,EAAC,CAAC;2CAWjD;IAQD;QADC,SAAG,CAAC,EAAC,OAAO,EAAE,SAAS,EAAE,UAAU,EAAE,UAAU,EAAC,CAAC;2CAUjD;IAsCD;QADC,SAAG,CAAC,EAAC,OAAO,EAAE,SAAS,EAAE,UAAU,EAAE,UAAU,EAAC,CAAC;gDAGjD;IAhGU,YAAY;QADxB,SAAG,CAAC,EAAC,OAAO,EAAE,SAAS,EAAE,UAAU,EAAE,SAAS,EAAC,CAAC;OACpC,YAAY,CAiGxB;IAAD,mBAAC;CAAA,AAjGD,IAiGC;AAjGY,oCAAY;AAoHzB;IA0BE,gBACI,KAAkB,EAAE,KAAe,EAAE,MAAmB,EACxD,MAAe;QAsKX,uBAAkB,GAAG,KAAK,CAAC;QArKjC,IAAI,CAAC,IAAI,GAAG,IAAI,CAAC,aAAa,CAAC,KAAK,CAAC,CAAC;QACtC,EAAE,CAAC,CAAC,MAAM,IAAI,IAAI,CAAC,CAAC,CAAC;YACnB,IAAI,CAAC,MAAM,CACP,IAAI,CAAC,IAAI,KAAK,MAAM,CAAC,MAAM,EAC3B,mCAAiC,IAAI,CAAC,IAAI,wBAAqB;iBAC3D,uBAAqB,MAAM,CAAC,MAAM,MAAG,CAAA,CAAC,CAAC;QACjD,CAAC;QACD,IAAI,CAAC,KAAK,GAAG,KAAK,CAAC,KAAK,EAAE,CAAC;QAC3B,IAAI,CAAC,KAAK,GAAG,KAAK,IAAI,SAAS,CAAC;QAChC,IAAI,CAAC,OAAO,GAAG,cAAc,CAAC,KAAK,CAAC,CAAC;QACrC,IAAI,CAAC,MAAM,GAAG,MAAM,IAAI,IAAI,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC,CAAC,EAAE,CAAC;QAC3C,IAAI,CAAC,EAAE,GAAG,QAAM,CAAC,MAAM,EAAE,CAAC;QAC1B,IAAI,CAAC,QAAQ,GAAG,CAAC,IAAI,CAAC,IAAI,GAAG,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,QAAQ,EAAE,CAAC,CAAC,CAAC,QAAQ,CAAM,CAAC;QACvE,iBAAG,CAAC,MAAM,CAAC,cAAc,CAAC,IAAI,CAAC,CAAC;QAChC,EAAE,CAAC,CAAC,MAAM,IAAI,IAAI,CAAC,CAAC,CAAC;YACnB,iBAAG,CAAC,MAAM,CAAC,KAAK,CAAC,IAAI,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC;QACxC,CAAC;IACH,CAAC;eA9CU,MAAM;IAoDV,WAAI,GAAX,UAEI,KAAkB,EAAE,IAAgB,EAAE,KAAS;QACjD,MAAM,CAAC,IAAI,QAAM,CAAC,KAAK,EAAE,KAAK,EAAE,IAAI,CAAC,MAAM,EAAE,IAAI,CAAC,MAAM,CAAM,CAAC;IACjE,CAAC;IAID,wBAAO,GAAP;QACE,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,IAAI,CAAC,IAAI,EAAE,CAAC;IACrB,CAAC;IAID,yBAAQ,GAAR;QACE,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,IAAI,CAAC,MAAM,CAAC,IAAI,CAAC,IAAI,KAAK,CAAC,EAAE,qCAAqC,CAAC,CAAC;QACpE,MAAM,CAAC,IAAI,CAAC,OAAO,CAAU,EAAE,CAAC,CAAC;IACnC,CAAC;IAID,qBAAI,GAAJ;QACE,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,IAAI,CAAC,OAAO,CAAU,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC;IAC5C,CAAC;IASD,qBAAI,GAAJ,UAAK,IAAY,EAAE,OAAe;QAChC,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,IAAI,CAAC,OAAO,CAAU,CAAC,IAAI,EAAE,OAAO,CAAC,CAAC,CAAC;IAChD,CAAC;IAUD,qBAAI,GAAJ,UAAK,IAAY,EAAE,OAAe,EAAE,KAAa;QAC/C,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,IAAI,CAAC,OAAO,CAAU,CAAC,IAAI,EAAE,OAAO,EAAE,KAAK,CAAC,CAAC,CAAC;IACvD,CAAC;IAWD,qBAAI,GAAJ,UAAK,IAAY,EAAE,OAAe,EAAE,KAAa,EAAE,MAAc;QAC/D,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,IAAI,CAAC,OAAO,CAAU,CAAC,IAAI,EAAE,OAAO,EAAE,KAAK,EAAE,MAAM,CAAC,CAAC,CAAC;IAC/D,CAAC;IAQD,uBAAM,GAAN,UAAgC,KAAe;QAC7C,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,IAAI,CAAC,IAAI,EAAE,KAAK,CAAC,CAAC;IAC/B,CAAC;IAED,sBAAI,wBAAI;aAAR;YACE,MAAM,CAAC,IAAI,CAAC,KAAK,CAAC,MAAM,CAAC;QAC3B,CAAC;;;OAAA;IASD,oBAAG,GAAH;QAAI,cAAiB;aAAjB,UAAiB,EAAjB,qBAAiB,EAAjB,IAAiB;YAAjB,yBAAiB;;QACnB,IAAI,CAAC,MAAM,CACP,IAAI,CAAC,MAAM,KAAK,IAAI,CAAC,IAAI,EACzB,kEAAkE,CAAC,CAAC;QACxE,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,EAAE,CAAC,CAAC,IAAI,CAAC,MAAM,KAAK,CAAC,CAAC,CAAC,CAAC;YACtB,IAAI,GAAG,CAAC,CAAC,CAAC,CAAC;QACb,CAAC;QACD,IAAI,KAAK,GAAG,IAAI,CAAC,IAAI,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC;QAClC,GAAG,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,IAAI,CAAC,MAAM,GAAG,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC;YACzC,KAAK,IAAI,IAAI,CAAC,OAAO,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,CAAC,CAAC,CAAC;QACrC,CAAC;QACD,MAAM,CAAC,IAAI,CAAC,QAAQ,EAAE,CAAC,KAAK,CAAC,CAAC;IAChC,CAAC;IAID,uBAAM,GAAN;QACE,MAAM,CAAC,GAAG,CAAC,MAAM,CAAC,IAAI,CAAC,KAAK,EAAE,IAAI,CAAC,KAAK,EAAE,IAAI,CAAC,QAAQ,EAAE,CAAC,CAAC;IAC7D,CAAC;IAOK,qBAAI,GAAV;;;gBACE,IAAI,CAAC,eAAe,EAAE,CAAC;gBACvB,WAAO,iBAAG,CAAC,MAAM,CAAC,IAAI,CAAC,IAAI,CAAC,MAAM,CAAC,EAAC;;;KACrC;IAOD,yBAAQ,GAAR;QACE,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,iBAAG,CAAC,MAAM,CAAC,QAAQ,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC;IAC1C,CAAC;IAMD,wBAAO,GAAP;QACE,EAAE,CAAC,CAAC,IAAI,CAAC,UAAU,CAAC,CAAC,CAAC;YACpB,MAAM,CAAC;QACT,CAAC;QACD,iBAAG,CAAC,MAAM,CAAC,aAAa,CAAC,IAAI,CAAC,CAAC;QAC/B,IAAI,CAAC,kBAAkB,GAAG,IAAI,CAAC;IACjC,CAAC;IAGD,sBAAI,8BAAU;aAAd;YACE,MAAM,CAAC,IAAI,CAAC,kBAAkB,CAAC;QACjC,CAAC;;;OAAA;IAEO,gCAAe,GAAvB;QACE,EAAE,CAAC,CAAC,IAAI,CAAC,UAAU,CAAC,CAAC,CAAC;YACpB,MAAM,IAAI,KAAK,CAAC,qBAAqB,CAAC,CAAC;QACzC,CAAC;IACH,CAAC;IAID,wBAAO,GAAP;QACE,MAAM,CAAC,IAAI,CAAC,MAAM,CAAC,SAAS,CAAC,CAAC;IAChC,CAAC;IAID,sBAAK,GAAL;QACE,MAAM,CAAC,IAAI,CAAC,MAAM,CAAC,OAAO,CAAC,CAAC;IAC9B,CAAC;IAID,uBAAM,GAAN;QACE,MAAM,CAAC,IAAI,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC;IAC7B,CAAC;IASD,sBAAK,GAAL,UAAM,OAAe;QAAf,wBAAA,EAAA,eAAe;QACnB,MAAM,CAAC,GAAG,CAAC,KAAK,CAAC,IAAI,EAAE,OAAO,CAAC,CAAC;IAClC,CAAC;IASD,wBAAO,GAAP,UAAyB,QAAsB;QAC7C,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,OAAO,CAAC,IAAI,EAAE,QAAQ,CAAC,CAAC;IACrC,CAAC;IAQD,0BAAS,GAAT,UAA4B,CAAI;QAC9B,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,IAAI,CAAC,OAAO,CAAC,CAAC,CAAC,KAAK,CAAM,CAAC;IACpC,CAAC;IAUD,2BAAU,GAAV,UAA4B,IAAQ;QAAR,qBAAA,EAAA,QAAQ;QAClC,MAAM,CAAC,GAAG,CAAC,UAAU,CAAC,IAAI,EAAE,IAAI,CAAC,CAAC;IACpC,CAAC;IAcD,uBAAM,GAAN,UAAyB,IAAQ,EAAE,SAAiB,EAAE,OAAe;QAA5C,qBAAA,EAAA,QAAQ;QAAE,0BAAA,EAAA,iBAAiB;QAAE,wBAAA,EAAA,eAAe;QACnE,MAAM,CAAC,GAAG,CAAC,MAAM,CAAC,IAAI,EAAE,IAAI,EAAE,SAAS,EAAE,OAAO,CAAC,CAAC;IACpD,CAAC;IAWD,wBAAO,GAAP,UAA0B,IAAe;QACvC,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,OAAO,CAAC,IAAI,EAAE,IAAI,CAAC,CAAC;IACjC,CAAC;IAID,sBAAK,GAAL;QACE,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,KAAK,CAAC,IAAI,CAAC,CAAC;IACzB,CAAC;IAID,yBAAQ,GAAR,UAAS,OAAe;QAAf,wBAAA,EAAA,eAAe;QACtB,MAAM,CAAC,WAAW,CAAC,cAAc,CAAC,IAAI,EAAE,OAAO,CAAC,CAAC;IACnD,CAAC;IAKD,qBAAI,GAAJ,UAA8B,IAAc;QAC1C,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,IAAI,CAAC,IAAI,EAAE,IAAI,CAAC,CAAC;IAC9B,CAAC;IAED,uBAAM,GAAN,UAAgC,OAAiB,EAAE,IAAQ;QAAR,qBAAA,EAAA,QAAQ;QACzD,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,MAAM,CAAC,IAAI,EAAE,OAAO,EAAE,IAAI,CAAC,CAAC;IACzC,CAAC;IAED,uBAAM,GAAN,UAAO,CAAW,EAAE,UAAkB,EAAE,UAAkB;QAAtC,2BAAA,EAAA,kBAAkB;QAAE,2BAAA,EAAA,kBAAkB;QACxD,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,MAAM,CAAC,IAAgB,EAAE,CAAC,EAAE,UAAU,EAAE,UAAU,CAAC,CAAC;IACjE,CAAC;IACD,oBAAG,GAAH,UAAI,CAAS;QACX,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,GAAG,CAAC,IAAI,EAAE,CAAC,CAAC,CAAC;IAC1B,CAAC;IACD,qBAAI,GAAJ,UACI,GAA2C,EAAE,IAA4B,EACzE,QAAgB;QADhB,oBAAA,EAAA,iBAA2C;QAAE,qBAAA,EAAA,WAA4B;QACzE,yBAAA,EAAA,gBAAgB;QAClB,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,IAAI,CAAC,IAAI,EAAE,GAAG,EAAE,IAAI,EAAE,QAAQ,CAAC,CAAC;IAC7C,CAAC;IACD,sBAAK,GAAL,UACa,KAAsB,EAAE,IAAsB;QACzD,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,KAAK,CAAC,IAAI,EAAE,KAAK,EAAE,IAAI,CAAC,CAAC;IACtC,CAAC;IACD,wBAAO,GAAP,UAAmC,IAAsB;QACvD,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,OAAO,CAAC,IAAI,EAAE,IAAI,CAAC,CAAC;IACjC,CAAC;IACD,uBAAM,GAAN,UAAkC,CAAI,EAAE,IAAQ;QAAR,qBAAA,EAAA,QAAQ;QAC9C,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC,IAAI,EAAE,CAAC,CAAC,EAAE,IAAI,CAAC,CAAC;IACrC,CAAC;IACD,sBAAK,GAAL,UAAM,CAAS,EAAE,IAAQ;QAAR,qBAAA,EAAA,QAAQ;QACvB,MAAM,CAAC,GAAG,CAAC,KAAK,CAAC,CAAC,IAAI,EAAE,CAAC,CAAC,EAAE,IAAI,CAAC,CAAC;IACpC,CAAC;IACD,wBAAO,GAAP,UAAQ,CAAS,EAAE,IAAQ;QAAR,qBAAA,EAAA,QAAQ;QACzB,MAAM,CAAC,GAAG,CAAC,OAAO,CAAC,IAAI,EAAE,IAAI,CAAC,CAAC;IACjC,CAAC;IACD,oBAAG,GAAH,UACa,QAAiC,EAAE,aAAiB;QAAjB,8BAAA,EAAA,iBAAiB;QAC/D,MAAM,CAAC,GAAG,CAAC,GAAG,CAAC,IAAI,EAAE,QAAQ,EAAE,aAAa,CAAC,CAAC;IAChD,CAAC;IACD,mCAAkB,GAAlB,UACI,IAAwB,EAAE,QAA4B,EACtD,eAAsB,EAAE,KAA0B,EAClD,MAA2B;QAD3B,gCAAA,EAAA,sBAAsB;QAExB,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,kBAAkB,CACzB,IAAI,EAAE,IAAI,EAAE,QAAQ,EAAE,eAAe,EAAE,KAAK,EAAE,MAAM,CAAC,CAAC;IAC5D,CAAC;IAID,0BAAS,GAAT,UAA4B,IAA4B,EAAE,QAAgB;QAA9C,qBAAA,EAAA,WAA4B;QAAE,yBAAA,EAAA,gBAAgB;QAExE,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,SAAS,CAAC,IAAI,EAAE,IAAI,EAAE,QAAQ,CAAC,CAAC;IAC7C,CAAC;IACD,oBAAG,GAAH,UAAsB,IAA4B,EAAE,QAAgB;QAA9C,qBAAA,EAAA,WAA4B;QAAE,yBAAA,EAAA,gBAAgB;QAClE,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,GAAG,CAAC,IAAI,EAAE,IAAI,EAAE,QAAQ,CAAC,CAAC;IACvC,CAAC;IACD,qBAAI,GAAJ,UAAuB,IAA4B,EAAE,QAAgB;QAA9C,qBAAA,EAAA,WAA4B;QAAE,yBAAA,EAAA,gBAAgB;QACnE,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,IAAI,CAAC,IAAI,EAAE,IAAI,EAAE,QAAQ,CAAC,CAAC;IACxC,CAAC;IACD,oBAAG,GAAH,UAAsB,IAA4B,EAAE,QAAgB;QAA9C,qBAAA,EAAA,WAA4B;QAAE,yBAAA,EAAA,gBAAgB;QAClE,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,GAAG,CAAC,IAAI,EAAE,IAAI,EAAE,QAAQ,CAAC,CAAC;IACvC,CAAC;IACD,oBAAG,GAAH,UAAsB,IAA4B,EAAE,QAAgB;QAA9C,qBAAA,EAAA,WAA4B;QAAE,yBAAA,EAAA,gBAAgB;QAClE,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,GAAG,CAAC,IAAI,EAAE,IAAI,EAAE,QAAQ,CAAC,CAAC;IACvC,CAAC;IACD,uBAAM,GAAN,UAAyB,IAAmB;QAAnB,qBAAA,EAAA,WAAmB;QAC1C,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,MAAM,CAAC,IAAI,EAAE,IAAI,CAAC,CAAC;IAChC,CAAC;IACD,uBAAM,GAAN,UAAyB,IAAmB;QAAnB,qBAAA,EAAA,WAAmB;QAC1C,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,MAAM,CAAC,IAAI,EAAE,IAAI,CAAC,CAAC;IAChC,CAAC;IAGD,qBAAI,GAAJ,UAAqB,KAAe;QAClC,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,IAAI,CAAC,IAAS,EAAE,KAAK,CAAC,CAAC;IACpC,CAAC;IAID,oBAAG,GAAH,UAAsB,CAAS;QAC7B,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,GAAG,CAAC,IAAI,EAAE,CAAC,CAAC,CAAC;IAC1B,CAAC;IACD,0BAAS,GAAT,UAAmC,CAAI;QACrC,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,SAAS,CAAC,IAAI,EAAE,CAAC,CAAC,CAAC;IAChC,CAAC;IACD,oBAAG,GAAH,UAAsB,CAAS;QAC7B,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,GAAG,CAAC,IAAI,EAAE,CAAC,CAAC,CAAC;IAC1B,CAAC;IACD,0BAAS,GAAT,UAAmC,CAAI;QACrC,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,SAAS,CAAC,IAAI,EAAE,CAAC,CAAC,CAAC;IAChC,CAAC;IACD,oBAAG,GAAH,UAA+B,GAAW;QACxC,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,GAAG,CAAC,IAAI,EAAE,GAAG,CAAC,CAAC;IAC5B,CAAC;IACD,0BAAS,GAAT,UAAU,GAAW;QACnB,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,SAAS,CAAC,IAAI,EAAE,GAAG,CAAC,CAAC;IAClC,CAAC;IACD,oBAAG,GAAH,UAAsB,CAAS;QAC7B,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,GAAG,CAAC,IAAI,EAAE,CAAC,CAAC,CAAC;IAC1B,CAAC;IACD,0BAAS,GAAT,UAAmC,CAAI;QACrC,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,SAAS,CAAC,IAAI,EAAE,CAAC,CAAC,CAAC;IAChC,CAAC;IACD,oBAAG,GAAH,UAAsB,CAAS;QAC7B,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,GAAG,CAAC,IAAI,EAAE,CAAC,CAAC,CAAC;IAC1B,CAAC;IACD,yBAAQ,GAAR,UAA2B,CAAS;QAClC,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,QAAQ,CAAC,IAAI,EAAE,CAAC,CAAC,CAAC;IAC/B,CAAC;IACD,0BAAS,GAAT,UAAmC,CAAI;QACrC,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,SAAS,CAAC,IAAI,EAAE,CAAC,CAAC,CAAC;IAChC,CAAC;IACD,wBAAO,GAAP,UAA0B,CAAS;QACjC,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,OAAO,CAAC,IAAI,EAAE,CAAC,CAAC,CAAC;IAC9B,CAAC;IACD,8BAAa,GAAb,UAAuC,CAAI;QACzC,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,aAAa,CAAC,IAAI,EAAE,CAAC,CAAC,CAAC;IACpC,CAAC;IACD,wBAAO,GAAP,UAA0B,CAAS;QACjC,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,OAAO,CAAC,IAAI,EAAE,CAAC,CAAC,CAAC;IAC9B,CAAC;IACD,8BAAa,GAAb,UAAuC,CAAI;QACzC,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,aAAa,CAAC,IAAI,EAAE,CAAC,CAAC,CAAC;IACpC,CAAC;IACD,oBAAG,GAAH,UAAsB,CAAS;QAC7B,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,GAAG,CAAC,IAAI,EAAE,CAAC,CAAC,CAAC;IAC1B,CAAC;IACD,0BAAS,GAAT,UAAmC,CAAI;QACrC,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,SAAS,CAAC,IAAI,EAAE,CAAC,CAAC,CAAC;IAChC,CAAC;IACD,kCAAiB,GAAjB,UAAoC,CAAS;QAC3C,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,iBAAiB,CAAC,IAAI,EAAE,CAAC,CAAC,CAAC;IACxC,CAAC;IACD,wCAAuB,GAAvB,UAAiD,CAAI;QACnD,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,uBAAuB,CAAC,IAAI,EAAE,CAAC,CAAC,CAAC;IAC9C,CAAC;IACD,0BAAS,GAAT,UAAqC,IAAe;QAClD,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,SAAS,CAAC,IAAI,EAAE,IAAI,CAAC,CAAC;IACnC,CAAC;IAID,yBAAQ,GAAR,UAA2B,CAAS;QAClC,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,QAAQ,CAAC,IAAI,EAAE,CAAC,CAAC,CAAC;IAC/B,CAAC;IACD,+BAAc,GAAd,UAAwC,CAAI;QAC1C,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,cAAc,CAAC,IAAI,EAAE,CAAC,CAAC,CAAC;IACrC,CAAC;IACD,qBAAI,GAAJ,UAAuB,CAAS;QAC9B,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,IAAI,CAAC,IAAI,EAAE,CAAC,CAAC,CAAC;IAC3B,CAAC;IACD,2BAAU,GAAV,UAAoC,CAAI;QACtC,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,UAAU,CAAC,IAAI,EAAE,CAAC,CAAC,CAAC;IACjC,CAAC;IACD,sBAAK,GAAL,UAAwB,CAAS;QAC/B,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,KAAK,CAAC,IAAI,EAAE,CAAC,CAAC,CAAC;IAC5B,CAAC;IACD,4BAAW,GAAX,UAAqC,CAAI;QACvC,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,WAAW,CAAC,IAAI,EAAE,CAAC,CAAC,CAAC;IAClC,CAAC;IACD,0BAAS,GAAT,UAA4B,CAAS;QACnC,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,SAAS,CAAC,IAAI,EAAE,CAAC,CAAC,CAAC;IAChC,CAAC;IACD,gCAAe,GAAf,UAAyC,CAAI;QAC3C,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,eAAe,CAAC,IAAI,EAAE,CAAC,CAAC,CAAC;IACtC,CAAC;IACD,wBAAO,GAAP,UAA0B,CAAS;QACjC,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,OAAO,CAAC,IAAI,EAAE,CAAC,CAAC,CAAC;IAC9B,CAAC;IACD,8BAAa,GAAb,UAAuC,CAAI;QACzC,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,aAAa,CAAC,IAAI,EAAE,CAAC,CAAC,CAAC;IACpC,CAAC;IACD,6BAAY,GAAZ,UAA+B,CAAS;QACtC,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,YAAY,CAAC,IAAI,EAAE,CAAC,CAAC,CAAC;IACnC,CAAC;IACD,mCAAkB,GAAlB,UAA4C,CAAI;QAC9C,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,kBAAkB,CAAC,IAAI,EAAE,CAAC,CAAC,CAAC;IACzC,CAAC;IAGD,2BAAU,GAAV,UAAW,CAAS;QAClB,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,UAAU,CAAC,IAAI,EAAE,CAAC,CAAC,CAAC;IACjC,CAAC;IACD,0BAAS,GAAT,UAAU,CAAS;QACjB,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,SAAS,CAAC,IAAI,EAAE,CAAC,CAAC,CAAC;IAChC,CAAC;IACD,2BAAU,GAAV;QACE,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,UAAU,CAAC,IAAI,CAAC,CAAC;IAC9B,CAAC;IACD,2BAAU,GAAV,UAAW,CAAS;QAClB,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,UAAU,CAAC,IAAI,EAAE,CAAC,CAAC,CAAC;IACjC,CAAC;IACD,sBAAK,GAAL,UAAM,SAAiB,EAAE,CAAS;QAChC,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,KAAK,CAAC,SAAS,EAAE,IAAI,EAAE,CAAC,CAAC,CAAC;IACvC,CAAC;IAGD,oBAAG,GAAH;QACE,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC;IACvB,CAAC;IACD,qBAAI,GAAJ;QACE,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;IACxB,CAAC;IACD,sBAAK,GAAL;QACE,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,KAAK,CAAC,IAAI,CAAC,CAAC;IACzB,CAAC;IACD,qBAAI,GAAJ;QACE,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;IACxB,CAAC;IACD,oBAAG,GAAH;QACE,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC;IACvB,CAAC;IACD,sBAAK,GAAL;QACE,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,KAAK,CAAC,IAAI,CAAC,CAAC;IACzB,CAAC;IACD,oBAAG,GAAH;QACE,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC;IACvB,CAAC;IACD,sBAAK,GAAL;QACE,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,KAAK,CAAC,IAAI,CAAC,CAAC;IACzB,CAAC;IACD,qBAAI,GAAJ;QACE,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;IACxB,CAAC;IACD,sBAAK,GAAL;QACE,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,KAAK,CAAC,IAAI,CAAC,CAAC;IACzB,CAAC;IACD,uBAAM,GAAN;QACE,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,MAAM,CAAC,IAAI,CAAC,CAAC;IAC1B,CAAC;IACD,2BAAU,GAAV;QACE,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,UAAU,CAAC,IAAI,CAAC,CAAC;IAC9B,CAAC;IACD,oBAAG,GAAH;QACE,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC;IACvB,CAAC;IACD,4BAAW,GAAX,UAAY,GAAW,EAAE,GAAW;QAClC,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,WAAW,CAAC,IAAI,EAAE,GAAG,EAAE,GAAG,CAAC,CAAC;IACzC,CAAC;IACD,qBAAI,GAAJ;QACE,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;IACxB,CAAC;IACD,oBAAG,GAAH;QACE,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC;IACvB,CAAC;IACD,qBAAI,GAAJ;QACE,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;IACxB,CAAC;IACD,0BAAS,GAAT,UAAU,KAAW;QAAX,sBAAA,EAAA,WAAW;QACnB,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,SAAS,CAAC,IAAI,EAAE,KAAK,CAAC,CAAC;IACpC,CAAC;IACD,sBAAK,GAAL,UAAM,KAAgB;QACpB,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,KAAK,CAAC,IAAI,EAAE,KAAK,CAAC,CAAC;IAChC,CAAC;IACD,wBAAO,GAAP;QACE,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC;IAC3B,CAAC;IACD,2BAAU,GAAV;QACE,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,UAAU,CAAC,IAAI,CAAC,CAAC;IAC9B,CAAC;IACD,yBAAQ,GAAR;QACE,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,QAAQ,CAAC,IAAI,CAAC,CAAC;IAC5B,CAAC;IACD,oBAAG,GAAH;QACE,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC;IACvB,CAAC;IACD,oBAAG,GAAH;QACE,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC;IACvB,CAAC;IACD,oBAAG,GAAH;QACE,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC;IACvB,CAAC;IACD,qBAAI,GAAJ;QACE,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;IACxB,CAAC;IACD,qBAAI,GAAJ;QACE,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;IACxB,CAAC;IACD,qBAAI,GAAJ;QACE,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;IACxB,CAAC;IACD,qBAAI,GAAJ;QACE,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;IACxB,CAAC;IACD,qBAAI,GAAJ;QACE,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;IACxB,CAAC;IACD,qBAAI,GAAJ;QACE,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;IACxB,CAAC;IACD,sBAAK,GAAL;QACE,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,KAAK,CAAC,IAAI,CAAC,CAAC;IACzB,CAAC;IACD,sBAAK,GAAL;QACE,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,KAAK,CAAC,IAAI,CAAC,CAAC;IACzB,CAAC;IACD,sBAAK,GAAL;QACE,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,KAAK,CAAC,IAAI,CAAC,CAAC;IACzB,CAAC;IACD,oBAAG,GAAH;QACE,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC;IACvB,CAAC;IACD,sBAAK,GAAL;QACE,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,KAAK,CAAC,IAAI,CAAC,CAAC;IACzB,CAAC;IACD,qBAAI,GAAJ,UAAgC,KAAW;QAAX,sBAAA,EAAA,WAAW;QACzC,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,IAAI,CAAC,IAAI,EAAE,KAAK,CAAC,CAAC;IAC/B,CAAC;IACD,wBAAO,GAAP,UAAiC,GAAQ;QAAR,oBAAA,EAAA,OAAO,CAAC;QACvC,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,OAAO,CAAC,IAAI,EAAE,GAAG,CAAC,CAAC;IAChC,CAAC;IAGD,+BAAc,GAAd,UACa,UAA4B,EAAE,YAAoB;QAApB,6BAAA,EAAA,oBAAoB;QAC5D,IAAe,CAAC,eAAe,EAAE,CAAC;QACnC,MAAM,CAAC,GAAG,CAAC,KAAK,CAAC,cAAc,CAAC,IAAI,EAAE,UAAU,EAAE,YAAY,CAAC,CAAC;IAClE,CAAC;IAED,sCAAqB,GAArB,UACa,UAA4B,EAAE,YAAoB;QAApB,6BAAA,EAAA,oBAAoB;QAC5D,IAAe,CAAC,eAAe,EAAE,CAAC;QACnC,MAAM,CAAC,GAAG,CAAC,KAAK,CAAC,qBAAqB,CAAC,IAAI,EAAE,UAAU,EAAE,YAAY,CAAC,CAAC;IACzE,CAAC;IAGD,uBAAM,GAAN,UACa,MAAgB,EAAE,MAAc,EAAE,GAA0B,EACrE,UAA+B,EAAE,QAAY,EAC7C,eAAwC;QADxC,2BAAA,EAAA,kBAA+B;QAAE,yBAAA,EAAA,YAAY;QAE9C,IAAe,CAAC,eAAe,EAAE,CAAC;QACnC,MAAM,CAAC,GAAG,CAAC,MAAM,CACb,IAAI,EAAE,MAAM,EAAE,MAAM,EAAE,GAAG,EAAE,UAAU,EAAE,QAAQ,EAAE,eAAe,CAAC,CAAC;IACxE,CAAC;IACD,uBAAM,GAAN,UACa,MAAgB,EAAE,OAAgC,EAC3D,GAA0B,EAAE,UAAkC,EAC9D,SAA2C,EAC3C,eAAwC;QAFZ,2BAAA,EAAA,mBAAkC;QAC9D,0BAAA,EAAA,aAAsC,CAAC,EAAE,CAAC,CAAC;QAE5C,IAAe,CAAC,eAAe,EAAE,CAAC;QACnC,MAAM,CAAC,GAAG,CAAC,MAAM,CACb,IAAI,EAAE,MAAM,EAAE,OAAO,EAAE,GAAG,EAAE,UAAU,EAAE,SAAS,EAAE,eAAe,CAAC,CAAC;IAC1E,CAAC;IACD,gCAAe,GAAf,UACa,MAAgB,EACzB,WAAsE,EACtE,OAAgC,EAAE,GAA0B,EAC5D,eAAwC;QACzC,IAAe,CAAC,eAAe,EAAE,CAAC;QACnC,MAAM,CAAC,GAAG,CAAC,eAAe,CACtB,IAAI,EAAE,MAAM,EAAE,WAAW,EAAE,OAAO,EAAE,GAAG,EAAE,eAAe,CAAC,CAAC;IAChE,CAAC;IACD,gCAAe,GAAf,UACa,MAAgB,EAAE,OAAgC,EAC3D,GAA0B,EAAE,UAAkC,EAC9D,SAA2C,EAC3C,eAAwC;QAFZ,2BAAA,EAAA,mBAAkC;QAC9D,0BAAA,EAAA,aAAsC,CAAC,EAAE,CAAC,CAAC;QAE5C,IAAe,CAAC,eAAe,EAAE,CAAC;QACnC,MAAM,CAAC,GAAG,CAAC,eAAe,CACtB,IAAI,EAAE,MAAM,EAAE,OAAO,EAAE,GAAG,EAAE,UAAU,EAAE,SAAS,EAAE,eAAe,CAAC,CAAC;IAC1E,CAAC;IAGD,wBAAO,GAAP,UACa,UAAmC,EAC5C,OAAgC,EAAE,GAA0B,EAC5D,eAAwC;QACzC,IAAe,CAAC,eAAe,EAAE,CAAC;QACnC,MAAM,CAAC,GAAG,CAAC,OAAO,CAAC,IAAI,EAAE,UAAU,EAAE,OAAO,EAAE,GAAG,EAAE,eAAe,CAAC,CAAC;IACtE,CAAC;IACD,wBAAO,GAAP,UACa,UAAmC,EAC5C,OAAgC,EAAE,GAA0B,EAC5D,eAAwC;QACzC,IAAe,CAAC,eAAe,EAAE,CAAC;QACnC,MAAM,CAAC,GAAG,CAAC,OAAO,CAAC,IAAI,EAAE,UAAU,EAAE,OAAO,EAAE,GAAG,EAAE,eAAe,CAAC,CAAC;IACtE,CAAC;IACD,2CAA0B,GAA1B,UACa,MAAU,EAAE,IAAQ,EAAE,KAAS,EAAE,IAAU;QAA3C,uBAAA,EAAA,UAAU;QAAE,qBAAA,EAAA,QAAQ;QAAE,sBAAA,EAAA,SAAS;QAAE,qBAAA,EAAA,UAAU;QACtD,MAAM,CAAC,GAAG,CAAC,0BAA0B,CAAC,IAAI,EAAE,MAAM,EAAE,IAAI,EAAE,KAAK,EAAE,IAAI,CAAC,CAAC;IACzE,CAAC;IAED,yBAAQ,GAAR,UAAS,SAAgB,EAAE,IAAa,EAAE,KAAgB;QAAjD,0BAAA,EAAA,gBAAgB;QACvB,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,QAAQ,CAAC,QAAQ,CAAC,IAAI,EAAE,SAAS,EAAE,IAAI,EAAE,KAAK,CAAC,CAAC;IACzD,CAAC;IAED,mCAAkB,GAAlB,UACa,UAAoB,EAAE,WAAmB;QACpD,IAAI,CAAC,eAAe,EAAE,CAAC;QACvB,MAAM,CAAC,GAAG,CAAC,kBAAkB,CAAC,IAAI,EAAE,UAAU,EAAE,WAAW,CAAC,CAAC;IAC/D,CAAC;IA7xBc,aAAM,GAAG,CAAC,CAAC;IA2D1B;QADC,SAAG,CAAC,EAAC,OAAO,EAAE,SAAS,EAAE,UAAU,EAAE,SAAS,EAAC,CAAC;yCAIhD;IAID;QADC,SAAG,CAAC,EAAC,OAAO,EAAE,SAAS,EAAE,UAAU,EAAE,SAAS,EAAC,CAAC;0CAKhD;IAID;QADC,SAAG,CAAC,EAAC,OAAO,EAAE,SAAS,EAAE,UAAU,EAAE,SAAS,EAAC,CAAC;sCAIhD;IASD;QADC,SAAG,CAAC,EAAC,OAAO,EAAE,SAAS,EAAE,UAAU,EAAE,SAAS,EAAC,CAAC;sCAIhD;IAUD;QADC,SAAG,CAAC,EAAC,OAAO,EAAE,SAAS,EAAE,UAAU,EAAE,SAAS,EAAC,CAAC;sCAIhD;IAWD;QADC,SAAG,CAAC,EAAC,OAAO,EAAE,SAAS,EAAE,UAAU,EAAE,SAAS,EAAC,CAAC;sCAIhD;IAQD;QADC,SAAG,CAAC,EAAC,OAAO,EAAE,SAAS,EAAE,UAAU,EAAE,SAAS,EAAC,CAAC;wCAIhD;IA8BD;QADC,SAAG,CAAC,EAAC,OAAO,EAAE,SAAS,EAAE,UAAU,EAAE,SAAS,EAAC,CAAC;wCAGhD;IAOD;QADC,SAAG,CAAC,EAAC,OAAO,EAAE,SAAS,EAAE,UAAU,EAAE,SAAS,EAAC,CAAC;sCAIhD;IAOD;QADC,SAAG,CAAC,EAAC,OAAO,EAAE,SAAS,EAAE,UAAU,EAAE,SAAS,EAAC,CAAC;0CAIhD;IAMD;QADC,SAAG,CAAC,EAAC,OAAO,EAAE,SAAS,EAAE,UAAU,EAAE,SAAS,EAAC,CAAC;yCAOhD;IAeD;QADC,SAAG,CAAC,EAAC,OAAO,EAAE,SAAS,EAAE,UAAU,EAAE,SAAS,EAAC,CAAC;yCAGhD;IAID;QADC,SAAG,CAAC,EAAC,OAAO,EAAE,SAAS,EAAE,UAAU,EAAE,SAAS,EAAC,CAAC;uCAGhD;IAID;QADC,SAAG,CAAC,EAAC,OAAO,EAAE,SAAS,EAAE,UAAU,EAAE,SAAS,EAAC,CAAC;wCAGhD;IASD;QADC,SAAG,CAAC,EAAC,OAAO,EAAE,SAAS,EAAE,UAAU,EAAE,SAAS,EAAC,CAAC;uCAGhD;IASD;QADC,SAAG,CAAC,EAAC,OAAO,EAAE,SAAS,EAAE,UAAU,EAAE,SAAS,EAAC,CAAC;yCAIhD;IAQD;QADC,SAAG,CAAC,EAAC,OAAO,EAAE,SAAS,EAAE,UAAU,EAAE,SAAS,EAAC,CAAC;2CAIhD;IAUD;QADC,SAAG,CAAC,EAAC,OAAO,EAAE,SAAS,EAAE,UAAU,EAAE,SAAS,EAAC,CAAC;4CAGhD;IAcD;QADC,SAAG,CAAC,EAAC,OAAO,EAAE,SAAS,EAAE,UAAU,EAAE,SAAS,EAAC,CAAC;wCAGhD;IAWD;QADC,SAAG,CAAC,EAAC,OAAO,EAAE,SAAS,EAAE,UAAU,EAAE,SAAS,EAAC,CAAC;yCAIhD;IAID;QADC,SAAG,CAAC,EAAC,OAAO,EAAE,SAAS,EAAE,UAAU,EAAE,SAAS,EAAC,CAAC;uCAIhD;IAID;QADC,SAAG,CAAC,EAAC,OAAO,EAAE,SAAS,EAAE,UAAU,EAAE,SAAS,EAAC,CAAC;0CAGhD;IAtTU,MAAM;QADlB,SAAG,CAAC,EAAC,OAAO,EAAE,SAAS,EAAE,UAAU,EAAE,SAAS,EAAC,CAAC;OACpC,MAAM,CA+xBlB;IAAD,aAAC;;CAAA,AA/xBD,IA+xBC;AA/xBY,wBAAM;AAkzBnB;IAAqD,4BAAS;IAS5D,kBACI,YAAuB,EAAS,SAAgB,EAAE,IAAa;QAA/B,0BAAA,EAAA,gBAAgB;QADpD,YAEE,kBACI,YAAY,CAAC,KAAK,EAAE,YAAY,CAAC,KAAK,EAAE,IAAI,EAC5C,YAAY,CAAC,MAAM,CAAC,SAOzB;QAVmC,eAAS,GAAT,SAAS,CAAO;QAIlD,KAAI,CAAC,IAAI,GAAG,IAAI,CAAC;QACjB,EAAE,CAAC,CAAC,KAAI,CAAC,IAAI,IAAI,IAAI,CAAC,CAAC,CAAC;YACtB,KAAI,CAAC,IAAI,GAAG,UAAQ,CAAC,SAAS,CAAC,QAAQ,EAAE,CAAC;YAC1C,UAAQ,CAAC,SAAS,EAAE,CAAC;QACvB,CAAC;QACD,iBAAG,CAAC,MAAM,CAAC,gBAAgB,CAAC,KAAI,CAAC,CAAC;;IACpC,CAAC;iBApBU,QAAQ;IAqCZ,iBAAQ,GAAf,UACI,YAAuB,EAAE,SAAgB,EAAE,IAAa,EACxD,KAAgB;QADS,0BAAA,EAAA,gBAAgB;QAE3C,EAAE,CAAC,CAAC,KAAK,IAAI,IAAI,IAAI,KAAK,KAAK,YAAY,CAAC,KAAK,CAAC,CAAC,CAAC;YAClD,YAAY,GAAG,YAAY,CAAC,MAAM,CAAC,KAAK,CAAc,CAAC;QACzD,CAAC;QACD,MAAM,CAAC,IAAI,UAAQ,CAAC,YAAY,EAAE,SAAS,EAAE,IAAI,CAAC,CAAC;IACrD,CAAC;IASD,yBAAM,GAAN,UAAO,QAAmB;QACxB,EAAE,CAAC,CAAC,QAAQ,CAAC,KAAK,KAAK,IAAI,CAAC,KAAK,CAAC,CAAC,CAAC;YAClC,MAAM,IAAI,KAAK,CACX,6BAA2B,QAAQ,CAAC,KAAK,WAAQ;iBACjD,qBAAmB,IAAI,CAAC,KAAK,iBAAc,CAAA,CAAC,CAAC;QACnD,CAAC;QACD,EAAE,CAAC,CAAC,CAAC,IAAI,CAAC,WAAW,CAAC,QAAQ,CAAC,KAAK,EAAE,IAAI,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;YAClD,MAAM,IAAI,KAAK,CACX,6BAA2B,QAAQ,CAAC,KAAK,WAAQ;iBACjD,qBAAmB,IAAI,CAAC,KAAK,iBAAc,CAAA,CAAC,CAAC;QACnD,CAAC;QACD,iBAAG,CAAC,MAAM,CAAC,aAAa,CAAC,IAAI,CAAC,CAAC;QAC/B,IAAI,CAAC,MAAM,GAAG,QAAQ,CAAC,MAAM,CAAC;QAC9B,iBAAG,CAAC,MAAM,CAAC,cAAc,CAAC,IAAI,CAAC,CAAC;IAClC,CAAC;IAlEc,kBAAS,GAAG,CAAC,CAAC;IAoD7B;QADC,SAAG,CAAC,EAAC,OAAO,EAAE,SAAS,EAAE,UAAU,EAAE,SAAS,EAAC,CAAC;0CAehD;IA9BD;QADC,SAAG,CAAC,EAAC,OAAO,EAAE,SAAS,EAAE,UAAU,EAAE,UAAU,EAAC,CAAC;kCAQjD;IA5CU,QAAQ;QADpB,SAAG,CAAC,EAAC,OAAO,EAAE,SAAS,EAAE,UAAU,EAAE,SAAS,EAAC,CAAC;OACpC,QAAQ,CAoEpB;IAAD,eAAC;;CAAA,AApED,CAAqD,MAAM,GAoE1D;AApEY,4BAAQ;AAsErB,IAAM,QAAQ,GAAG,QAAQ,CAAC,QAAQ,CAAC;AAC3B,4BAAQ;AAEhB,wBAAwB,KAAe;IACrC,IAAM,IAAI,GAAG,KAAK,CAAC,MAAM,CAAC;IAC1B,EAAE,CAAC,CAAC,IAAI,GAAG,CAAC,CAAC,CAAC,CAAC;QACb,MAAM,CAAC,EAAE,CAAC;IACZ,CAAC;IAID,IAAM,OAAO,GAAG,IAAI,KAAK,CAAC,IAAI,GAAG,CAAC,CAAC,CAAC;IACpC,OAAO,CAAC,IAAI,GAAG,CAAC,CAAC,GAAG,KAAK,CAAC,IAAI,GAAG,CAAC,CAAC,CAAC;IACpC,GAAG,CAAC,CAAC,IAAI,CAAC,GAAG,IAAI,GAAG,CAAC,EAAE,CAAC,IAAI,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC;QACnC,OAAO,CAAC,CAAC,CAAC,GAAG,OAAO,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,KAAK,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC;IAC7C,CAAC;IACD,MAAM,CAAC,OAAO,CAAC;AACjB,CAAC","sourcesContent":["/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {doc} from './doc';\nimport {ENV} from './environment';\nimport * as ops from './ops/ops';\nimport * as tensor_util from './tensor_util';\nimport {DataType, Rank, ShapeMap, TypedArray} from './types';\nimport * as util from './util';\n\n/** @hidden */\nexport interface TensorData {\n  dataId?: DataId;\n  values?: TypedArray;\n}\n\n/**\n * A mutable object, similar to `Tensor`, that allows users to set values\n * at locations before converting to an immutable `Tensor`.\n *\n * See `buffer` for creating a tensor buffer.\n */\n@doc({heading: 'Tensors', subheading: 'Classes'})\nexport class TensorBuffer<R extends Rank> {\n  size: number;\n  shape: ShapeMap[R];\n  strides: number[];\n  values: TypedArray;\n\n  constructor(shape: ShapeMap[R], public dtype: DataType, values: TypedArray) {\n    if (values != null) {\n      const n = values.length;\n      const size = util.sizeFromShape(shape);\n      util.assert(\n          n === size,\n          `Length of values '${n}' does not match the size ` +\n              `inferred by the shape '${size}'`);\n    }\n    this.shape = shape.slice();\n    this.values =\n        values || util.getTypedArrayFromDType(dtype, util.sizeFromShape(shape));\n    this.strides = computeStrides(shape);\n    this.size = util.sizeFromShape(shape);\n  }\n\n  /**\n   * Sets a value in the buffer at a given location.\n   *\n   * @param value The value to set.\n   * @param locs  The location indices.\n   */\n  @doc({heading: 'Tensors', subheading: 'Creation'})\n  set(value: number, ...locs: number[]) {\n    if (locs.length === 0) {\n      locs = [0];\n    }\n    util.assert(\n        locs.length === this.rank,\n        `The number of provided coordinates (${locs.length}) must ` +\n            `match the rank (${this.rank})`);\n    const index = this.locToIndex(locs);\n    this.values[index] = value;\n  }\n\n  /**\n   * Returns the value in the buffer at the provided location.\n   *\n   * @param locs The location indices.\n   */\n  @doc({heading: 'Tensors', subheading: 'Creation'})\n  get(...locs: number[]): number {\n    if (locs.length === 0) {\n      locs = [0];\n    }\n    let index = locs[locs.length - 1];\n    for (let i = 0; i < locs.length - 1; ++i) {\n      index += this.strides[i] * locs[i];\n    }\n    return this.values[index];\n  }\n\n  locToIndex(locs: number[]): number {\n    if (this.rank === 0) {\n      return 0;\n    } else if (this.rank === 1) {\n      return locs[0];\n    }\n    let index = locs[locs.length - 1];\n    for (let i = 0; i < locs.length - 1; ++i) {\n      index += this.strides[i] * locs[i];\n    }\n    return index;\n  }\n\n  indexToLoc(index: number): number[] {\n    if (this.rank === 0) {\n      return [];\n    } else if (this.rank === 1) {\n      return [index];\n    }\n    const locs: number[] = new Array(this.shape.length);\n    for (let i = 0; i < locs.length - 1; ++i) {\n      locs[i] = Math.floor(index / this.strides[i]);\n      index -= locs[i] * this.strides[i];\n    }\n    locs[locs.length - 1] = index;\n    return locs;\n  }\n\n  get rank() {\n    return this.shape.length;\n  }\n\n  /**\n   * Creates an immutable `Tensor` object from the buffer.\n   */\n  @doc({heading: 'Tensors', subheading: 'Creation'})\n  toTensor(): Tensor<R> {\n    return Tensor.make(this.shape, {values: this.values}, this.dtype);\n  }\n}\n\n/**\n * We wrap data id since we use weak map to avoid memory leaks.\n * Since we have our own memory management, we have a reference counter\n * mapping a tensor to its data, so there is always a pointer (even if that\n * data is otherwise garbage collectable).\n * See https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/\n * Global_Objects/WeakMap\n */\nexport type DataId = object;  // object instead of {} to force non-primitive.\n\n/**\n * A `Tensor` object represents an immutable, multidimensional array of numbers\n * that has a shape and a data type.\n *\n * See `tensor` for details on how to create a `Tensor`.\n */\n@doc({heading: 'Tensors', subheading: 'Classes'})\nexport class Tensor<R extends Rank = Rank> {\n  private static nextId = 0;\n\n  /** Unique id of this tensor. */\n  readonly id: number;\n  /**\n   * Id of the bucket holding the data for this tensor. Multiple arrays can\n   * point to the same bucket (e.g. when calling array.reshape()).\n   */\n  dataId: DataId;\n  /** The shape of the tensor. */\n  readonly shape: ShapeMap[R];\n  /** Number of elements in the tensor. */\n  readonly size: number;\n  /** The data type for the array. */\n  readonly dtype: DataType;\n  /** The rank type for the array (see `Rank` enum). */\n  readonly rankType: R;\n\n  /**\n   * Number of elements to skip in each dimension when indexing. See\n   * https://docs.scipy.org/doc/numpy/reference/generated/\\\n   * numpy.ndarray.strides.html\n   */\n  readonly strides: number[];\n\n  protected constructor(\n      shape: ShapeMap[R], dtype: DataType, values?: TypedArray,\n      dataId?: DataId) {\n    this.size = util.sizeFromShape(shape);\n    if (values != null) {\n      util.assert(\n          this.size === values.length,\n          `Constructing tensor of shape (${this.size}) should match the ` +\n              `length of values (${values.length})`);\n    }\n    this.shape = shape.slice();\n    this.dtype = dtype || 'float32';\n    this.strides = computeStrides(shape);\n    this.dataId = dataId != null ? dataId : {};\n    this.id = Tensor.nextId++;\n    this.rankType = (this.rank < 5 ? this.rank.toString() : 'higher') as R;\n    ENV.engine.registerTensor(this);\n    if (values != null) {\n      ENV.engine.write(this.dataId, values);\n    }\n  }\n\n  /**\n   * Makes a new tensor with the provided shape and values. Values should be in\n   * a flat array.\n   */\n  static make<T extends Tensor<R>, D extends DataType = 'float32',\n                                             R extends Rank = Rank>(\n      shape: ShapeMap[R], data: TensorData, dtype?: D): T {\n    return new Tensor(shape, dtype, data.values, data.dataId) as T;\n  }\n\n  /** Flatten a Tensor to a 1D array. */\n  @doc({heading: 'Tensors', subheading: 'Classes'})\n  flatten(): Tensor1D {\n    this.throwIfDisposed();\n    return this.as1D();\n  }\n\n  /** Converts a size-1 `Tensor` to a `Scalar`. */\n  @doc({heading: 'Tensors', subheading: 'Classes'})\n  asScalar(): Scalar {\n    this.throwIfDisposed();\n    util.assert(this.size === 1, 'The array must have only 1 element.');\n    return this.reshape<Rank.R0>([]);\n  }\n\n  /** Converts a `Tensor` to a `Tensor1D`. */\n  @doc({heading: 'Tensors', subheading: 'Classes'})\n  as1D(): Tensor1D {\n    this.throwIfDisposed();\n    return this.reshape<Rank.R1>([this.size]);\n  }\n\n  /**\n   * Converts a `Tensor` to a `Tensor2D`.\n   *\n   * @param rows Number of rows in `Tensor2D`.\n   * @param columns Number of columns in `Tensor2D`.\n   */\n  @doc({heading: 'Tensors', subheading: 'Classes'})\n  as2D(rows: number, columns: number): Tensor2D {\n    this.throwIfDisposed();\n    return this.reshape<Rank.R2>([rows, columns]);\n  }\n\n  /**\n   * Converts a `Tensor` to a `Tensor3D`.\n   *\n   * @param rows Number of rows in `Tensor3D`.\n   * @param columns Number of columns in `Tensor3D`.\n   * @param depth Depth of `Tensor3D`.\n   */\n  @doc({heading: 'Tensors', subheading: 'Classes'})\n  as3D(rows: number, columns: number, depth: number): Tensor3D {\n    this.throwIfDisposed();\n    return this.reshape<Rank.R3>([rows, columns, depth]);\n  }\n\n  /**\n   * Converts a `Tensor` to a `Tensor4D`.\n   *\n   * @param rows Number of rows in `Tensor4D`.\n   * @param columns Number of columns in `Tensor4D`.\n   * @param depth Depth of `Tensor4D`.\n   * @param depth2 4th dimension of `Tensor4D`.\n   */\n  @doc({heading: 'Tensors', subheading: 'Classes'})\n  as4D(rows: number, columns: number, depth: number, depth2: number): Tensor4D {\n    this.throwIfDisposed();\n    return this.reshape<Rank.R4>([rows, columns, depth, depth2]);\n  }\n\n  /**\n   * Casts a `Tensor` to a specified dtype.\n   *\n   * @param dtype Data-type to cast the tensor to.\n   */\n  @doc({heading: 'Tensors', subheading: 'Classes'})\n  asType<T extends this>(this: T, dtype: DataType): T {\n    this.throwIfDisposed();\n    return ops.cast(this, dtype);\n  }\n\n  get rank(): number {\n    return this.shape.length;\n  }\n\n  /**\n   * Returns the value in the tensor at the provided location.\n   * If using WebGL backend, this is a blocking call.\n   * Prefer calling the `async data()[flatIndex]` method instead.\n   *\n   * @param locs The location indices.\n   */\n  get(...locs: number[]) {\n    util.assert(\n        locs.length === this.rank,\n        'Number of coordinates in get() must match the rank of the tensor');\n    this.throwIfDisposed();\n    if (locs.length === 0) {\n      locs = [0];\n    }\n    let index = locs[locs.length - 1];\n    for (let i = 0; i < locs.length - 1; ++i) {\n      index += this.strides[i] * locs[i];\n    }\n    return this.dataSync()[index];\n  }\n\n  /** Returns a `TensorBuffer` that holds the underlying data. */\n  @doc({heading: 'Tensors', subheading: 'Classes'})\n  buffer(): TensorBuffer<R> {\n    return ops.buffer(this.shape, this.dtype, this.dataSync());\n  }\n\n  /**\n   * Asynchronously downloads the values from the `Tensor`. Returns a promise of\n   * `TypedArray` that resolves when the computation has finished.\n   */\n  @doc({heading: 'Tensors', subheading: 'Classes'})\n  async data(): Promise<TypedArray> {\n    this.throwIfDisposed();\n    return ENV.engine.read(this.dataId);\n  }\n\n  /**\n   * Synchronously downloads the values from the `Tensor`. This blocks the UI\n   * thread until the values are ready, which can cause performance issues.\n   */\n  @doc({heading: 'Tensors', subheading: 'Classes'})\n  dataSync(): TypedArray {\n    this.throwIfDisposed();\n    return ENV.engine.readSync(this.dataId);\n  }\n\n  /**\n   * Disposes `Tensor` from memory.\n   */\n  @doc({heading: 'Tensors', subheading: 'Classes'})\n  dispose(): void {\n    if (this.isDisposed) {\n      return;\n    }\n    ENV.engine.disposeTensor(this);\n    this.isDisposedInternal = true;\n  }\n\n  private isDisposedInternal = false;\n  get isDisposed(): boolean {\n    return this.isDisposedInternal;\n  }\n\n  private throwIfDisposed() {\n    if (this.isDisposed) {\n      throw new Error(`Tensor is disposed.`);\n    }\n  }\n\n  /** Casts the array to type `float32` */\n  @doc({heading: 'Tensors', subheading: 'Classes'})\n  toFloat<T extends this>(this: T): T {\n    return this.asType('float32');\n  }\n\n  /** Casts the array to type `int32` */\n  @doc({heading: 'Tensors', subheading: 'Classes'})\n  toInt() {\n    return this.asType('int32');\n  }\n\n  /** Casts the array to type `bool` */\n  @doc({heading: 'Tensors', subheading: 'Classes'})\n  toBool() {\n    return this.asType('bool');\n  }\n\n  /**\n   * Prints the `Tensor`. See `print` for details.\n   *\n   * @param verbose Whether to print verbose information about the tensor,\n   *    including dtype and size.\n   */\n  @doc({heading: 'Tensors', subheading: 'Classes'})\n  print(verbose = false): void {\n    return ops.print(this, verbose);\n  }\n\n  /**\n   * Reshapes the tensor into the provided shape.\n   * See `reshape` for more details.\n   *\n   * @param newShape An array of integers defining the output tensor shape.\n   */\n  @doc({heading: 'Tensors', subheading: 'Classes'})\n  reshape<R2 extends Rank>(newShape: ShapeMap[R2]): Tensor<R2> {\n    this.throwIfDisposed();\n    return ops.reshape(this, newShape);\n  }\n\n  /**\n   * Reshapes the tensor into the shape of the provided tensor.\n   *\n   * @param x The tensor of required shape.\n   */\n  @doc({heading: 'Tensors', subheading: 'Classes'})\n  reshapeAs<T extends Tensor>(x: T): T {\n    this.throwIfDisposed();\n    return this.reshape(x.shape) as T;\n  }\n\n  /**\n   * Returns a `Tensor` that has expanded rank, by inserting a dimension\n   * into the tensor's shape. See `expandDims` for details.\n   *\n   * @param axis The dimension index at which to insert shape of 1. Defaults to\n   *    0 (the first dimension).\n   */\n  @doc({heading: 'Tensors', subheading: 'Classes'})\n  expandDims<R2 extends Rank>(axis = 0): Tensor<R2> {\n    return ops.expandDims(this, axis);\n  }\n\n  /**\n   * Returns the cumulative sum of the `Tensor` along `axis`.\n   *\n   * @param axis The axis along which to sum. Optional. Defaults to 0.\n   * @param exclusive Whether to perform exclusive cumulative sum. Defaults to\n   *    false. If set to true then the sum of each tensor entry does not include\n   *    its own value, but only the values previous to it along the specified\n   *    axis.\n   * @param reverse Whether to sum in the opposite direction. Defaults to\n   *    false.\n   */\n  @doc({heading: 'Tensors', subheading: 'Classes'})\n  cumsum<T extends Tensor>(axis = 0, exclusive = false, reverse = false): T {\n    return ops.cumsum(this, axis, exclusive, reverse);\n  }\n\n  /**\n   * Returns a `Tensor` with dimensions of size 1 removed from the shape.\n   * See `squeeze` for more details.\n   *\n   * @param axis A list of numbers. If specified, only squeezes the\n   *    dimensions listed. The dimension index starts at 0. It is an error to\n   *    squeeze a dimension that is not 1.\n   */\n  @doc({heading: 'Tensors', subheading: 'Classes'})\n  squeeze<T extends Tensor>(axis?: number[]): T {\n    this.throwIfDisposed();\n    return ops.squeeze(this, axis);\n  }\n\n  /** Returns a copy of the tensor. See `clone` for details. */\n  @doc({heading: 'Tensors', subheading: 'Classes'})\n  clone<T extends Tensor>(this: T): T {\n    this.throwIfDisposed();\n    return ops.clone(this);\n  }\n\n  /** Returns a human-readable description of the tensor. Useful for logging. */\n  @doc({heading: 'Tensors', subheading: 'Classes'})\n  toString(verbose = false): string {\n    return tensor_util.tensorToString(this, verbose);\n  }\n\n  // Below is chain API that is not exposed to docs to avoid repetition. To\n  // expose a method, move it above this comment and add @doc and jsdoc.\n\n  tile<T extends this>(this: T, reps: number[]): T {\n    this.throwIfDisposed();\n    return ops.tile(this, reps);\n  }\n\n  gather<T extends this>(this: T, indices: Tensor1D, axis = 0): T {\n    this.throwIfDisposed();\n    return ops.gather(this, indices, axis);\n  }\n\n  matMul(b: Tensor2D, transposeA = false, transposeB = false): Tensor2D {\n    this.throwIfDisposed();\n    return ops.matMul(this as Tensor2D, b, transposeA, transposeB);\n  }\n  dot(b: Tensor): Tensor {\n    this.throwIfDisposed();\n    return ops.dot(this, b);\n  }\n  norm(\n      ord: number|'euclidean'|'fro' = 'euclidean', axis: number|number[] = null,\n      keepDims = false): Tensor {\n    this.throwIfDisposed();\n    return ops.norm(this, ord, axis, keepDims);\n  }\n  slice<T extends Tensor<R>>(\n      this: T, begin: number|number[], size?: number|number[]): T {\n    this.throwIfDisposed();\n    return ops.slice(this, begin, size);\n  }\n  reverse<T extends Tensor>(this: T, axis?: number|number[]): T {\n    this.throwIfDisposed();\n    return ops.reverse(this, axis);\n  }\n  concat<T extends Tensor>(this: T, x: T, axis = 0): T {\n    this.throwIfDisposed();\n    return ops.concat([this, x], axis);\n  }\n  stack(x: Tensor, axis = 0): Tensor {\n    return ops.stack([this, x], axis);\n  }\n  unstack(x: Tensor, axis = 0): Tensor[] {\n    return ops.unstack(this, axis);\n  }\n  pad<T extends Tensor>(\n      this: T, paddings: Array<[number, number]>, constantValue = 0): T {\n    return ops.pad(this, paddings, constantValue);\n  }\n  batchNormalization(\n      mean: Tensor<R>|Tensor1D, variance: Tensor<R>|Tensor1D,\n      varianceEpsilon = .001, scale?: Tensor<R>|Tensor1D,\n      offset?: Tensor<R>|Tensor1D): Tensor<R> {\n    this.throwIfDisposed();\n    return ops.batchNormalization(\n        this, mean, variance, varianceEpsilon, scale, offset);\n  }\n\n  // Reduction ops.\n\n  logSumExp<T extends Tensor>(axis: number|number[] = null, keepDims = false):\n      T {\n    this.throwIfDisposed();\n    return ops.logSumExp(this, axis, keepDims);\n  }\n  sum<T extends Tensor>(axis: number|number[] = null, keepDims = false): T {\n    this.throwIfDisposed();\n    return ops.sum(this, axis, keepDims);\n  }\n  mean<T extends Tensor>(axis: number|number[] = null, keepDims = false): T {\n    this.throwIfDisposed();\n    return ops.mean(this, axis, keepDims);\n  }\n  min<T extends Tensor>(axis: number|number[] = null, keepDims = false): T {\n    this.throwIfDisposed();\n    return ops.min(this, axis, keepDims);\n  }\n  max<T extends Tensor>(axis: number|number[] = null, keepDims = false): T {\n    this.throwIfDisposed();\n    return ops.max(this, axis, keepDims);\n  }\n  argMin<T extends Tensor>(axis: number = null): T {\n    this.throwIfDisposed();\n    return ops.argMin(this, axis);\n  }\n  argMax<T extends Tensor>(axis: number = null): T {\n    this.throwIfDisposed();\n    return ops.argMax(this, axis);\n  }\n\n  // Transformations\n  cast<T extends this>(dtype: DataType): T {\n    this.throwIfDisposed();\n    return ops.cast(this as T, dtype);\n  }\n\n  // Binary ops.\n\n  add<T extends Tensor>(x: Tensor): T {\n    this.throwIfDisposed();\n    return ops.add(this, x);\n  }\n  addStrict<T extends this>(this: T, x: T): T {\n    this.throwIfDisposed();\n    return ops.addStrict(this, x);\n  }\n  sub<T extends Tensor>(x: Tensor): T {\n    this.throwIfDisposed();\n    return ops.sub(this, x);\n  }\n  subStrict<T extends this>(this: T, x: T): T {\n    this.throwIfDisposed();\n    return ops.subStrict(this, x);\n  }\n  pow<T extends Tensor>(this: T, exp: Tensor): T {\n    this.throwIfDisposed();\n    return ops.pow(this, exp);\n  }\n  powStrict(exp: Tensor): Tensor<R> {\n    this.throwIfDisposed();\n    return ops.powStrict(this, exp);\n  }\n  mul<T extends Tensor>(x: Tensor): T {\n    this.throwIfDisposed();\n    return ops.mul(this, x);\n  }\n  mulStrict<T extends this>(this: T, x: T): T {\n    this.throwIfDisposed();\n    return ops.mulStrict(this, x);\n  }\n  div<T extends Tensor>(x: Tensor): T {\n    this.throwIfDisposed();\n    return ops.div(this, x);\n  }\n  floorDiv<T extends Tensor>(x: Tensor): T {\n    this.throwIfDisposed();\n    return ops.floorDiv(this, x);\n  }\n  divStrict<T extends this>(this: T, x: T): T {\n    this.throwIfDisposed();\n    return ops.divStrict(this, x);\n  }\n  minimum<T extends Tensor>(x: Tensor): T {\n    this.throwIfDisposed();\n    return ops.minimum(this, x);\n  }\n  minimumStrict<T extends this>(this: T, x: T): T {\n    this.throwIfDisposed();\n    return ops.minimumStrict(this, x);\n  }\n  maximum<T extends Tensor>(x: Tensor): T {\n    this.throwIfDisposed();\n    return ops.maximum(this, x);\n  }\n  maximumStrict<T extends this>(this: T, x: T): T {\n    this.throwIfDisposed();\n    return ops.maximumStrict(this, x);\n  }\n  mod<T extends Tensor>(x: Tensor): T {\n    this.throwIfDisposed();\n    return ops.mod(this, x);\n  }\n  modStrict<T extends this>(this: T, x: T): T {\n    this.throwIfDisposed();\n    return ops.modStrict(this, x);\n  }\n  squaredDifference<T extends Tensor>(x: Tensor): T {\n    this.throwIfDisposed();\n    return ops.squaredDifference(this, x);\n  }\n  squaredDifferenceStrict<T extends this>(this: T, x: T): T {\n    this.throwIfDisposed();\n    return ops.squaredDifferenceStrict(this, x);\n  }\n  transpose<T extends Tensor>(this: T, perm?: number[]): T {\n    this.throwIfDisposed();\n    return ops.transpose(this, perm);\n  }\n\n  // Compare ops.\n\n  notEqual<T extends Tensor>(x: Tensor): T {\n    this.throwIfDisposed();\n    return ops.notEqual(this, x);\n  }\n  notEqualStrict<T extends this>(this: T, x: T): T {\n    this.throwIfDisposed();\n    return ops.notEqualStrict(this, x);\n  }\n  less<T extends Tensor>(x: Tensor): T {\n    this.throwIfDisposed();\n    return ops.less(this, x);\n  }\n  lessStrict<T extends this>(this: T, x: T): T {\n    this.throwIfDisposed();\n    return ops.lessStrict(this, x);\n  }\n  equal<T extends Tensor>(x: Tensor): T {\n    this.throwIfDisposed();\n    return ops.equal(this, x);\n  }\n  equalStrict<T extends this>(this: T, x: T): T {\n    this.throwIfDisposed();\n    return ops.equalStrict(this, x);\n  }\n  lessEqual<T extends Tensor>(x: Tensor): T {\n    this.throwIfDisposed();\n    return ops.lessEqual(this, x);\n  }\n  lessEqualStrict<T extends this>(this: T, x: T): T {\n    this.throwIfDisposed();\n    return ops.lessEqualStrict(this, x);\n  }\n  greater<T extends Tensor>(x: Tensor): T {\n    this.throwIfDisposed();\n    return ops.greater(this, x);\n  }\n  greaterStrict<T extends this>(this: T, x: T): T {\n    this.throwIfDisposed();\n    return ops.greaterStrict(this, x);\n  }\n  greaterEqual<T extends Tensor>(x: Tensor): T {\n    this.throwIfDisposed();\n    return ops.greaterEqual(this, x);\n  }\n  greaterEqualStrict<T extends this>(this: T, x: T): T {\n    this.throwIfDisposed();\n    return ops.greaterEqualStrict(this, x);\n  }\n\n  // Compare ops.\n  logicalAnd(x: Tensor): Tensor {\n    this.throwIfDisposed();\n    return ops.logicalAnd(this, x);\n  }\n  logicalOr(x: Tensor): Tensor {\n    this.throwIfDisposed();\n    return ops.logicalOr(this, x);\n  }\n  logicalNot<T extends Tensor>(this: T): T {\n    this.throwIfDisposed();\n    return ops.logicalNot(this);\n  }\n  logicalXor(x: Tensor): Tensor {\n    this.throwIfDisposed();\n    return ops.logicalXor(this, x);\n  }\n  where(condition: Tensor, x: Tensor): Tensor {\n    this.throwIfDisposed();\n    return ops.where(condition, this, x);\n  }\n\n  // Unary ops.\n  neg<T extends Tensor>(this: T): T {\n    this.throwIfDisposed();\n    return ops.neg(this);\n  }\n  ceil<T extends Tensor>(this: T): T {\n    this.throwIfDisposed();\n    return ops.ceil(this);\n  }\n  floor<T extends Tensor>(this: T): T {\n    this.throwIfDisposed();\n    return ops.floor(this);\n  }\n  sign<T extends Tensor>(this: T): T {\n    this.throwIfDisposed();\n    return ops.sign(this);\n  }\n  exp<T extends Tensor>(this: T): T {\n    this.throwIfDisposed();\n    return ops.exp(this);\n  }\n  expm1<T extends Tensor>(this: T): T {\n    this.throwIfDisposed();\n    return ops.expm1(this);\n  }\n  log<T extends Tensor>(this: T): T {\n    this.throwIfDisposed();\n    return ops.log(this);\n  }\n  log1p<T extends Tensor>(this: T): T {\n    this.throwIfDisposed();\n    return ops.log1p(this);\n  }\n  sqrt<T extends Tensor>(this: T): T {\n    this.throwIfDisposed();\n    return ops.sqrt(this);\n  }\n  rsqrt<T extends Tensor>(this: T): T {\n    this.throwIfDisposed();\n    return ops.rsqrt(this);\n  }\n  square<T extends Tensor>(this: T): T {\n    this.throwIfDisposed();\n    return ops.square(this);\n  }\n  reciprocal<T extends Tensor>(this: T): T {\n    this.throwIfDisposed();\n    return ops.reciprocal(this);\n  }\n  abs<T extends Tensor>(this: T): T {\n    this.throwIfDisposed();\n    return ops.abs(this);\n  }\n  clipByValue(min: number, max: number): Tensor<R> {\n    this.throwIfDisposed();\n    return ops.clipByValue(this, min, max);\n  }\n  relu<T extends Tensor>(this: T): T {\n    this.throwIfDisposed();\n    return ops.relu(this);\n  }\n  elu<T extends Tensor>(this: T): T {\n    this.throwIfDisposed();\n    return ops.elu(this);\n  }\n  selu<T extends Tensor>(this: T): T {\n    this.throwIfDisposed();\n    return ops.selu(this);\n  }\n  leakyRelu(alpha = 0.2): Tensor<R> {\n    this.throwIfDisposed();\n    return ops.leakyRelu(this, alpha);\n  }\n  prelu(alpha: Tensor<R>): Tensor<R> {\n    this.throwIfDisposed();\n    return ops.prelu(this, alpha);\n  }\n  sigmoid<T extends Tensor>(this: T): T {\n    this.throwIfDisposed();\n    return ops.sigmoid(this);\n  }\n  logSigmoid<T extends Tensor>(this: T): T {\n    this.throwIfDisposed();\n    return ops.logSigmoid(this);\n  }\n  softplus<T extends Tensor>(this: T): T {\n    this.throwIfDisposed();\n    return ops.softplus(this);\n  }\n  sin<T extends Tensor>(this: T): T {\n    this.throwIfDisposed();\n    return ops.sin(this);\n  }\n  cos<T extends Tensor>(this: T): T {\n    this.throwIfDisposed();\n    return ops.cos(this);\n  }\n  tan<T extends Tensor>(this: T): T {\n    this.throwIfDisposed();\n    return ops.tan(this);\n  }\n  asin<T extends Tensor>(this: T): T {\n    this.throwIfDisposed();\n    return ops.asin(this);\n  }\n  acos<T extends Tensor>(this: T): T {\n    this.throwIfDisposed();\n    return ops.acos(this);\n  }\n  atan<T extends Tensor>(this: T): T {\n    this.throwIfDisposed();\n    return ops.atan(this);\n  }\n  sinh<T extends Tensor>(this: T): T {\n    this.throwIfDisposed();\n    return ops.sinh(this);\n  }\n  cosh<T extends Tensor>(this: T): T {\n    this.throwIfDisposed();\n    return ops.cosh(this);\n  }\n  tanh<T extends Tensor>(this: T): T {\n    this.throwIfDisposed();\n    return ops.tanh(this);\n  }\n  asinh<T extends Tensor>(this: T): T {\n    this.throwIfDisposed();\n    return ops.asinh(this);\n  }\n  acosh<T extends Tensor>(this: T): T {\n    this.throwIfDisposed();\n    return ops.acosh(this);\n  }\n  atanh<T extends Tensor>(this: T): T {\n    this.throwIfDisposed();\n    return ops.atanh(this);\n  }\n  erf<T extends Tensor>(this: T): T {\n    this.throwIfDisposed();\n    return ops.erf(this);\n  }\n  round<T extends Tensor>(this: T): T {\n    this.throwIfDisposed();\n    return ops.round(this);\n  }\n  step<T extends Tensor>(this: T, alpha = 0.0): T {\n    this.throwIfDisposed();\n    return ops.step(this, alpha);\n  }\n  softmax<T extends this>(this: T, dim = -1): T {\n    this.throwIfDisposed();\n    return ops.softmax(this, dim);\n  }\n\n  // Image ops.\n  resizeBilinear<T extends Tensor3D|Tensor4D>(\n      this: T, newShape2D: [number, number], alignCorners = false): T {\n    (this as Tensor).throwIfDisposed();\n    return ops.image.resizeBilinear(this, newShape2D, alignCorners);\n  }\n\n  resizeNearestNeighbor<T extends Tensor3D|Tensor4D>(\n      this: T, newShape2D: [number, number], alignCorners = false): T {\n    (this as Tensor).throwIfDisposed();\n    return ops.image.resizeNearestNeighbor(this, newShape2D, alignCorners);\n  }\n\n  // Convolutions.\n  conv1d<T extends Tensor2D|Tensor3D>(\n      this: T, filter: Tensor3D, stride: number, pad: 'valid'|'same'|number,\n      dataFormat: 'NWC'|'NCW' = 'NWC', dilation = 1,\n      dimRoundingMode?: 'floor'|'round'|'ceil'): T {\n    (this as Tensor).throwIfDisposed();\n    return ops.conv1d(\n        this, filter, stride, pad, dataFormat, dilation, dimRoundingMode);\n  }\n  conv2d<T extends Tensor3D|Tensor4D>(\n      this: T, filter: Tensor4D, strides: [number, number]|number,\n      pad: 'valid'|'same'|number, dataFormat: 'NHWC'|'NCHW' = 'NHWC',\n      dilations: [number, number]|number = [1, 1],\n      dimRoundingMode?: 'floor'|'round'|'ceil'): T {\n    (this as Tensor).throwIfDisposed();\n    return ops.conv2d(\n        this, filter, strides, pad, dataFormat, dilations, dimRoundingMode);\n  }\n  conv2dTranspose<T extends Tensor3D|Tensor4D>(\n      this: T, filter: Tensor4D,\n      outputShape: [number, number, number, number]|[number, number, number],\n      strides: [number, number]|number, pad: 'valid'|'same'|number,\n      dimRoundingMode?: 'floor'|'round'|'ceil'): T {\n    (this as Tensor).throwIfDisposed();\n    return ops.conv2dTranspose(\n        this, filter, outputShape, strides, pad, dimRoundingMode);\n  }\n  depthwiseConv2D<T extends Tensor3D|Tensor4D>(\n      this: T, filter: Tensor4D, strides: [number, number]|number,\n      pad: 'valid'|'same'|number, dataFormat: 'NHWC'|'NCHW' = 'NHWC',\n      dilations: [number, number]|number = [1, 1],\n      dimRoundingMode?: 'floor'|'round'|'ceil'): T {\n    (this as Tensor).throwIfDisposed();\n    return ops.depthwiseConv2d(\n        this, filter, strides, pad, dataFormat, dilations, dimRoundingMode);\n  }\n\n  // Pooling.\n  avgPool<T extends Tensor3D|Tensor4D>(\n      this: T, filterSize: [number, number]|number,\n      strides: [number, number]|number, pad: 'valid'|'same'|number,\n      dimRoundingMode?: 'floor'|'round'|'ceil'): T {\n    (this as Tensor).throwIfDisposed();\n    return ops.avgPool(this, filterSize, strides, pad, dimRoundingMode);\n  }\n  maxPool<T extends Tensor3D|Tensor4D>(\n      this: T, filterSize: [number, number]|number,\n      strides: [number, number]|number, pad: 'valid'|'same'|number,\n      dimRoundingMode?: 'floor'|'round'|'ceil'): T {\n    (this as Tensor).throwIfDisposed();\n    return ops.maxPool(this, filterSize, strides, pad, dimRoundingMode);\n  }\n  localResponseNormalization<T extends Tensor3D|Tensor4D>(\n      this: T, radius = 5, bias = 1, alpha = 1, beta = 0.5): T {\n    return ops.localResponseNormalization(this, radius, bias, alpha, beta);\n  }\n\n  variable(trainable = true, name?: string, dtype?: DataType): Variable<R> {\n    this.throwIfDisposed();\n    return Variable.variable(this, trainable, name, dtype);\n  }\n\n  unsortedSegmentSum<T extends Tensor>(\n      this: T, segmentIds: Tensor1D, numSegments: number): T {\n    this.throwIfDisposed();\n    return ops.unsortedSegmentSum(this, segmentIds, numSegments);\n  }\n}\n\n/** @doclink Tensor */\nexport type Scalar = Tensor<Rank.R0>;\n/** @doclink Tensor */\nexport type Tensor1D = Tensor<Rank.R1>;\n/** @doclink Tensor */\nexport type Tensor2D = Tensor<Rank.R2>;\n/** @doclink Tensor */\nexport type Tensor3D = Tensor<Rank.R3>;\n/** @doclink Tensor */\nexport type Tensor4D = Tensor<Rank.R4>;\n/** @doclink Tensor */\nexport type Tensor5D = Tensor<Rank.R5>;\n\n/**\n * A mutable `Tensor`, useful for persisting state, e.g. for training.\n */\n@doc({heading: 'Tensors', subheading: 'Classes'})\nexport class Variable<R extends Rank = Rank> extends Tensor<R> {\n  private static nextVarId = 0;\n  name: string;\n\n  /**\n   * Private constructor since we can not add logic before calling `super()`.\n   * Instead, we expose static `Variable.variable` method below, which will be\n   * added to global namespace.\n   */\n  private constructor(\n      initialValue: Tensor<R>, public trainable = true, name?: string) {\n    super(\n        initialValue.shape, initialValue.dtype, null /* values */,\n        initialValue.dataId);\n    this.name = name;\n    if (this.name == null) {\n      this.name = Variable.nextVarId.toString();\n      Variable.nextVarId++;\n    }\n    ENV.engine.registerVariable(this);\n  }\n\n  /**\n   * Creates a new variable with the provided initial value.\n   * ```js\n   * const x = tf.variable(tf.tensor([1, 2, 3]));\n   * x.assign(tf.tensor([4, 5, 6]));\n   *\n   * x.print();\n   * ```\n   *\n   * @param initialValue Initial value for the tensor.\n   * @param trainable If true, optimizers are allowed to update it.\n   * @param name Name of the variable. Defaults to a unique id.\n   * @param dtype If set, initialValue will be converted to the given type.\n   */\n  @doc({heading: 'Tensors', subheading: 'Creation'})\n  static variable<R extends Rank>(\n      initialValue: Tensor<R>, trainable = true, name?: string,\n      dtype?: DataType): Variable<R> {\n    if (dtype != null && dtype !== initialValue.dtype) {\n      initialValue = initialValue.asType(dtype) as Tensor<R>;\n    }\n    return new Variable(initialValue, trainable, name);\n  }\n\n  /**\n   * Assign a new `Tensor` to this variable. The new `Tensor` must have the\n   * same shape and dtype as the old `Tensor`.\n   *\n   * @param newValue New tensor to be assigned to this variable.\n   */\n  @doc({heading: 'Tensors', subheading: 'Classes'})\n  assign(newValue: Tensor<R>): void {\n    if (newValue.dtype !== this.dtype) {\n      throw new Error(\n          `dtype of the new value (${newValue.dtype}) and ` +\n          `previous value (${this.dtype}) must match`);\n    }\n    if (!util.arraysEqual(newValue.shape, this.shape)) {\n      throw new Error(\n          `shape of the new value (${newValue.shape}) and ` +\n          `previous value (${this.shape}) must match`);\n    }\n    ENV.engine.disposeTensor(this);\n    this.dataId = newValue.dataId;\n    ENV.engine.registerTensor(this);\n  }\n}\n\nconst variable = Variable.variable;\nexport {variable};\n\nfunction computeStrides(shape: number[]): number[] {\n  const rank = shape.length;\n  if (rank < 2) {\n    return [];\n  }\n\n  // Last dimension has implicit stride of 1, thus having D-1 (instead of D)\n  // strides.\n  const strides = new Array(rank - 1);\n  strides[rank - 2] = shape[rank - 1];\n  for (let i = rank - 3; i >= 0; --i) {\n    strides[i] = strides[i + 1] * shape[i + 1];\n  }\n  return strides;\n}\n"]}},"hash":"1d94992dcd86b065816e116615072aff","cacheData":{"env":{}}}