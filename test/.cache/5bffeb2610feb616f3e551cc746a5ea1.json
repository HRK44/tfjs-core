{"dependencies":[{"name":"/usr/local/google/home/nsthorat/deeplearnjs-clients/float16/tfjs-core/test/package.json","includedInParent":true,"mtime":1528810356568},{"name":"/usr/local/google/home/nsthorat/deeplearnjs-clients/float16/tfjs-core/test/.babelrc","includedInParent":true,"mtime":1525096773813},{"name":"/usr/local/google/home/nsthorat/deeplearnjs-clients/float16/tfjs-core/tsconfig.json","includedInParent":true,"mtime":1528810356568},{"name":"../doc","loc":{"line":9,"column":20}},{"name":"../util","loc":{"line":10,"column":19}},{"name":"./axis_util","loc":{"line":11,"column":24}},{"name":"./operation","loc":{"line":12,"column":26}},{"name":"./ops","loc":{"line":13,"column":18}}],"generated":{"js":"\"use strict\";\nvar __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {\n    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;\n    if (typeof Reflect === \"object\" && typeof Reflect.decorate === \"function\") r = Reflect.decorate(decorators, target, key, desc);\n    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;\n    return c > 3 && r && Object.defineProperty(target, key, r), r;\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar doc_1 = require(\"../doc\");\nvar util = require(\"../util\");\nvar axis_util = require(\"./axis_util\");\nvar operation_1 = require(\"./operation\");\nvar ops = require(\"./ops\");\nvar NormOps = (function () {\n    function NormOps() {\n    }\n    NormOps.norm = function (x, ord, axis, keepDims) {\n        if (ord === void 0) { ord = 'euclidean'; }\n        if (axis === void 0) { axis = null; }\n        if (keepDims === void 0) { keepDims = false; }\n        util.assertArgumentsAreTensors({ x: x }, 'norm');\n        var norm = normImpl(x, ord, axis);\n        var keepDimsShape = norm.shape;\n        if (keepDims) {\n            var axes = axis_util.parseAxisParam(axis, x.shape);\n            keepDimsShape = axis_util.expandShapeToKeepDim(norm.shape, axes);\n        }\n        return norm.reshape(keepDimsShape);\n    };\n    __decorate([\n        doc_1.doc({ heading: 'Operations', subheading: 'Matrices' }),\n        operation_1.operation\n    ], NormOps, \"norm\", null);\n    return NormOps;\n}());\nexports.NormOps = NormOps;\nfunction normImpl(x, p, axis) {\n    if (axis === void 0) { axis = null; }\n    if (x.rank === 0) {\n        return x.abs();\n    }\n    if (x.rank !== 1 && axis === null) {\n        return normImpl(x.reshape([-1]), p, axis);\n    }\n    if (x.rank === 1 || typeof axis === 'number' ||\n        axis instanceof Array && axis.length === 1) {\n        if (p === 1) {\n            return x.abs().sum(axis);\n        }\n        if (p === Infinity) {\n            return x.abs().max(axis);\n        }\n        if (p === -Infinity) {\n            return x.abs().min(axis);\n        }\n        if (p === 'euclidean' || p === 2) {\n            return x.abs().pow(ops.scalar(2, 'int32')).sum(axis).sqrt();\n        }\n        throw new Error(\"Error in norm: invalid ord value: \" + p);\n    }\n    if (axis instanceof Array && axis.length === 2) {\n        if (p === 1) {\n            return x.abs().sum(axis[0]).max(axis[1] - 1);\n        }\n        if (p === Infinity) {\n            return x.abs().sum(axis[1]).max(axis[0]);\n        }\n        if (p === -Infinity) {\n            return x.abs().sum(axis[1]).min(axis[0]);\n        }\n        if (p === 'fro' || p === 'euclidean') {\n            return x.square().sum(axis).sqrt();\n        }\n        throw new Error(\"Error in norm: invalid ord value: \" + p);\n    }\n    throw new Error(\"Error in norm: invalid axis: \" + axis);\n}\n","map":{"version":3,"file":"norm.js","sourceRoot":"","sources":["../src/ops/norm.ts"],"names":[],"mappings":";;;;;;;;AAiBA,8BAA2B;AAE3B,8BAAgC;AAEhC,uCAAyC;AACzC,yCAAsC;AACtC,2BAA6B;AAE7B;IAAA;IAoDA,CAAC;IAbQ,YAAI,GAAX,UACI,CAAS,EAAE,GAA2C,EACtD,IAA4B,EAAE,QAAgB;QADnC,oBAAA,EAAA,iBAA2C;QACtD,qBAAA,EAAA,WAA4B;QAAE,yBAAA,EAAA,gBAAgB;QAChD,IAAI,CAAC,yBAAyB,CAAC,EAAC,CAAC,GAAA,EAAC,EAAE,MAAM,CAAC,CAAC;QAE5C,IAAM,IAAI,GAAG,QAAQ,CAAC,CAAC,EAAE,GAAG,EAAE,IAAI,CAAC,CAAC;QACpC,IAAI,aAAa,GAAG,IAAI,CAAC,KAAK,CAAC;QAC/B,EAAE,CAAC,CAAC,QAAQ,CAAC,CAAC,CAAC;YACb,IAAM,IAAI,GAAG,SAAS,CAAC,cAAc,CAAC,IAAI,EAAE,CAAC,CAAC,KAAK,CAAC,CAAC;YACrD,aAAa,GAAG,SAAS,CAAC,oBAAoB,CAAC,IAAI,CAAC,KAAK,EAAE,IAAI,CAAC,CAAC;QACnE,CAAC;QACD,MAAM,CAAC,IAAI,CAAC,OAAO,CAAC,aAAa,CAAC,CAAC;IACrC,CAAC;IAZD;QAFC,SAAG,CAAC,EAAC,OAAO,EAAE,YAAY,EAAE,UAAU,EAAE,UAAU,EAAC,CAAC;QACpD,qBAAS;6BAaT;IACH,cAAC;CAAA,AApDD,IAoDC;AApDY,0BAAO;AAsDpB,kBACI,CAAS,EAAE,CAAgB,EAAE,IAA4B;IAA5B,qBAAA,EAAA,WAA4B;IAC3D,EAAE,CAAC,CAAC,CAAC,CAAC,IAAI,KAAK,CAAC,CAAC,CAAC,CAAC;QACjB,MAAM,CAAC,CAAC,CAAC,GAAG,EAAE,CAAC;IACjB,CAAC;IAGD,EAAE,CAAC,CAAC,CAAC,CAAC,IAAI,KAAK,CAAC,IAAI,IAAI,KAAK,IAAI,CAAC,CAAC,CAAC;QAClC,MAAM,CAAC,QAAQ,CAAC,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,IAAI,CAAC,CAAC;IAC5C,CAAC;IAGD,EAAE,CAAC,CAAC,CAAC,CAAC,IAAI,KAAK,CAAC,IAAI,OAAO,IAAI,KAAK,QAAQ;QACxC,IAAI,YAAY,KAAK,IAAI,IAAI,CAAC,MAAM,KAAK,CAAC,CAAC,CAAC,CAAC;QAC/C,EAAE,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;YACZ,MAAM,CAAC,CAAC,CAAC,GAAG,EAAE,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC;QAC3B,CAAC;QACD,EAAE,CAAC,CAAC,CAAC,KAAK,QAAQ,CAAC,CAAC,CAAC;YACnB,MAAM,CAAC,CAAC,CAAC,GAAG,EAAE,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC;QAC3B,CAAC;QACD,EAAE,CAAC,CAAC,CAAC,KAAK,CAAC,QAAQ,CAAC,CAAC,CAAC;YACpB,MAAM,CAAC,CAAC,CAAC,GAAG,EAAE,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC;QAC3B,CAAC;QACD,EAAE,CAAC,CAAC,CAAC,KAAK,WAAW,IAAI,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;YAEjC,MAAM,CAAC,CAAC,CAAC,GAAG,EAAE,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC,EAAE,OAAO,CAAC,CAAC,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,IAAI,EAAY,CAAC;QACxE,CAAC;QAED,MAAM,IAAI,KAAK,CAAC,uCAAqC,CAAG,CAAC,CAAC;IAC5D,CAAC;IAGD,EAAE,CAAC,CAAC,IAAI,YAAY,KAAK,IAAI,IAAI,CAAC,MAAM,KAAK,CAAC,CAAC,CAAC,CAAC;QAC/C,EAAE,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;YACZ,MAAM,CAAC,CAAC,CAAC,GAAG,EAAE,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC;QAC/C,CAAC;QACD,EAAE,CAAC,CAAC,CAAC,KAAK,QAAQ,CAAC,CAAC,CAAC;YACnB,MAAM,CAAC,CAAC,CAAC,GAAG,EAAE,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC;QAC3C,CAAC;QACD,EAAE,CAAC,CAAC,CAAC,KAAK,CAAC,QAAQ,CAAC,CAAC,CAAC;YACpB,MAAM,CAAC,CAAC,CAAC,GAAG,EAAE,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC;QAC3C,CAAC;QACD,EAAE,CAAC,CAAC,CAAC,KAAK,KAAK,IAAI,CAAC,KAAK,WAAW,CAAC,CAAC,CAAC;YAErC,MAAM,CAAC,CAAC,CAAC,MAAM,EAAE,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,IAAI,EAAE,CAAC;QACrC,CAAC;QAED,MAAM,IAAI,KAAK,CAAC,uCAAqC,CAAG,CAAC,CAAC;IAC5D,CAAC;IAED,MAAM,IAAI,KAAK,CAAC,kCAAgC,IAAM,CAAC,CAAC;AAC1D,CAAC","sourcesContent":["/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {doc} from '../doc';\nimport {Tensor} from '../tensor';\nimport * as util from '../util';\n\nimport * as axis_util from './axis_util';\nimport {operation} from './operation';\nimport * as ops from './ops';\n\nexport class NormOps {\n  /**\n   * Computes the norm of scalar, vectors, and matrices.\n   * This function can compute several different vector norms (the 1-norm, the\n   * Euclidean or 2-norm, the inf-norm, and in general the p-norm for p > 0)\n   * and matrix norms (Frobenius, 1-norm, and inf-norm).\n   *\n   * ```js\n   * const x = tf.tensor1d([1, 2, 3, 4]);\n   *\n   * x.norm().print();  // or tf.norm(x)\n   * ```\n   *\n   * @param x The input array.\n   * @param ord Optional. Order of the norm. Supported norm types are\n   * following:\n   *\n   *  | ord        | norm for matrices         | norm for vectors\n   *  |------------|---------------------------|---------------------\n   *  |'euclidean' |Frobenius norm             |2-norm\n   *  |'fro'       |Frobenius norm\t           |\n   *  |Infinity    |max(sum(abs(x), axis=1))   |max(abs(x))\n   *  |-Infinity   |min(sum(abs(x), axis=1))   |min(abs(x))\n   *  |1           |max(sum(abs(x), axis=0))   |sum(abs(x))\n   *  |2           |                           |sum(abs(x)^2)^1/2*\n   *\n   * @param axis Optional. If axis is null (the default), the input is\n   * considered a vector and a single vector norm is computed over the entire\n   * set of values in the Tensor, i.e. norm(x, ord) is equivalent\n   * to norm(x.reshape([-1]), ord). If axis is a integer, the input\n   * is considered a batch of vectors, and axis determines the axis in x\n   * over which to compute vector norms. If axis is a 2-tuple of integer it is\n   * considered a batch of matrices and axis determines the axes in NDArray\n   * over which to compute a matrix norm.\n   * @param keepDims Optional. If true, the norm have the same dimensionality\n   * as the input.\n   */\n  @doc({heading: 'Operations', subheading: 'Matrices'})\n  @operation\n  static norm(\n      x: Tensor, ord: number|'euclidean'|'fro' = 'euclidean',\n      axis: number|number[] = null, keepDims = false): Tensor {\n    util.assertArgumentsAreTensors({x}, 'norm');\n\n    const norm = normImpl(x, ord, axis);\n    let keepDimsShape = norm.shape;\n    if (keepDims) {\n      const axes = axis_util.parseAxisParam(axis, x.shape);\n      keepDimsShape = axis_util.expandShapeToKeepDim(norm.shape, axes);\n    }\n    return norm.reshape(keepDimsShape);\n  }\n}\n\nfunction normImpl(\n    x: Tensor, p: number|string, axis: number|number[] = null): Tensor {\n  if (x.rank === 0) {\n    return x.abs();\n  }\n\n  // consider vector when no axis is specified\n  if (x.rank !== 1 && axis === null) {\n    return normImpl(x.reshape([-1]), p, axis);\n  }\n\n  // vector\n  if (x.rank === 1 || typeof axis === 'number' ||\n      axis instanceof Array && axis.length === 1) {\n    if (p === 1) {\n      return x.abs().sum(axis);\n    }\n    if (p === Infinity) {\n      return x.abs().max(axis);\n    }\n    if (p === -Infinity) {\n      return x.abs().min(axis);\n    }\n    if (p === 'euclidean' || p === 2) {\n      // norm(x, 2) = sum(abs(xi) ^ 2) ^ 1/2\n      return x.abs().pow(ops.scalar(2, 'int32')).sum(axis).sqrt() as Tensor;\n    }\n\n    throw new Error(`Error in norm: invalid ord value: ${p}`);\n  }\n\n  // matrix (assumption axis[0] < axis[1])\n  if (axis instanceof Array && axis.length === 2) {\n    if (p === 1) {\n      return x.abs().sum(axis[0]).max(axis[1] - 1);\n    }\n    if (p === Infinity) {\n      return x.abs().sum(axis[1]).max(axis[0]);\n    }\n    if (p === -Infinity) {\n      return x.abs().sum(axis[1]).min(axis[0]);\n    }\n    if (p === 'fro' || p === 'euclidean') {\n      // norm(x) = sqrt(sum(pow(x, 2)))\n      return x.square().sum(axis).sqrt();\n    }\n\n    throw new Error(`Error in norm: invalid ord value: ${p}`);\n  }\n\n  throw new Error(`Error in norm: invalid axis: ${axis}`);\n}\n"]}},"hash":"ec7dc54bd59bc9eeb75f42a3d3c4c8b3","cacheData":{"env":{}}}