{"dependencies":[{"name":"/usr/local/google/home/nsthorat/deeplearnjs-clients/float16/tfjs-core/test/package.json","includedInParent":true,"mtime":1528810356568},{"name":"/usr/local/google/home/nsthorat/deeplearnjs-clients/float16/tfjs-core/test/.babelrc","includedInParent":true,"mtime":1525096773813},{"name":"/usr/local/google/home/nsthorat/deeplearnjs-clients/float16/tfjs-core/tsconfig.json","includedInParent":true,"mtime":1528810356568},{"name":"../../ops/broadcast_util","loc":{"line":3,"column":29}}],"generated":{"js":"\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar broadcast_util = require(\"../../ops/broadcast_util\");\nvar BatchNormProgram = (function () {\n    function BatchNormProgram(xShape, meanShape, varianceShape, offsetShape, scaleShape, varianceEpsilon) {\n        this.outputShape = [];\n        this.supportsBroadcasting = true;\n        this.variableNames = ['x', 'mean', 'variance'];\n        broadcast_util.assertAndGetBroadcastShape(xShape, meanShape);\n        broadcast_util.assertAndGetBroadcastShape(xShape, varianceShape);\n        var offsetSnippet = '0.0';\n        if (offsetShape != null) {\n            broadcast_util.assertAndGetBroadcastShape(xShape, offsetShape);\n            this.variableNames.push('offset');\n            offsetSnippet = 'getOffsetAtOutCoords()';\n        }\n        var scaleSnippet = '1.0';\n        if (scaleShape != null) {\n            broadcast_util.assertAndGetBroadcastShape(xShape, scaleShape);\n            this.variableNames.push('scale');\n            scaleSnippet = 'getScaleAtOutCoords()';\n        }\n        this.outputShape = xShape;\n        this.userCode = \"\\n      void main() {\\n        float x = getXAtOutCoords();\\n        float mean = getMeanAtOutCoords();\\n        float variance = getVarianceAtOutCoords();\\n        float offset = \" + offsetSnippet + \";\\n        float scale = \" + scaleSnippet + \";\\n        float inv = scale * inversesqrt(variance + float(\" + varianceEpsilon + \"));\\n        setOutput((x - mean) * inv + offset);\\n      }\\n    \";\n    }\n    return BatchNormProgram;\n}());\nexports.BatchNormProgram = BatchNormProgram;\n","map":{"version":3,"file":"batchnorm_gpu.js","sourceRoot":"","sources":["../src/kernels/webgl/batchnorm_gpu.ts"],"names":[],"mappings":";;AAiBA,yDAA2D;AAG3D;IAME,0BACI,MAAgB,EAAE,SAAmB,EAAE,aAAuB,EAC9D,WAA0B,EAAE,UAAyB,EACrD,eAAuB;QAP3B,gBAAW,GAAa,EAAE,CAAC;QAE3B,yBAAoB,GAAG,IAAI,CAAC;QAM1B,IAAI,CAAC,aAAa,GAAG,CAAC,GAAG,EAAE,MAAM,EAAE,UAAU,CAAC,CAAC;QAC/C,cAAc,CAAC,0BAA0B,CAAC,MAAM,EAAE,SAAS,CAAC,CAAC;QAC7D,cAAc,CAAC,0BAA0B,CAAC,MAAM,EAAE,aAAa,CAAC,CAAC;QAEjE,IAAI,aAAa,GAAG,KAAK,CAAC;QAC1B,EAAE,CAAC,CAAC,WAAW,IAAI,IAAI,CAAC,CAAC,CAAC;YACxB,cAAc,CAAC,0BAA0B,CAAC,MAAM,EAAE,WAAW,CAAC,CAAC;YAC/D,IAAI,CAAC,aAAa,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC;YAClC,aAAa,GAAG,wBAAwB,CAAC;QAC3C,CAAC;QAED,IAAI,YAAY,GAAG,KAAK,CAAC;QACzB,EAAE,CAAC,CAAC,UAAU,IAAI,IAAI,CAAC,CAAC,CAAC;YACvB,cAAc,CAAC,0BAA0B,CAAC,MAAM,EAAE,UAAU,CAAC,CAAC;YAC9D,IAAI,CAAC,aAAa,CAAC,IAAI,CAAC,OAAO,CAAC,CAAC;YACjC,YAAY,GAAG,uBAAuB,CAAC;QACzC,CAAC;QAED,IAAI,CAAC,WAAW,GAAG,MAAM,CAAC;QAC1B,IAAI,CAAC,QAAQ,GAAG,yLAKK,aAAa,iCACd,YAAY,oEACuB,eAAe,sEAGrE,CAAC;IACJ,CAAC;IACH,uBAAC;AAAD,CAAC,AAzCD,IAyCC;AAzCY,4CAAgB","sourcesContent":["/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as broadcast_util from '../../ops/broadcast_util';\nimport {GPGPUProgram} from './gpgpu_math';\n\nexport class BatchNormProgram implements GPGPUProgram {\n  variableNames: string[];\n  outputShape: number[] = [];\n  userCode: string;\n  supportsBroadcasting = true;\n\n  constructor(\n      xShape: number[], meanShape: number[], varianceShape: number[],\n      offsetShape: number[]|null, scaleShape: number[]|null,\n      varianceEpsilon: number) {\n    this.variableNames = ['x', 'mean', 'variance'];\n    broadcast_util.assertAndGetBroadcastShape(xShape, meanShape);\n    broadcast_util.assertAndGetBroadcastShape(xShape, varianceShape);\n\n    let offsetSnippet = '0.0';\n    if (offsetShape != null) {\n      broadcast_util.assertAndGetBroadcastShape(xShape, offsetShape);\n      this.variableNames.push('offset');\n      offsetSnippet = 'getOffsetAtOutCoords()';\n    }\n\n    let scaleSnippet = '1.0';\n    if (scaleShape != null) {\n      broadcast_util.assertAndGetBroadcastShape(xShape, scaleShape);\n      this.variableNames.push('scale');\n      scaleSnippet = 'getScaleAtOutCoords()';\n    }\n\n    this.outputShape = xShape;\n    this.userCode = `\n      void main() {\n        float x = getXAtOutCoords();\n        float mean = getMeanAtOutCoords();\n        float variance = getVarianceAtOutCoords();\n        float offset = ${offsetSnippet};\n        float scale = ${scaleSnippet};\n        float inv = scale * inversesqrt(variance + float(${varianceEpsilon}));\n        setOutput((x - mean) * inv + offset);\n      }\n    `;\n  }\n}\n"]}},"hash":"cb7ed51d2834501903b5c5622089cd0b","cacheData":{"env":{}}}