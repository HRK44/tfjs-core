{"dependencies":[{"name":"/usr/local/google/home/nsthorat/deeplearnjs-clients/float16/tfjs-core/test/package.json","includedInParent":true,"mtime":1525096773813},{"name":"/usr/local/google/home/nsthorat/deeplearnjs-clients/float16/tfjs-core/test/.babelrc","includedInParent":true,"mtime":1525096773813},{"name":"/usr/local/google/home/nsthorat/deeplearnjs-clients/float16/tfjs-core/tsconfig.json","includedInParent":true,"mtime":1524062920943},{"name":"../doc","loc":{"line":44,"column":20}},{"name":"../environment","loc":{"line":45,"column":28}},{"name":"../tensor","loc":{"line":46,"column":23}},{"name":"../tensor_util","loc":{"line":47,"column":26}},{"name":"../util","loc":{"line":48,"column":19}},{"name":"./axis_util","loc":{"line":49,"column":26}},{"name":"./concat","loc":{"line":50,"column":23}},{"name":"./operation","loc":{"line":51,"column":26}},{"name":"./rand","loc":{"line":52,"column":21}}],"generated":{"js":"\"use strict\";\nvar __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {\n    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;\n    if (typeof Reflect === \"object\" && typeof Reflect.decorate === \"function\") r = Reflect.decorate(decorators, target, key, desc);\n    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;\n    return c > 3 && r && Object.defineProperty(target, key, r), r;\n};\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = y[op[0] & 2 ? \"return\" : op[0] ? \"throw\" : \"next\"]) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [0, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar doc_1 = require(\"../doc\");\nvar environment_1 = require(\"../environment\");\nvar tensor_1 = require(\"../tensor\");\nvar tensor_util = require(\"../tensor_util\");\nvar util = require(\"../util\");\nvar axis_util_1 = require(\"./axis_util\");\nvar concat_1 = require(\"./concat\");\nvar operation_1 = require(\"./operation\");\nvar rand_1 = require(\"./rand\");\nvar ArrayOps = (function () {\n    function ArrayOps() {\n    }\n    ArrayOps.tensor = function (values, shape, dtype) {\n        if (dtype === void 0) { dtype = 'float32'; }\n        var inferredShape = util.inferShape(values);\n        if (shape != null && inferredShape.length !== 1) {\n            util.assertShapesMatch(shape, inferredShape, \"Error creating a new Tensor. \" +\n                (\"Inferred shape (\" + inferredShape + \") does not match the \") +\n                (\"provided shape (\" + shape + \"). \"));\n        }\n        if (!util.isTypedArray(values) && !Array.isArray(values)) {\n            values = [values];\n        }\n        shape = shape || inferredShape;\n        return tensor_1.Tensor.make(shape, { values: toTypedArray(values, dtype) }, dtype);\n    };\n    ArrayOps.scalar = function (value, dtype) {\n        if (dtype === void 0) { dtype = 'float32'; }\n        if (util.isTypedArray(value) || Array.isArray(value)) {\n            throw new Error('Error creating a new Scalar: value must be a primitive ' +\n                '(number|boolean)');\n        }\n        return ArrayOps.tensor(value, [], dtype);\n    };\n    ArrayOps.tensor1d = function (values, dtype) {\n        if (dtype === void 0) { dtype = 'float32'; }\n        var inferredShape = util.inferShape(values);\n        if (inferredShape.length !== 1) {\n            throw new Error('tensor1d() requires values to be a flat/TypedArray');\n        }\n        return ArrayOps.tensor(values, inferredShape, dtype);\n    };\n    ArrayOps.tensor2d = function (values, shape, dtype) {\n        if (dtype === void 0) { dtype = 'float32'; }\n        if (shape != null && shape.length !== 2) {\n            throw new Error('tensor2d() requires shape to have two numbers');\n        }\n        var inferredShape = util.inferShape(values);\n        if (inferredShape.length !== 2 && inferredShape.length !== 1) {\n            throw new Error('tensor2d() requires values to be number[][] or flat/TypedArray');\n        }\n        if (inferredShape.length === 1 && shape == null) {\n            throw new Error('tensor2d() requires shape to be provided when `values` ' +\n                'are a flat/TypedArray');\n        }\n        shape = shape || inferredShape;\n        return ArrayOps.tensor(values, shape, dtype);\n    };\n    ArrayOps.tensor3d = function (values, shape, dtype) {\n        if (dtype === void 0) { dtype = 'float32'; }\n        if (shape != null && shape.length !== 3) {\n            throw new Error('tensor3d() requires shape to have three numbers');\n        }\n        var inferredShape = util.inferShape(values);\n        if (inferredShape.length !== 3 && inferredShape.length !== 1) {\n            throw new Error('tensor3d() requires values to be number[][][] or flat/TypedArray');\n        }\n        if (inferredShape.length === 1 && shape == null) {\n            throw new Error('tensor3d() requires shape to be provided when `values` ' +\n                'are a flat array');\n        }\n        shape = shape || inferredShape;\n        return ArrayOps.tensor(values, shape, dtype);\n    };\n    ArrayOps.tensor4d = function (values, shape, dtype) {\n        if (dtype === void 0) { dtype = 'float32'; }\n        if (shape != null && shape.length !== 4) {\n            throw new Error('tensor4d() requires shape to have four numbers');\n        }\n        var inferredShape = util.inferShape(values);\n        if (inferredShape.length !== 4 && inferredShape.length !== 1) {\n            throw new Error('tensor4d() requires values to be number[][][][] or flat/TypedArray');\n        }\n        if (inferredShape.length === 1 && shape == null) {\n            throw new Error('tensor4d() requires shape to be provided when `values` ' +\n                'are a flat array');\n        }\n        shape = shape || inferredShape;\n        return ArrayOps.tensor(values, shape, dtype);\n    };\n    ArrayOps.ones = function (shape, dtype) {\n        if (dtype === void 0) { dtype = 'float32'; }\n        var values = makeOnesTypedArray(util.sizeFromShape(shape), dtype);\n        return tensor_1.Tensor.make(shape, { values: values }, dtype);\n    };\n    ArrayOps.zeros = function (shape, dtype) {\n        if (dtype === void 0) { dtype = 'float32'; }\n        var values = makeZerosTypedArray(util.sizeFromShape(shape), dtype);\n        return tensor_1.Tensor.make(shape, { values: values }, dtype);\n    };\n    ArrayOps.fill = function (shape, value, dtype) {\n        if (dtype === void 0) { dtype = 'float32'; }\n        var values = util.getTypedArrayFromDType(dtype, util.sizeFromShape(shape));\n        values.fill(value);\n        return tensor_1.Tensor.make(shape, { values: values }, dtype);\n    };\n    ArrayOps.onesLike = function (x) {\n        util.assertArgumentsAreTensors({ x: x }, 'onesLike');\n        return ArrayOps.ones(x.shape, x.dtype);\n    };\n    ArrayOps.zerosLike = function (x) {\n        util.assertArgumentsAreTensors({ x: x }, 'zerosLike');\n        return ArrayOps.zeros(x.shape, x.dtype);\n    };\n    ArrayOps.clone = function (x) {\n        util.assertArgumentsAreTensors({ x: x }, 'clone');\n        var der = function (dy) {\n            return { x: function () { return dy.toFloat(); } };\n        };\n        return environment_1.ENV.engine.runKernel(function (backend) {\n            return tensor_1.Tensor.make(x.shape, { dataId: x.dataId }, x.dtype);\n        }, { x: x }, der);\n    };\n    ArrayOps.randomNormal = function (shape, mean, stdDev, dtype, seed) {\n        if (mean === void 0) { mean = 0; }\n        if (stdDev === void 0) { stdDev = 1; }\n        if (dtype != null && dtype === 'bool') {\n            throw new Error(\"Unsupported data type \" + dtype);\n        }\n        var randGauss = new rand_1.MPRandGauss(mean, stdDev, dtype, false, seed);\n        var res = ArrayOps.buffer(shape, dtype);\n        for (var i = 0; i < res.values.length; i++) {\n            res.values[i] = randGauss.nextValue();\n        }\n        return res.toTensor();\n    };\n    ArrayOps.truncatedNormal = function (shape, mean, stdDev, dtype, seed) {\n        if (mean === void 0) { mean = 0; }\n        if (stdDev === void 0) { stdDev = 1; }\n        if (dtype != null && dtype === 'bool') {\n            throw new Error(\"Unsupported data type \" + dtype);\n        }\n        var randGauss = new rand_1.MPRandGauss(mean, stdDev, dtype, true, seed);\n        var res = ArrayOps.buffer(shape, dtype);\n        for (var i = 0; i < res.values.length; i++) {\n            res.values[i] = randGauss.nextValue();\n        }\n        return res.toTensor();\n    };\n    ArrayOps.randomUniform = function (shape, minval, maxval, dtype) {\n        if (minval === void 0) { minval = 0; }\n        if (maxval === void 0) { maxval = 1; }\n        if (dtype === void 0) { dtype = 'float32'; }\n        var res = ArrayOps.buffer(shape, dtype);\n        for (var i = 0; i < res.values.length; i++) {\n            res.values[i] = util.randUniform(minval, maxval);\n        }\n        return res.toTensor();\n    };\n    ArrayOps.rand = function (shape, randFunction, dtype) {\n        var size = util.sizeFromShape(shape);\n        var values = null;\n        if (dtype == null || dtype === 'float32') {\n            values = new Float32Array(size);\n        }\n        else if (dtype === 'int32') {\n            values = new Int32Array(size);\n        }\n        else if (dtype === 'bool') {\n            values = new Uint8Array(size);\n        }\n        else {\n            throw new Error(\"Unknown data type \" + dtype);\n        }\n        for (var i = 0; i < size; i++) {\n            values[i] = randFunction();\n        }\n        return tensor_1.Tensor.make(shape, { values: values }, dtype);\n    };\n    ArrayOps.multinomial = function (logits, numSamples, seed, normalized) {\n        if (normalized === void 0) { normalized = false; }\n        util.assertArgumentsAreTensors({ logits: logits }, 'multinomial');\n        var numOutcomes = logits.size;\n        var origRank = logits.rank;\n        if (numOutcomes < 2) {\n            throw new Error(\"Error in multinomial: you need at least 2 outcomes, but got \" +\n                (numOutcomes + \".\"));\n        }\n        if (origRank > 2) {\n            throw new Error(\"Rank of probabilities must be 1 or 2, but is \" + origRank);\n        }\n        seed = seed || Math.random();\n        var logits2D = origRank === 1 ? logits.as2D(1, -1) : logits;\n        var res = environment_1.ENV.engine.runKernel(function (backend) { return backend.multinomial(logits2D, normalized, numSamples, seed); }, { logits2D: logits2D });\n        return origRank === 1 ? res.as1D() : res;\n    };\n    ArrayOps.oneHot = function (indices, depth, onValue, offValue) {\n        if (onValue === void 0) { onValue = 1; }\n        if (offValue === void 0) { offValue = 0; }\n        util.assert(indices.dtype === 'int32', 'Indices must be of dtype `int32`');\n        if (depth < 2) {\n            throw new Error(\"Error in oneHot: depth must be >=2, but it is \" + depth);\n        }\n        return environment_1.ENV.engine.runKernel(function (backend) { return backend.oneHot(indices, depth, onValue, offValue); }, { indices: indices });\n    };\n    ArrayOps.fromPixels = function (pixels, numChannels) {\n        if (numChannels === void 0) { numChannels = 3; }\n        if (numChannels > 4) {\n            throw new Error('Cannot construct Tensor with more than 4 channels from pixels.');\n        }\n        return environment_1.ENV.engine.fromPixels(pixels, numChannels);\n    };\n    ArrayOps.toPixels = function (img, canvas) {\n        return __awaiter(this, void 0, void 0, function () {\n            var _a, height, width, depth, min, max, data, multiplier, bytes, i, r, g, b, a, j, ctx, imageData;\n            return __generator(this, function (_b) {\n                switch (_b.label) {\n                    case 0:\n                        util.assertArgumentsAreTensors({ img: img }, 'toPixels');\n                        if (img.rank !== 2 && img.rank !== 3) {\n                            throw new Error(\"toPixels only supports rank 2 or 3 tensors, got rank \" + img.rank + \".\");\n                        }\n                        _a = img.shape.slice(0, 2), height = _a[0], width = _a[1];\n                        depth = img.rank === 2 ? 1 : img.shape[2];\n                        if (depth > 4 || depth === 2) {\n                            throw new Error(\"toPixels only supports depth of size \" +\n                                (\"1, 3 or 4 but got \" + depth));\n                        }\n                        return [4, img.min().data()];\n                    case 1:\n                        min = (_b.sent())[0];\n                        return [4, img.max().data()];\n                    case 2:\n                        max = (_b.sent())[0];\n                        if (img.dtype === 'float32') {\n                            if (min < 0 || max > 1) {\n                                throw new Error(\"Tensor values for a float32 Tensor must be in the \" +\n                                    (\"range [0 - 1] but got range [\" + min + \" - \" + max + \"].\"));\n                            }\n                        }\n                        else if (img.dtype === 'int32') {\n                            if (min < 0 || max > 255) {\n                                throw new Error(\"Tensor values for a int32 Tensor must be in the \" +\n                                    (\"range [0 - 255] but got range [\" + min + \" - \" + max + \"].\"));\n                            }\n                        }\n                        else {\n                            throw new Error(\"Unsupported type for toPixels: \" + img.dtype + \".\" +\n                                \" Please use float32 or int32 tensors.\");\n                        }\n                        return [4, img.data()];\n                    case 3:\n                        data = _b.sent();\n                        multiplier = img.dtype === 'float32' ? 255 : 1;\n                        bytes = new Uint8ClampedArray(width * height * 4);\n                        for (i = 0; i < height * width; ++i) {\n                            r = void 0, g = void 0, b = void 0, a = void 0;\n                            if (depth === 1) {\n                                r = data[i] * multiplier;\n                                g = data[i] * multiplier;\n                                b = data[i] * multiplier;\n                                a = 255;\n                            }\n                            else if (depth === 3) {\n                                r = data[i * 3] * multiplier;\n                                g = data[i * 3 + 1] * multiplier;\n                                b = data[i * 3 + 2] * multiplier;\n                                a = 255;\n                            }\n                            else if (depth === 4) {\n                                r = data[i * 4] * multiplier;\n                                g = data[i * 4 + 1] * multiplier;\n                                b = data[i * 4 + 2] * multiplier;\n                                a = data[i * 4 + 3] * multiplier;\n                            }\n                            j = i * 4;\n                            bytes[j + 0] = Math.round(r);\n                            bytes[j + 1] = Math.round(g);\n                            bytes[j + 2] = Math.round(b);\n                            bytes[j + 3] = Math.round(a);\n                        }\n                        if (canvas != null) {\n                            canvas.width = width;\n                            canvas.height = height;\n                            ctx = canvas.getContext('2d');\n                            imageData = new ImageData(bytes, width, height);\n                            ctx.putImageData(imageData, 0, 0);\n                        }\n                        return [2, bytes];\n                }\n            });\n        });\n    };\n    ArrayOps.reshape = function (x, shape) {\n        util.assertArgumentsAreTensors({ x: x }, 'reshape');\n        shape = util.inferFromImplicitShape(shape, x.size);\n        util.assert(x.size === util.sizeFromShape(shape), 'new shape and old shape must have the same number of elements.');\n        var grad = function (dy) {\n            return { x: function () { return dy.reshape(x.shape); } };\n        };\n        return environment_1.ENV.engine.runKernel(function (backend) { return backend.reshape(x, shape); }, { x: x }, grad);\n    };\n    ArrayOps.squeeze = function (x, axis) {\n        util.assertArgumentsAreTensors({ x: x }, 'squeeze');\n        return ArrayOps.reshape(x, util.squeezeShape(x.shape, axis).newShape);\n    };\n    ArrayOps.cast = function (x, dtype) {\n        util.assertArgumentsAreTensors({ x: x }, 'cast');\n        var grad = function (dy) {\n            return { x: function () { return dy.clone(); } };\n        };\n        return environment_1.ENV.engine.runKernel(function (backend) { return backend.cast(x, dtype); }, { x: x }, grad);\n    };\n    ArrayOps.tile = function (x, reps) {\n        util.assertArgumentsAreTensors({ x: x }, 'tile');\n        util.assert(x.rank === reps.length, \"Error in transpose: rank of input \" + x.rank + \" \" +\n            (\"must match length of reps \" + reps + \".\"));\n        var grad = function (dy) {\n            var derX = function () {\n                var xGrad = ArrayOps.zerosLike(x);\n                if (x.rank === 1) {\n                    for (var i = 0; i < reps[0]; ++i) {\n                        xGrad = xGrad.add(dy.slice([i * x.shape[0]], [x.shape[0]]));\n                    }\n                }\n                else if (x.rank === 2) {\n                    for (var i = 0; i < reps[0]; ++i) {\n                        for (var j = 0; j < reps[1]; ++j) {\n                            xGrad = xGrad.add(dy.slice([i * x.shape[0], j * x.shape[1]], [x.shape[0], x.shape[1]]));\n                        }\n                    }\n                }\n                else if (x.rank === 3) {\n                    for (var i = 0; i < reps[0]; ++i) {\n                        for (var j = 0; j < reps[1]; ++j) {\n                            for (var k = 0; k < reps[2]; ++k) {\n                                xGrad = xGrad.add(dy.slice([i * x.shape[0], j * x.shape[1], k * x.shape[2]], [x.shape[0], x.shape[1], x.shape[2]]));\n                            }\n                        }\n                    }\n                }\n                else if (x.rank === 4) {\n                    for (var i = 0; i < reps[0]; ++i) {\n                        for (var j = 0; j < reps[1]; ++j) {\n                            for (var k = 0; k < reps[2]; ++k) {\n                                for (var l = 0; l < reps[3]; ++l) {\n                                    xGrad = xGrad.add(dy.slice([\n                                        i * x.shape[0], j * x.shape[1], k * x.shape[2],\n                                        l * x.shape[3]\n                                    ], [x.shape[0], x.shape[1], x.shape[2], x.shape[3]]));\n                                }\n                            }\n                        }\n                    }\n                }\n                else {\n                    throw new Error(\"Gradient for tile operation is not implemented for rank-\" +\n                        (x.rank + \" tensors yet.\"));\n                }\n                return xGrad;\n            };\n            return { x: derX };\n        };\n        return environment_1.ENV.engine.runKernel(function (backend) { return backend.tile(x, reps); }, { x: x }, grad);\n    };\n    ArrayOps.gather = function (x, indices, axis) {\n        if (axis === void 0) { axis = 0; }\n        util.assertArgumentsAreTensors({ x: x, indices: indices }, 'gather');\n        util.assert(indices.dtype === 'int32', 'Indices must be of dtype `int32`');\n        var axes = axis_util_1.parseAxisParam(axis, x.shape);\n        return environment_1.ENV.engine.runKernel(function (backend) { return backend.gather(x, indices, axes[0]); }, { x: x, indices: indices });\n    };\n    ArrayOps.pad1d = function (x, paddings, constantValue) {\n        if (constantValue === void 0) { constantValue = 0; }\n        util.assert(paddings.length === 2, 'Invalid number of paddings. Must be length of 2.');\n        return ArrayOps.pad(x, [paddings], constantValue);\n    };\n    ArrayOps.pad2d = function (x, paddings, constantValue) {\n        if (constantValue === void 0) { constantValue = 0; }\n        util.assert(paddings.length === 2 && paddings[0].length === 2 &&\n            paddings[1].length === 2, 'Invalid number of paddings. Must be length of 2 each.');\n        return ArrayOps.pad(x, paddings, constantValue);\n    };\n    ArrayOps.pad3d = function (x, paddings, constantValue) {\n        if (constantValue === void 0) { constantValue = 0; }\n        util.assert(paddings.length === 3 && paddings[0].length === 2 &&\n            paddings[1].length === 2 && paddings[2].length === 2, 'Invalid number of paddings. Must be length of 2 each.');\n        return ArrayOps.pad(x, paddings, constantValue);\n    };\n    ArrayOps.pad4d = function (x, paddings, constantValue) {\n        if (constantValue === void 0) { constantValue = 0; }\n        util.assert(paddings.length === 4 && paddings[0].length === 2 &&\n            paddings[1].length === 2 && paddings[2].length === 2 &&\n            paddings[3].length === 2, 'Invalid number of paddings. Must be length of 2 each.');\n        return ArrayOps.pad(x, paddings, constantValue);\n    };\n    ArrayOps.pad = function (x, paddings, constantValue) {\n        if (constantValue === void 0) { constantValue = 0; }\n        util.assertArgumentsAreTensors({ x: x }, 'pad');\n        if (x.rank === 0) {\n            throw new Error('pad(scalar) is not defined. Pass non-scalar to pad');\n        }\n        var begin = paddings.map(function (p) { return p[0]; });\n        var grad = function (dy) {\n            return { x: function () { return dy.slice(begin, x.shape); } };\n        };\n        return environment_1.ENV.engine.runKernel(function (backend) { return backend.pad(x, paddings, constantValue); }, { x: x }, grad);\n    };\n    ArrayOps.stack = function (tensors, axis) {\n        if (axis === void 0) { axis = 0; }\n        util.assertArgumentsAreTensors({ tensors: tensors }, 'stack');\n        util.assert(tensors.length >= 1, 'Pass at least one tensor to tf.stack');\n        if (tensors.length === 1) {\n            return tensors[0].expandDims(axis);\n        }\n        var rank = tensors[0].rank;\n        var shape = tensors[0].shape;\n        var dtype = tensors[0].dtype;\n        util.assert(axis <= rank, 'Axis must be <= rank of the tensor');\n        tensors.forEach(function (t) {\n            util.assertShapesMatch(shape, t.shape, 'All tensors passed to stack must have matching shapes');\n        });\n        tensors.forEach(function (t) {\n            util.assert(dtype === t.dtype, 'All tensors passed to stack must have matching dtypes');\n        });\n        var expandedTensors = tensors.map(function (t) { return t.expandDims(axis); });\n        return concat_1.ConcatOps.concat(expandedTensors, axis);\n    };\n    ArrayOps.split = function (x, numOrSizeSplits, axis) {\n        if (axis === void 0) { axis = 0; }\n        util.assertArgumentsAreTensors({ x: x }, 'split');\n        axis = axis_util_1.parseAxisParam(axis, x.shape)[0];\n        var splitSizes;\n        if (typeof (numOrSizeSplits) === 'number') {\n            util.assert(x.shape[axis] % numOrSizeSplits === 0, 'Number of splits must evenly divide the axis.');\n            splitSizes = Array(numOrSizeSplits).fill(x.shape[axis] / numOrSizeSplits);\n        }\n        else {\n            util.assert(x.shape[axis] === numOrSizeSplits.reduce(function (a, b) { return a + b; }), 'The sum of sizes must match the size of the axis dimension.');\n            splitSizes = numOrSizeSplits;\n        }\n        var begin = Array(x.rank).fill(0);\n        var size = x.shape.slice();\n        return splitSizes.map(function (s) {\n            size[axis] = s;\n            var slice = x.slice(begin, size);\n            begin[axis] += s;\n            return slice;\n        });\n    };\n    ArrayOps.expandDims = function (x, axis) {\n        if (axis === void 0) { axis = 0; }\n        util.assertArgumentsAreTensors({ x: x }, 'expandDims');\n        util.assert(axis <= x.rank, 'Axis must be <= rank of the tensor');\n        var newShape = x.shape.slice();\n        newShape.splice(axis, 0, 1);\n        return ArrayOps.reshape(x, newShape);\n    };\n    ArrayOps.linspace = function (start, stop, num) {\n        if (num === 0) {\n            throw new Error('Cannot request zero samples');\n        }\n        var step = (stop - start) / (num - 1);\n        var values = makeZerosTypedArray(num, 'float32');\n        values[0] = start;\n        for (var i = 1; i < values.length; i++) {\n            values[i] = values[i - 1] + step;\n        }\n        return ArrayOps.tensor1d(values, 'float32');\n    };\n    ArrayOps.range = function (start, stop, step, dtype) {\n        if (step === void 0) { step = 1; }\n        if (dtype === void 0) { dtype = 'float32'; }\n        if (step === 0) {\n            throw new Error('Cannot have a step of zero');\n        }\n        var sameStartStop = start === stop;\n        var increasingRangeNegativeStep = start < stop && step < 0;\n        var decreasingRangePositiveStep = stop < start && step > 1;\n        if (sameStartStop || increasingRangeNegativeStep ||\n            decreasingRangePositiveStep) {\n            return ArrayOps.zeros([0], dtype);\n        }\n        var numElements = Math.abs(Math.ceil((stop - start) / step));\n        var values = makeZerosTypedArray(numElements, dtype);\n        if (stop < start && step === 1) {\n            step = -1;\n        }\n        values[0] = start;\n        for (var i = 1; i < values.length; i++) {\n            values[i] = values[i - 1] + step;\n        }\n        return ArrayOps.tensor1d(values, dtype);\n    };\n    ArrayOps.buffer = function (shape, dtype, values) {\n        if (dtype === void 0) { dtype = 'float32'; }\n        return new tensor_1.TensorBuffer(shape, dtype, values);\n    };\n    ArrayOps.print = function (x, verbose) {\n        if (verbose === void 0) { verbose = false; }\n        console.log(tensor_util.tensorToString(x, verbose));\n    };\n    __decorate([\n        doc_1.doc({ heading: 'Tensors', subheading: 'Creation' })\n    ], ArrayOps, \"tensor\", null);\n    __decorate([\n        doc_1.doc({ heading: 'Tensors', subheading: 'Creation' })\n    ], ArrayOps, \"scalar\", null);\n    __decorate([\n        doc_1.doc({ heading: 'Tensors', subheading: 'Creation' })\n    ], ArrayOps, \"tensor1d\", null);\n    __decorate([\n        doc_1.doc({ heading: 'Tensors', subheading: 'Creation' })\n    ], ArrayOps, \"tensor2d\", null);\n    __decorate([\n        doc_1.doc({ heading: 'Tensors', subheading: 'Creation' })\n    ], ArrayOps, \"tensor3d\", null);\n    __decorate([\n        doc_1.doc({ heading: 'Tensors', subheading: 'Creation' })\n    ], ArrayOps, \"tensor4d\", null);\n    __decorate([\n        doc_1.doc({ heading: 'Tensors', subheading: 'Creation' }),\n        operation_1.operation\n    ], ArrayOps, \"ones\", null);\n    __decorate([\n        doc_1.doc({ heading: 'Tensors', subheading: 'Creation' }),\n        operation_1.operation\n    ], ArrayOps, \"zeros\", null);\n    __decorate([\n        doc_1.doc({ heading: 'Tensors', subheading: 'Creation' }),\n        operation_1.operation\n    ], ArrayOps, \"fill\", null);\n    __decorate([\n        doc_1.doc({ heading: 'Tensors', subheading: 'Creation' }),\n        operation_1.operation\n    ], ArrayOps, \"onesLike\", null);\n    __decorate([\n        doc_1.doc({ heading: 'Tensors', subheading: 'Creation' }),\n        operation_1.operation\n    ], ArrayOps, \"zerosLike\", null);\n    __decorate([\n        doc_1.doc({ heading: 'Tensors', subheading: 'Creation' }),\n        operation_1.operation\n    ], ArrayOps, \"clone\", null);\n    __decorate([\n        doc_1.doc({ heading: 'Tensors', subheading: 'Creation' }),\n        operation_1.operation\n    ], ArrayOps, \"randomNormal\", null);\n    __decorate([\n        doc_1.doc({ heading: 'Tensors', subheading: 'Creation' }),\n        operation_1.operation\n    ], ArrayOps, \"truncatedNormal\", null);\n    __decorate([\n        doc_1.doc({ heading: 'Tensors', subheading: 'Creation' }),\n        operation_1.operation\n    ], ArrayOps, \"randomUniform\", null);\n    __decorate([\n        operation_1.operation\n    ], ArrayOps, \"rand\", null);\n    __decorate([\n        operation_1.operation\n    ], ArrayOps, \"multinomial\", null);\n    __decorate([\n        doc_1.doc({ heading: 'Tensors', subheading: 'Creation' }),\n        operation_1.operation\n    ], ArrayOps, \"oneHot\", null);\n    __decorate([\n        doc_1.doc({ heading: 'Tensors', subheading: 'Creation' }),\n        operation_1.operation\n    ], ArrayOps, \"fromPixels\", null);\n    __decorate([\n        doc_1.doc({ heading: 'Visualization' })\n    ], ArrayOps, \"toPixels\", null);\n    __decorate([\n        doc_1.doc({ heading: 'Tensors', subheading: 'Transformations' }),\n        operation_1.operation\n    ], ArrayOps, \"reshape\", null);\n    __decorate([\n        doc_1.doc({ heading: 'Tensors', subheading: 'Transformations' })\n    ], ArrayOps, \"squeeze\", null);\n    __decorate([\n        doc_1.doc({ heading: 'Tensors', subheading: 'Transformations' }),\n        operation_1.operation\n    ], ArrayOps, \"cast\", null);\n    __decorate([\n        doc_1.doc({ heading: 'Tensors', subheading: 'Slicing and Joining' }),\n        operation_1.operation\n    ], ArrayOps, \"tile\", null);\n    __decorate([\n        doc_1.doc({ heading: 'Tensors', subheading: 'Slicing and Joining' }),\n        operation_1.operation\n    ], ArrayOps, \"gather\", null);\n    __decorate([\n        doc_1.doc({ heading: 'Tensors', subheading: 'Transformations' }),\n        operation_1.operation\n    ], ArrayOps, \"pad\", null);\n    __decorate([\n        doc_1.doc({ heading: 'Tensors', subheading: 'Slicing and Joining' }),\n        operation_1.operation\n    ], ArrayOps, \"stack\", null);\n    __decorate([\n        doc_1.doc({ heading: 'Tensors', subheading: 'Slicing and Joining' }),\n        operation_1.operation\n    ], ArrayOps, \"split\", null);\n    __decorate([\n        doc_1.doc({ heading: 'Tensors', subheading: 'Transformations' }),\n        operation_1.operation\n    ], ArrayOps, \"expandDims\", null);\n    __decorate([\n        operation_1.operation,\n        doc_1.doc({ heading: 'Tensors', subheading: 'Creation' })\n    ], ArrayOps, \"linspace\", null);\n    __decorate([\n        operation_1.operation,\n        doc_1.doc({ heading: 'Tensors', subheading: 'Creation' })\n    ], ArrayOps, \"range\", null);\n    __decorate([\n        doc_1.doc({ heading: 'Tensors', subheading: 'Creation' })\n    ], ArrayOps, \"buffer\", null);\n    __decorate([\n        doc_1.doc({ heading: 'Tensors', subheading: 'Creation' })\n    ], ArrayOps, \"print\", null);\n    return ArrayOps;\n}());\nexports.ArrayOps = ArrayOps;\nfunction makeZerosTypedArray(size, dtype) {\n    if (dtype == null || dtype === 'float32') {\n        return new Float32Array(size);\n    }\n    else if (dtype === 'int32') {\n        return new Int32Array(size);\n    }\n    else if (dtype === 'bool') {\n        return new Uint8Array(size);\n    }\n    else {\n        throw new Error(\"Unknown data type $ {dtype}\");\n    }\n}\nfunction makeOnesTypedArray(size, dtype) {\n    var array = makeZerosTypedArray(size, dtype);\n    for (var i = 0; i < array.length; i++) {\n        array[i] = 1;\n    }\n    return array;\n}\nfunction toTypedArray(a, dtype) {\n    if (noConversionNeeded(a, dtype)) {\n        return a;\n    }\n    if (Array.isArray(a)) {\n        a = util.flatten(a);\n    }\n    return util.copyTypedArray(a, dtype);\n}\nfunction noConversionNeeded(a, dtype) {\n    return (a instanceof Float32Array && dtype === 'float32') ||\n        (a instanceof Int32Array && dtype === 'int32') ||\n        (a instanceof Uint8Array && dtype === 'bool');\n}\n","map":{"version":3,"file":"array_ops.js","sourceRoot":"","sources":["../src/ops/array_ops.ts"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAiBA,8BAA2B;AAE3B,8CAAmC;AAEnC,oCAA+F;AAC/F,4CAA8C;AAG9C,8BAAgC;AAChC,yCAA2C;AAC3C,mCAAmC;AACnC,yCAAsC;AACtC,+BAAmC;AAEnC;IAAA;IA6rCA,CAAC;IAlqCQ,eAAM,GAAb,UACI,MAAkB,EAAE,KAAmB,EAAE,KAA2B;QAA3B,sBAAA,EAAA,iBAA2B;QAEtE,IAAM,aAAa,GAAG,IAAI,CAAC,UAAU,CAAC,MAAM,CAAC,CAAC;QAC9C,EAAE,CAAC,CAAC,KAAK,IAAI,IAAI,IAAI,aAAa,CAAC,MAAM,KAAK,CAAC,CAAC,CAAC,CAAC;YAChD,IAAI,CAAC,iBAAiB,CAClB,KAAK,EAAE,aAAa,EACpB,+BAA+B;iBAC3B,qBAAmB,aAAa,0BAAuB,CAAA;iBACvD,qBAAmB,KAAK,QAAK,CAAA,CAAC,CAAC;QACzC,CAAC;QACD,EAAE,CAAC,CAAC,CAAC,IAAI,CAAC,YAAY,CAAC,MAAM,CAAC,IAAI,CAAC,KAAK,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC;YACzD,MAAM,GAAG,CAAC,MAAM,CAAa,CAAC;QAChC,CAAC;QACD,KAAK,GAAG,KAAK,IAAI,aAAa,CAAC;QAC/B,MAAM,CAAC,eAAM,CAAC,IAAI,CACd,KAAK,EAAE,EAAC,MAAM,EAAE,YAAY,CAAC,MAA6B,EAAE,KAAK,CAAC,EAAC,EACnE,KAAK,CAAC,CAAC;IACb,CAAC;IAgBM,eAAM,GAAb,UAAc,KAAqB,EAAE,KAA2B;QAA3B,sBAAA,EAAA,iBAA2B;QAC9D,EAAE,CAAC,CAAC,IAAI,CAAC,YAAY,CAAC,KAAK,CAAC,IAAI,KAAK,CAAC,OAAO,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;YACrD,MAAM,IAAI,KAAK,CACX,yDAAyD;gBACzD,kBAAkB,CAAC,CAAC;QAC1B,CAAC;QACD,MAAM,CAAC,QAAQ,CAAC,MAAM,CAAC,KAAK,EAAE,EAAE,EAAE,KAAK,CAAC,CAAC;IAC3C,CAAC;IAiBM,iBAAQ,GAAf,UAAgB,MAAoB,EAAE,KAA2B;QAA3B,sBAAA,EAAA,iBAA2B;QAC/D,IAAM,aAAa,GAAG,IAAI,CAAC,UAAU,CAAC,MAAM,CAAC,CAAC;QAC9C,EAAE,CAAC,CAAC,aAAa,CAAC,MAAM,KAAK,CAAC,CAAC,CAAC,CAAC;YAC/B,MAAM,IAAI,KAAK,CAAC,oDAAoD,CAAC,CAAC;QACxE,CAAC;QACD,MAAM,CAAC,QAAQ,CAAC,MAAM,CAAC,MAAM,EAAE,aAAyB,EAAE,KAAK,CAAC,CAAC;IACnE,CAAC;IAwBM,iBAAQ,GAAf,UACI,MAAoB,EAAE,KAAwB,EAC9C,KAA2B;QAA3B,sBAAA,EAAA,iBAA2B;QAC7B,EAAE,CAAC,CAAC,KAAK,IAAI,IAAI,IAAI,KAAK,CAAC,MAAM,KAAK,CAAC,CAAC,CAAC,CAAC;YACxC,MAAM,IAAI,KAAK,CAAC,+CAA+C,CAAC,CAAC;QACnE,CAAC;QACD,IAAM,aAAa,GAAG,IAAI,CAAC,UAAU,CAAC,MAAM,CAAC,CAAC;QAC9C,EAAE,CAAC,CAAC,aAAa,CAAC,MAAM,KAAK,CAAC,IAAI,aAAa,CAAC,MAAM,KAAK,CAAC,CAAC,CAAC,CAAC;YAC7D,MAAM,IAAI,KAAK,CACX,gEAAgE,CAAC,CAAC;QACxE,CAAC;QACD,EAAE,CAAC,CAAC,aAAa,CAAC,MAAM,KAAK,CAAC,IAAI,KAAK,IAAI,IAAI,CAAC,CAAC,CAAC;YAChD,MAAM,IAAI,KAAK,CACX,yDAAyD;gBACzD,uBAAuB,CAAC,CAAC;QAC/B,CAAC;QACD,KAAK,GAAG,KAAK,IAAI,aAAiC,CAAC;QACnD,MAAM,CAAC,QAAQ,CAAC,MAAM,CAAC,MAAM,EAAE,KAAK,EAAE,KAAK,CAAC,CAAC;IAC/C,CAAC;IAwBM,iBAAQ,GAAf,UACI,MAAoB,EAAE,KAAgC,EACtD,KAA2B;QAA3B,sBAAA,EAAA,iBAA2B;QAC7B,EAAE,CAAC,CAAC,KAAK,IAAI,IAAI,IAAI,KAAK,CAAC,MAAM,KAAK,CAAC,CAAC,CAAC,CAAC;YACxC,MAAM,IAAI,KAAK,CAAC,iDAAiD,CAAC,CAAC;QACrE,CAAC;QACD,IAAM,aAAa,GAAG,IAAI,CAAC,UAAU,CAAC,MAAM,CAAC,CAAC;QAC9C,EAAE,CAAC,CAAC,aAAa,CAAC,MAAM,KAAK,CAAC,IAAI,aAAa,CAAC,MAAM,KAAK,CAAC,CAAC,CAAC,CAAC;YAC7D,MAAM,IAAI,KAAK,CACX,kEAAkE,CAAC,CAAC;QAC1E,CAAC;QACD,EAAE,CAAC,CAAC,aAAa,CAAC,MAAM,KAAK,CAAC,IAAI,KAAK,IAAI,IAAI,CAAC,CAAC,CAAC;YAChD,MAAM,IAAI,KAAK,CACX,yDAAyD;gBACzD,kBAAkB,CAAC,CAAC;QAC1B,CAAC;QACD,KAAK,GAAG,KAAK,IAAI,aAAyC,CAAC;QAC3D,MAAM,CAAC,QAAQ,CAAC,MAAM,CAAC,MAAM,EAAE,KAAK,EAAE,KAAK,CAAC,CAAC;IAC/C,CAAC;IAwBM,iBAAQ,GAAf,UACI,MAAoB,EAAE,KAAwC,EAC9D,KAA2B;QAA3B,sBAAA,EAAA,iBAA2B;QAC7B,EAAE,CAAC,CAAC,KAAK,IAAI,IAAI,IAAI,KAAK,CAAC,MAAM,KAAK,CAAC,CAAC,CAAC,CAAC;YACxC,MAAM,IAAI,KAAK,CAAC,gDAAgD,CAAC,CAAC;QACpE,CAAC;QACD,IAAM,aAAa,GAAG,IAAI,CAAC,UAAU,CAAC,MAAM,CAAC,CAAC;QAC9C,EAAE,CAAC,CAAC,aAAa,CAAC,MAAM,KAAK,CAAC,IAAI,aAAa,CAAC,MAAM,KAAK,CAAC,CAAC,CAAC,CAAC;YAC7D,MAAM,IAAI,KAAK,CACX,oEAAoE,CAAC,CAAC;QAC5E,CAAC;QACD,EAAE,CAAC,CAAC,aAAa,CAAC,MAAM,KAAK,CAAC,IAAI,KAAK,IAAI,IAAI,CAAC,CAAC,CAAC;YAChD,MAAM,IAAI,KAAK,CACX,yDAAyD;gBACzD,kBAAkB,CAAC,CAAC;QAC1B,CAAC;QACD,KAAK,GAAG,KAAK,IAAI,aAAiD,CAAC;QACnE,MAAM,CAAC,QAAQ,CAAC,MAAM,CAAC,MAAM,EAAE,KAAK,EAAE,KAAK,CAAC,CAAC;IAC/C,CAAC;IAeM,aAAI,GAAX,UAA4B,KAAkB,EAAE,KAA2B;QAA3B,sBAAA,EAAA,iBAA2B;QAEzE,IAAM,MAAM,GAAG,kBAAkB,CAAC,IAAI,CAAC,aAAa,CAAC,KAAK,CAAC,EAAE,KAAK,CAAC,CAAC;QACpE,MAAM,CAAC,eAAM,CAAC,IAAI,CAAC,KAAK,EAAE,EAAC,MAAM,QAAA,EAAC,EAAE,KAAK,CAAC,CAAC;IAC7C,CAAC;IAeM,cAAK,GAAZ,UAA6B,KAAkB,EAAE,KAA2B;QAA3B,sBAAA,EAAA,iBAA2B;QAE1E,IAAM,MAAM,GAAG,mBAAmB,CAAC,IAAI,CAAC,aAAa,CAAC,KAAK,CAAC,EAAE,KAAK,CAAC,CAAC;QACrE,MAAM,CAAC,eAAM,CAAC,IAAI,CAAC,KAAK,EAAE,EAAC,MAAM,QAAA,EAAC,EAAE,KAAK,CAAC,CAAC;IAC7C,CAAC;IAgBM,aAAI,GAAX,UACI,KAAkB,EAAE,KAAa,EAAE,KAA2B;QAA3B,sBAAA,EAAA,iBAA2B;QAEhE,IAAM,MAAM,GACR,IAAI,CAAC,sBAAsB,CAAC,KAAK,EAAE,IAAI,CAAC,aAAa,CAAC,KAAK,CAAC,CAAC,CAAC;QAClE,MAAM,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;QACnB,MAAM,CAAC,eAAM,CAAC,IAAI,CAAC,KAAK,EAAE,EAAC,MAAM,QAAA,EAAC,EAAE,KAAK,CAAC,CAAC;IAC7C,CAAC;IAcM,iBAAQ,GAAf,UAAkC,CAAI;QACpC,IAAI,CAAC,yBAAyB,CAAC,EAAC,CAAC,GAAA,EAAC,EAAE,UAAU,CAAC,CAAC;QAChD,MAAM,CAAC,QAAQ,CAAC,IAAI,CAAC,CAAC,CAAC,KAAK,EAAE,CAAC,CAAC,KAAK,CAAM,CAAC;IAC9C,CAAC;IAeM,kBAAS,GAAhB,UAAmC,CAAI;QACrC,IAAI,CAAC,yBAAyB,CAAC,EAAC,CAAC,GAAA,EAAC,EAAE,WAAW,CAAC,CAAC;QACjD,MAAM,CAAC,QAAQ,CAAC,KAAK,CAAC,CAAC,CAAC,KAAK,EAAE,CAAC,CAAC,KAAK,CAAM,CAAC;IAC/C,CAAC;IAgBM,cAAK,GAAZ,UAA+B,CAAI;QACjC,IAAI,CAAC,yBAAyB,CAAC,EAAC,CAAC,GAAA,EAAC,EAAE,OAAO,CAAC,CAAC;QAC7C,IAAM,GAAG,GAAG,UAAC,EAAK;YAChB,MAAM,CAAC,EAAC,CAAC,EAAE,cAAM,OAAA,EAAE,CAAC,OAAO,EAAE,EAAZ,CAAY,EAAC,CAAC;QACjC,CAAC,CAAC;QAEF,MAAM,CAAC,iBAAG,CAAC,MAAM,CAAC,SAAS,CAChB,UAAA,OAAO;YACH,OAAA,eAAM,CAAC,IAAI,CAAC,CAAC,CAAC,KAAK,EAAE,EAAC,MAAM,EAAE,CAAC,CAAC,MAAM,EAAC,EAAE,CAAC,CAAC,KAAK,CAAM;QAAtD,CAAsD,EAC1D,EAAC,CAAC,GAAA,EAAC,EAAE,GAAG,CAAM,CAAC;IAC5B,CAAC;IAiBM,qBAAY,GAAnB,UACI,KAAkB,EAAE,IAAQ,EAAE,MAAU,EAAE,KAAyB,EACnE,IAAa;QADO,qBAAA,EAAA,QAAQ;QAAE,uBAAA,EAAA,UAAU;QAE1C,EAAE,CAAC,CAAC,KAAK,IAAI,IAAI,IAAK,KAAkB,KAAK,MAAM,CAAC,CAAC,CAAC;YACpD,MAAM,IAAI,KAAK,CAAC,2BAAyB,KAAO,CAAC,CAAC;QACpD,CAAC;QACD,IAAM,SAAS,GACX,IAAI,kBAAW,CAAC,IAAI,EAAE,MAAM,EAAE,KAAK,EAAE,KAAK,EAAkB,IAAI,CAAC,CAAC;QACtE,IAAM,GAAG,GAAG,QAAQ,CAAC,MAAM,CAAC,KAAK,EAAE,KAAK,CAAC,CAAC;QAC1C,GAAG,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,GAAG,CAAC,MAAM,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE,CAAC;YAC3C,GAAG,CAAC,MAAM,CAAC,CAAC,CAAC,GAAG,SAAS,CAAC,SAAS,EAAE,CAAC;QACxC,CAAC;QACD,MAAM,CAAC,GAAG,CAAC,QAAQ,EAAE,CAAC;IACxB,CAAC;IAsBM,wBAAe,GAAtB,UACI,KAAkB,EAAE,IAAQ,EAAE,MAAU,EAAE,KAAyB,EACnE,IAAa;QADO,qBAAA,EAAA,QAAQ;QAAE,uBAAA,EAAA,UAAU;QAE1C,EAAE,CAAC,CAAC,KAAK,IAAI,IAAI,IAAK,KAAkB,KAAK,MAAM,CAAC,CAAC,CAAC;YACpD,MAAM,IAAI,KAAK,CAAC,2BAAyB,KAAO,CAAC,CAAC;QACpD,CAAC;QACD,IAAM,SAAS,GACX,IAAI,kBAAW,CAAC,IAAI,EAAE,MAAM,EAAE,KAAK,EAAE,IAAI,EAAkB,IAAI,CAAC,CAAC;QACrE,IAAM,GAAG,GAAG,QAAQ,CAAC,MAAM,CAAC,KAAK,EAAE,KAAK,CAAC,CAAC;QAC1C,GAAG,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,GAAG,CAAC,MAAM,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE,CAAC;YAC3C,GAAG,CAAC,MAAM,CAAC,CAAC,CAAC,GAAG,SAAS,CAAC,SAAS,EAAE,CAAC;QACxC,CAAC;QACD,MAAM,CAAC,GAAG,CAAC,QAAQ,EAAE,CAAC;IACxB,CAAC;IAsBM,sBAAa,GAApB,UACI,KAAkB,EAAE,MAAU,EAAE,MAAU,EAAE,KAA2B;QAAnD,uBAAA,EAAA,UAAU;QAAE,uBAAA,EAAA,UAAU;QAAE,sBAAA,EAAA,iBAA2B;QAEzE,IAAM,GAAG,GAAG,QAAQ,CAAC,MAAM,CAAC,KAAK,EAAE,KAAK,CAAC,CAAC;QAC1C,GAAG,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,GAAG,CAAC,MAAM,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE,CAAC;YAC3C,GAAG,CAAC,MAAM,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,WAAW,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC;QACnD,CAAC;QACD,MAAM,CAAC,GAAG,CAAC,QAAQ,EAAE,CAAC;IACxB,CAAC;IAYM,aAAI,GAAX,UACI,KAAkB,EAAE,YAA0B,EAAE,KAAgB;QAElE,IAAM,IAAI,GAAG,IAAI,CAAC,aAAa,CAAC,KAAK,CAAC,CAAC;QAEvC,IAAI,MAAM,GAAG,IAAI,CAAC;QAClB,EAAE,CAAC,CAAC,KAAK,IAAI,IAAI,IAAI,KAAK,KAAK,SAAS,CAAC,CAAC,CAAC;YACzC,MAAM,GAAG,IAAI,YAAY,CAAC,IAAI,CAAC,CAAC;QAClC,CAAC;QAAC,IAAI,CAAC,EAAE,CAAC,CAAC,KAAK,KAAK,OAAO,CAAC,CAAC,CAAC;YAC7B,MAAM,GAAG,IAAI,UAAU,CAAC,IAAI,CAAC,CAAC;QAChC,CAAC;QAAC,IAAI,CAAC,EAAE,CAAC,CAAC,KAAK,KAAK,MAAM,CAAC,CAAC,CAAC;YAC5B,MAAM,GAAG,IAAI,UAAU,CAAC,IAAI,CAAC,CAAC;QAChC,CAAC;QAAC,IAAI,CAAC,CAAC;YACN,MAAM,IAAI,KAAK,CAAC,uBAAqB,KAAO,CAAC,CAAC;QAChD,CAAC;QAED,GAAG,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,IAAI,EAAE,CAAC,EAAE,EAAE,CAAC;YAC9B,MAAM,CAAC,CAAC,CAAC,GAAG,YAAY,EAAE,CAAC;QAC7B,CAAC;QACD,MAAM,CAAC,eAAM,CAAC,IAAI,CAAC,KAAK,EAAE,EAAC,MAAM,QAAA,EAAC,EAAE,KAAK,CAAC,CAAC;IAC7C,CAAC;IAqBM,oBAAW,GAAlB,UACI,MAAyB,EAAE,UAAkB,EAAE,IAAa,EAC5D,UAAkB;QAAlB,2BAAA,EAAA,kBAAkB;QACpB,IAAI,CAAC,yBAAyB,CAAC,EAAC,MAAM,QAAA,EAAC,EAAE,aAAa,CAAC,CAAC;QACxD,IAAM,WAAW,GAAG,MAAM,CAAC,IAAI,CAAC;QAChC,IAAM,QAAQ,GAAG,MAAM,CAAC,IAAI,CAAC;QAC7B,EAAE,CAAC,CAAC,WAAW,GAAG,CAAC,CAAC,CAAC,CAAC;YACpB,MAAM,IAAI,KAAK,CACX,8DAA8D;iBAC3D,WAAW,MAAG,CAAA,CAAC,CAAC;QACzB,CAAC;QACD,EAAE,CAAC,CAAC,QAAQ,GAAG,CAAC,CAAC,CAAC,CAAC;YACjB,MAAM,IAAI,KAAK,CACX,kDAAgD,QAAU,CAAC,CAAC;QAClE,CAAC;QACD,IAAI,GAAG,IAAI,IAAI,IAAI,CAAC,MAAM,EAAE,CAAC;QAC7B,IAAM,QAAQ,GAAG,QAAQ,KAAK,CAAC,CAAC,CAAC,CAAC,MAAM,CAAC,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,MAAkB,CAAC;QAC1E,IAAM,GAAG,GAAG,iBAAG,CAAC,MAAM,CAAC,SAAS,CAC5B,UAAA,OAAO,IAAI,OAAA,OAAO,CAAC,WAAW,CAAC,QAAQ,EAAE,UAAU,EAAE,UAAU,EAAE,IAAI,CAAC,EAA3D,CAA2D,EACtE,EAAC,QAAQ,UAAA,EAAC,CAAC,CAAC;QAEhB,MAAM,CAAC,QAAQ,KAAK,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,IAAI,EAAE,CAAC,CAAC,CAAC,GAAG,CAAC;IAC3C,CAAC;IAoBM,eAAM,GAAb,UAAc,OAAiB,EAAE,KAAa,EAAE,OAAW,EAAE,QAAY;QAAzB,wBAAA,EAAA,WAAW;QAAE,yBAAA,EAAA,YAAY;QAEvE,IAAI,CAAC,MAAM,CAAC,OAAO,CAAC,KAAK,KAAK,OAAO,EAAE,kCAAkC,CAAC,CAAC;QAC3E,EAAE,CAAC,CAAC,KAAK,GAAG,CAAC,CAAC,CAAC,CAAC;YACd,MAAM,IAAI,KAAK,CAAC,mDAAiD,KAAO,CAAC,CAAC;QAC5E,CAAC;QACD,MAAM,CAAC,iBAAG,CAAC,MAAM,CAAC,SAAS,CACvB,UAAA,OAAO,IAAI,OAAA,OAAO,CAAC,MAAM,CAAC,OAAO,EAAE,KAAK,EAAE,OAAO,EAAE,QAAQ,CAAC,EAAjD,CAAiD,EAC5D,EAAC,OAAO,SAAA,EAAC,CAAC,CAAC;IACjB,CAAC;IAsBM,mBAAU,GAAjB,UACI,MAAqE,EACrE,WAAe;QAAf,4BAAA,EAAA,eAAe;QACjB,EAAE,CAAC,CAAC,WAAW,GAAG,CAAC,CAAC,CAAC,CAAC;YACpB,MAAM,IAAI,KAAK,CACX,gEAAgE,CAAC,CAAC;QACxE,CAAC;QACD,MAAM,CAAC,iBAAG,CAAC,MAAM,CAAC,UAAU,CAAC,MAAM,EAAE,WAAW,CAAC,CAAC;IACpD,CAAC;IAoBY,iBAAQ,GAArB,UAAsB,GAAsB,EAAE,MAA0B;;;;;;wBAEtE,IAAI,CAAC,yBAAyB,CAAC,EAAC,GAAG,KAAA,EAAC,EAAE,UAAU,CAAC,CAAC;wBAElD,EAAE,CAAC,CAAC,GAAG,CAAC,IAAI,KAAK,CAAC,IAAI,GAAG,CAAC,IAAI,KAAK,CAAC,CAAC,CAAC,CAAC;4BACrC,MAAM,IAAI,KAAK,CACX,0DAAwD,GAAG,CAAC,IAAI,MAAG,CAAC,CAAC;wBAC3E,CAAC;wBACK,KAAkB,GAAG,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC,EAAtC,MAAM,QAAA,EAAE,KAAK,QAAA,CAA0B;wBACxC,KAAK,GAAG,GAAG,CAAC,IAAI,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;wBAEhD,EAAE,CAAC,CAAC,KAAK,GAAG,CAAC,IAAI,KAAK,KAAK,CAAC,CAAC,CAAC,CAAC;4BAC7B,MAAM,IAAI,KAAK,CACX,uCAAuC;iCACvC,uBAAqB,KAAO,CAAA,CAAC,CAAC;wBACpC,CAAC;wBAEY,WAAM,GAAG,CAAC,GAAG,EAAE,CAAC,IAAI,EAAE,EAAA;;wBAA7B,GAAG,GAAG,CAAC,SAAsB,CAAC,CAAC,CAAC,CAAC;wBAC1B,WAAM,GAAG,CAAC,GAAG,EAAE,CAAC,IAAI,EAAE,EAAA;;wBAA7B,GAAG,GAAG,CAAC,SAAsB,CAAC,CAAC,CAAC,CAAC;wBACvC,EAAE,CAAC,CAAC,GAAG,CAAC,KAAK,KAAK,SAAS,CAAC,CAAC,CAAC;4BAC5B,EAAE,CAAC,CAAC,GAAG,GAAG,CAAC,IAAI,GAAG,GAAG,CAAC,CAAC,CAAC,CAAC;gCACvB,MAAM,IAAI,KAAK,CACX,oDAAoD;qCACpD,kCAAgC,GAAG,WAAM,GAAG,OAAI,CAAA,CAAC,CAAC;4BACxD,CAAC;wBACH,CAAC;wBAAC,IAAI,CAAC,EAAE,CAAC,CAAC,GAAG,CAAC,KAAK,KAAK,OAAO,CAAC,CAAC,CAAC;4BACjC,EAAE,CAAC,CAAC,GAAG,GAAG,CAAC,IAAI,GAAG,GAAG,GAAG,CAAC,CAAC,CAAC;gCACzB,MAAM,IAAI,KAAK,CACX,kDAAkD;qCAClD,oCAAkC,GAAG,WAAM,GAAG,OAAI,CAAA,CAAC,CAAC;4BAC1D,CAAC;wBACH,CAAC;wBAAC,IAAI,CAAC,CAAC;4BACN,MAAM,IAAI,KAAK,CACX,oCAAkC,GAAG,CAAC,KAAK,MAAG;gCAC9C,uCAAuC,CAAC,CAAC;wBAC/C,CAAC;wBAEY,WAAM,GAAG,CAAC,IAAI,EAAE,EAAA;;wBAAvB,IAAI,GAAG,SAAgB;wBACvB,UAAU,GAAG,GAAG,CAAC,KAAK,KAAK,SAAS,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC;wBAC/C,KAAK,GAAG,IAAI,iBAAiB,CAAC,KAAK,GAAG,MAAM,GAAG,CAAC,CAAC,CAAC;wBAExD,GAAG,CAAC,CAAK,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,GAAG,KAAK,EAAE,EAAE,CAAC,EAAE,CAAC;4BACpC,CAAC,SAAA,EAAE,CAAC,SAAA,EAAE,CAAC,SAAA,EAAE,CAAC,SAAA,CAAC;4BACf,EAAE,CAAC,CAAC,KAAK,KAAK,CAAC,CAAC,CAAC,CAAC;gCAChB,CAAC,GAAG,IAAI,CAAC,CAAC,CAAC,GAAG,UAAU,CAAC;gCACzB,CAAC,GAAG,IAAI,CAAC,CAAC,CAAC,GAAG,UAAU,CAAC;gCACzB,CAAC,GAAG,IAAI,CAAC,CAAC,CAAC,GAAG,UAAU,CAAC;gCACzB,CAAC,GAAG,GAAG,CAAC;4BACV,CAAC;4BAAC,IAAI,CAAC,EAAE,CAAC,CAAC,KAAK,KAAK,CAAC,CAAC,CAAC,CAAC;gCACvB,CAAC,GAAG,IAAI,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,UAAU,CAAC;gCAC7B,CAAC,GAAG,IAAI,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC,GAAG,UAAU,CAAC;gCACjC,CAAC,GAAG,IAAI,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC,GAAG,UAAU,CAAC;gCACjC,CAAC,GAAG,GAAG,CAAC;4BACV,CAAC;4BAAC,IAAI,CAAC,EAAE,CAAC,CAAC,KAAK,KAAK,CAAC,CAAC,CAAC,CAAC;gCACvB,CAAC,GAAG,IAAI,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,UAAU,CAAC;gCAC7B,CAAC,GAAG,IAAI,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC,GAAG,UAAU,CAAC;gCACjC,CAAC,GAAG,IAAI,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC,GAAG,UAAU,CAAC;gCACjC,CAAC,GAAG,IAAI,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC,GAAG,UAAU,CAAC;4BACnC,CAAC;4BAEK,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC;4BAChB,KAAK,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,IAAI,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;4BAC7B,KAAK,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,IAAI,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;4BAC7B,KAAK,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,IAAI,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;4BAC7B,KAAK,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,IAAI,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;wBAC/B,CAAC;wBAED,EAAE,CAAC,CAAC,MAAM,IAAI,IAAI,CAAC,CAAC,CAAC;4BACnB,MAAM,CAAC,KAAK,GAAG,KAAK,CAAC;4BACrB,MAAM,CAAC,MAAM,GAAG,MAAM,CAAC;4BACjB,GAAG,GAAG,MAAM,CAAC,UAAU,CAAC,IAAI,CAAC,CAAC;4BAC9B,SAAS,GAAG,IAAI,SAAS,CAAC,KAAK,EAAE,KAAK,EAAE,MAAM,CAAC,CAAC;4BACtD,GAAG,CAAC,YAAY,CAAC,SAAS,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;wBACpC,CAAC;wBAED,WAAO,KAAK,EAAC;;;;KACd;IA4BM,gBAAO,GAAd,UAAgC,CAAS,EAAE,KAAmB;QAC5D,IAAI,CAAC,yBAAyB,CAAC,EAAC,CAAC,GAAA,EAAC,EAAE,SAAS,CAAC,CAAC;QAE/C,KAAK,GAAG,IAAI,CAAC,sBAAsB,CAAC,KAAK,EAAE,CAAC,CAAC,IAAI,CAAC,CAAC;QACnD,IAAI,CAAC,MAAM,CACP,CAAC,CAAC,IAAI,KAAK,IAAI,CAAC,aAAa,CAAC,KAAK,CAAC,EACpC,gEAAgE,CAAC,CAAC;QAEtE,IAAM,IAAI,GAAG,UAAC,EAAc;YAC1B,MAAM,CAAC,EAAC,CAAC,EAAE,cAAM,OAAA,EAAE,CAAC,OAAO,CAAC,CAAC,CAAC,KAAK,CAAC,EAAnB,CAAmB,EAAC,CAAC;QACxC,CAAC,CAAC;QACF,MAAM,CAAC,iBAAG,CAAC,MAAM,CAAC,SAAS,CACvB,UAAA,OAAO,IAAI,OAAA,OAAO,CAAC,OAAO,CAAC,CAAC,EAAE,KAAK,CAAC,EAAzB,CAAyB,EAAE,EAAC,CAAC,GAAA,EAAC,EAAE,IAAI,CAAC,CAAC;IACvD,CAAC;IAgBM,gBAAO,GAAd,UAAiC,CAAS,EAAE,IAAe;QACzD,IAAI,CAAC,yBAAyB,CAAC,EAAC,CAAC,GAAA,EAAC,EAAE,SAAS,CAAC,CAAC;QAC/C,MAAM,CAAC,QAAQ,CAAC,OAAO,CAAC,CAAC,EAAE,IAAI,CAAC,YAAY,CAAC,CAAC,CAAC,KAAK,EAAE,IAAI,CAAC,CAAC,QAAQ,CAAM,CAAC;IAC7E,CAAC;IAcM,aAAI,GAAX,UAA8B,CAAI,EAAE,KAAe;QACjD,IAAI,CAAC,yBAAyB,CAAC,EAAC,CAAC,GAAA,EAAC,EAAE,MAAM,CAAC,CAAC;QAE5C,IAAM,IAAI,GAAG,UAAC,EAAK;YACjB,MAAM,CAAC,EAAC,CAAC,EAAE,cAAM,OAAA,EAAE,CAAC,KAAK,EAAE,EAAV,CAAU,EAAC,CAAC;QAC/B,CAAC,CAAC;QACF,MAAM,CAAC,iBAAG,CAAC,MAAM,CAAC,SAAS,CAAC,UAAA,OAAO,IAAI,OAAA,OAAO,CAAC,IAAI,CAAC,CAAC,EAAE,KAAK,CAAC,EAAtB,CAAsB,EAAE,EAAC,CAAC,GAAA,EAAC,EAAE,IAAI,CACnE,CAAC;IACR,CAAC;IA2BM,aAAI,GAAX,UAA8B,CAAI,EAAE,IAAc;QAChD,IAAI,CAAC,yBAAyB,CAAC,EAAC,CAAC,GAAA,EAAC,EAAE,MAAM,CAAC,CAAC;QAE5C,IAAI,CAAC,MAAM,CACP,CAAC,CAAC,IAAI,KAAK,IAAI,CAAC,MAAM,EACtB,uCAAqC,CAAC,CAAC,IAAI,MAAG;aAC1C,+BAA6B,IAAI,MAAG,CAAA,CAAC,CAAC;QAC9C,IAAM,IAAI,GAAG,UAAC,EAAK;YACjB,IAAM,IAAI,GAAG;gBACX,IAAI,KAAK,GAAG,QAAQ,CAAC,SAAS,CAAC,CAAC,CAAC,CAAC;gBAGlC,EAAE,CAAC,CAAC,CAAC,CAAC,IAAI,KAAK,CAAC,CAAC,CAAC,CAAC;oBACjB,GAAG,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,IAAI,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC;wBACjC,KAAK,GAAG,KAAK,CAAC,GAAG,CAAC,EAAE,CAAC,KAAK,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;oBAC9D,CAAC;gBACH,CAAC;gBAAC,IAAI,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,IAAI,KAAK,CAAC,CAAC,CAAC,CAAC;oBACxB,GAAG,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,IAAI,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC;wBACjC,GAAG,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,IAAI,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC;4BACjC,KAAK,GAAG,KAAK,CAAC,GAAG,CAAC,EAAE,CAAC,KAAK,CACtB,CAAC,CAAC,GAAG,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,GAAG,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;wBACnE,CAAC;oBACH,CAAC;gBACH,CAAC;gBAAC,IAAI,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,IAAI,KAAK,CAAC,CAAC,CAAC,CAAC;oBACxB,GAAG,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,IAAI,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC;wBACjC,GAAG,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,IAAI,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC;4BACjC,GAAG,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,IAAI,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC;gCACjC,KAAK,GAAG,KAAK,CAAC,GAAG,CAAC,EAAE,CAAC,KAAK,CACtB,CAAC,CAAC,GAAG,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,GAAG,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,GAAG,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,EAChD,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;4BAC7C,CAAC;wBACH,CAAC;oBACH,CAAC;gBACH,CAAC;gBAAC,IAAI,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,IAAI,KAAK,CAAC,CAAC,CAAC,CAAC;oBACxB,GAAG,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,IAAI,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC;wBACjC,GAAG,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,IAAI,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC;4BACjC,GAAG,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,IAAI,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC;gCACjC,GAAG,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,IAAI,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC;oCACjC,KAAK,GAAG,KAAK,CAAC,GAAG,CAAC,EAAE,CAAC,KAAK,CACtB;wCACE,CAAC,GAAG,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,GAAG,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,GAAG,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC;wCAC9C,CAAC,GAAG,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC;qCACf,EACD,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;gCACzD,CAAC;4BACH,CAAC;wBACH,CAAC;oBACH,CAAC;gBACH,CAAC;gBAAC,IAAI,CAAC,CAAC;oBACN,MAAM,IAAI,KAAK,CACX,0DAA0D;yBACvD,CAAC,CAAC,IAAI,kBAAe,CAAA,CAAC,CAAC;gBAChC,CAAC;gBACD,MAAM,CAAC,KAAK,CAAC;YACf,CAAC,CAAC;YACF,MAAM,CAAC,EAAC,CAAC,EAAE,IAAI,EAAC,CAAC;QACnB,CAAC,CAAC;QACF,MAAM,CAAC,iBAAG,CAAC,MAAM,CAAC,SAAS,CAAC,UAAA,OAAO,IAAI,OAAA,OAAO,CAAC,IAAI,CAAC,CAAC,EAAE,IAAI,CAAC,EAArB,CAAqB,EAAE,EAAC,CAAC,GAAA,EAAC,EAAE,IAAI,CAAC,CAAC;IAC3E,CAAC;IAwBM,eAAM,GAAb,UAAgC,CAAI,EAAE,OAAiB,EAAE,IAAQ;QAAR,qBAAA,EAAA,QAAQ;QAC/D,IAAI,CAAC,yBAAyB,CAAC,EAAC,CAAC,GAAA,EAAE,OAAO,SAAA,EAAC,EAAE,QAAQ,CAAC,CAAC;QAEvD,IAAI,CAAC,MAAM,CAAC,OAAO,CAAC,KAAK,KAAK,OAAO,EAAE,kCAAkC,CAAC,CAAC;QAC3E,IAAM,IAAI,GAAG,0BAAc,CAAC,IAAI,EAAE,CAAC,CAAC,KAAK,CAAC,CAAC;QAC3C,MAAM,CAAC,iBAAG,CAAC,MAAM,CAAC,SAAS,CACvB,UAAA,OAAO,IAAI,OAAA,OAAO,CAAC,MAAM,CAAC,CAAC,EAAE,OAAO,EAAE,IAAI,CAAC,CAAC,CAAC,CAAC,EAAnC,CAAmC,EAAE,EAAC,CAAC,GAAA,EAAE,OAAO,SAAA,EAAC,CAAC,CAAC;IACpE,CAAC;IAKM,cAAK,GAAZ,UAAa,CAAW,EAAE,QAA0B,EAAE,aAAiB;QAAjB,8BAAA,EAAA,iBAAiB;QAErE,IAAI,CAAC,MAAM,CACP,QAAQ,CAAC,MAAM,KAAK,CAAC,EACrB,kDAAkD,CAAC,CAAC;QACxD,MAAM,CAAC,QAAQ,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,QAAQ,CAAC,EAAE,aAAa,CAAC,CAAC;IACpD,CAAC;IAKM,cAAK,GAAZ,UACI,CAAW,EAAE,QAA8C,EAC3D,aAAiB;QAAjB,8BAAA,EAAA,iBAAiB;QACnB,IAAI,CAAC,MAAM,CACP,QAAQ,CAAC,MAAM,KAAK,CAAC,IAAI,QAAQ,CAAC,CAAC,CAAC,CAAC,MAAM,KAAK,CAAC;YAC7C,QAAQ,CAAC,CAAC,CAAC,CAAC,MAAM,KAAK,CAAC,EAC5B,uDAAuD,CAAC,CAAC;QAC7D,MAAM,CAAC,QAAQ,CAAC,GAAG,CAAC,CAAC,EAAE,QAAQ,EAAE,aAAa,CAAC,CAAC;IAClD,CAAC;IAKM,cAAK,GAAZ,UACI,CAAW,EACX,QAAgE,EAChE,aAAiB;QAAjB,8BAAA,EAAA,iBAAiB;QACnB,IAAI,CAAC,MAAM,CACP,QAAQ,CAAC,MAAM,KAAK,CAAC,IAAI,QAAQ,CAAC,CAAC,CAAC,CAAC,MAAM,KAAK,CAAC;YAC7C,QAAQ,CAAC,CAAC,CAAC,CAAC,MAAM,KAAK,CAAC,IAAI,QAAQ,CAAC,CAAC,CAAC,CAAC,MAAM,KAAK,CAAC,EACxD,uDAAuD,CAAC,CAAC;QAC7D,MAAM,CAAC,QAAQ,CAAC,GAAG,CAAC,CAAC,EAAE,QAAQ,EAAE,aAAa,CAAC,CAAC;IAClD,CAAC;IAKM,cAAK,GAAZ,UACI,CAAW,EACX,QAIK,EACL,aAAiB;QAAjB,8BAAA,EAAA,iBAAiB;QACnB,IAAI,CAAC,MAAM,CACP,QAAQ,CAAC,MAAM,KAAK,CAAC,IAAI,QAAQ,CAAC,CAAC,CAAC,CAAC,MAAM,KAAK,CAAC;YAC7C,QAAQ,CAAC,CAAC,CAAC,CAAC,MAAM,KAAK,CAAC,IAAI,QAAQ,CAAC,CAAC,CAAC,CAAC,MAAM,KAAK,CAAC;YACpD,QAAQ,CAAC,CAAC,CAAC,CAAC,MAAM,KAAK,CAAC,EAC5B,uDAAuD,CAAC,CAAC;QAC7D,MAAM,CAAC,QAAQ,CAAC,GAAG,CAAC,CAAC,EAAE,QAAQ,EAAE,aAAa,CAAC,CAAC;IAClD,CAAC;IAmBM,YAAG,GAAV,UACI,CAAI,EAAE,QAAiC,EAAE,aAAiB;QAAjB,8BAAA,EAAA,iBAAiB;QAC5D,IAAI,CAAC,yBAAyB,CAAC,EAAC,CAAC,GAAA,EAAC,EAAE,KAAK,CAAC,CAAC;QAE3C,EAAE,CAAC,CAAC,CAAC,CAAC,IAAI,KAAK,CAAC,CAAC,CAAC,CAAC;YACjB,MAAM,IAAI,KAAK,CAAC,oDAAoD,CAAC,CAAC;QACxE,CAAC;QAGD,IAAM,KAAK,GAAG,QAAQ,CAAC,GAAG,CAAC,UAAA,CAAC,IAAI,OAAA,CAAC,CAAC,CAAC,CAAC,EAAJ,CAAI,CAAC,CAAC;QACtC,IAAM,IAAI,GAAG,UAAC,EAAK;YACjB,MAAM,CAAC,EAAC,CAAC,EAAE,cAAM,OAAA,EAAE,CAAC,KAAK,CAAC,KAAK,EAAE,CAAC,CAAC,KAAK,CAAC,EAAxB,CAAwB,EAAC,CAAC;QAC7C,CAAC,CAAC;QACF,MAAM,CAAC,iBAAG,CAAC,MAAM,CAAC,SAAS,CAChB,UAAA,OAAO,IAAI,OAAA,OAAO,CAAC,GAAG,CAAC,CAAC,EAAE,QAAQ,EAAE,aAAa,CAAC,EAAvC,CAAuC,EAAE,EAAC,CAAC,GAAA,EAAC,EAAE,IAAI,CACnE,CAAC;IACR,CAAC;IAiBM,cAAK,GAAZ,UAA+B,OAAY,EAAE,IAAQ;QAAR,qBAAA,EAAA,QAAQ;QACnD,IAAI,CAAC,yBAAyB,CAAC,EAAC,OAAO,SAAA,EAAC,EAAE,OAAO,CAAC,CAAC;QAEnD,IAAI,CAAC,MAAM,CAAC,OAAO,CAAC,MAAM,IAAI,CAAC,EAAE,sCAAsC,CAAC,CAAC;QACzE,EAAE,CAAC,CAAC,OAAO,CAAC,MAAM,KAAK,CAAC,CAAC,CAAC,CAAC;YACzB,MAAM,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,UAAU,CAAC,IAAI,CAAC,CAAC;QACrC,CAAC;QACD,IAAM,IAAI,GAAG,OAAO,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC;QAC7B,IAAM,KAAK,GAAG,OAAO,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC;QAC/B,IAAM,KAAK,GAAG,OAAO,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC;QAE/B,IAAI,CAAC,MAAM,CAAC,IAAI,IAAI,IAAI,EAAE,oCAAoC,CAAC,CAAC;QAEhE,OAAO,CAAC,OAAO,CAAC,UAAA,CAAC;YACf,IAAI,CAAC,iBAAiB,CAClB,KAAK,EAAE,CAAC,CAAC,KAAK,EACd,uDAAuD,CAAC,CAAC;QAC/D,CAAC,CAAC,CAAC;QAEH,OAAO,CAAC,OAAO,CAAC,UAAA,CAAC;YACf,IAAI,CAAC,MAAM,CACP,KAAK,KAAK,CAAC,CAAC,KAAK,EACjB,uDAAuD,CAAC,CAAC;QAC/D,CAAC,CAAC,CAAC;QACH,IAAM,eAAe,GAAG,OAAO,CAAC,GAAG,CAAC,UAAA,CAAC,IAAI,OAAA,CAAC,CAAC,UAAU,CAAC,IAAI,CAAC,EAAlB,CAAkB,CAAC,CAAC;QAC7D,MAAM,CAAC,kBAAS,CAAC,MAAM,CAAC,eAAe,EAAE,IAAI,CAAC,CAAC;IACjD,CAAC;IAoCM,cAAK,GAAZ,UACI,CAAI,EAAE,eAAgC,EAAE,IAAQ;QAAR,qBAAA,EAAA,QAAQ;QAClD,IAAI,CAAC,yBAAyB,CAAC,EAAC,CAAC,GAAA,EAAC,EAAE,OAAO,CAAC,CAAC;QAE7C,IAAI,GAAG,0BAAc,CAAC,IAAI,EAAE,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC;QACxC,IAAI,UAAoB,CAAC;QACzB,EAAE,CAAC,CAAC,OAAO,CAAC,eAAe,CAAC,KAAK,QAAQ,CAAC,CAAC,CAAC;YAC1C,IAAI,CAAC,MAAM,CACP,CAAC,CAAC,KAAK,CAAC,IAAI,CAAC,GAAG,eAAe,KAAK,CAAC,EACrC,+CAA+C,CAAC,CAAC;YACrD,UAAU,GAAG,KAAK,CAAC,eAAe,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,KAAK,CAAC,IAAI,CAAC,GAAG,eAAe,CAAC,CAAC;QAC5E,CAAC;QAAC,IAAI,CAAC,CAAC;YACN,IAAI,CAAC,MAAM,CACP,CAAC,CAAC,KAAK,CAAC,IAAI,CAAC,KAAK,eAAe,CAAC,MAAM,CAAC,UAAC,CAAC,EAAE,CAAC,IAAK,OAAA,CAAC,GAAG,CAAC,EAAL,CAAK,CAAC,EACzD,6DAA6D,CAAC,CAAC;YACnE,UAAU,GAAG,eAAe,CAAC;QAC/B,CAAC;QACD,IAAM,KAAK,GAAG,KAAK,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;QACpC,IAAM,IAAI,GAAG,CAAC,CAAC,KAAK,CAAC,KAAK,EAAE,CAAC;QAC7B,MAAM,CAAC,UAAU,CAAC,GAAG,CAAC,UAAA,CAAC;YACrB,IAAI,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;YACf,IAAM,KAAK,GAAG,CAAC,CAAC,KAAK,CAAC,KAAK,EAAE,IAAI,CAAC,CAAC;YACnC,KAAK,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;YACjB,MAAM,CAAC,KAAK,CAAC;QACf,CAAC,CAAC,CAAC;IACL,CAAC;IAkBM,mBAAU,GAAjB,UAAmC,CAAS,EAAE,IAAQ;QAAR,qBAAA,EAAA,QAAQ;QACpD,IAAI,CAAC,yBAAyB,CAAC,EAAC,CAAC,GAAA,EAAC,EAAE,YAAY,CAAC,CAAC;QAElD,IAAI,CAAC,MAAM,CAAC,IAAI,IAAI,CAAC,CAAC,IAAI,EAAE,oCAAoC,CAAC,CAAC;QAClE,IAAM,QAAQ,GAAG,CAAC,CAAC,KAAK,CAAC,KAAK,EAAE,CAAC;QACjC,QAAQ,CAAC,MAAM,CAAC,IAAI,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;QAC5B,MAAM,CAAC,QAAQ,CAAC,OAAO,CAAC,CAAC,EAAE,QAAQ,CAAC,CAAC;IACvC,CAAC;IAgBM,iBAAQ,GAAf,UAAgB,KAAa,EAAE,IAAY,EAAE,GAAW;QACtD,EAAE,CAAC,CAAC,GAAG,KAAK,CAAC,CAAC,CAAC,CAAC;YACd,MAAM,IAAI,KAAK,CAAC,6BAA6B,CAAC,CAAC;QACjD,CAAC;QAED,IAAM,IAAI,GAAG,CAAC,IAAI,GAAG,KAAK,CAAC,GAAG,CAAC,GAAG,GAAG,CAAC,CAAC,CAAC;QAExC,IAAM,MAAM,GAAG,mBAAmB,CAAC,GAAG,EAAE,SAAS,CAAC,CAAC;QACnD,MAAM,CAAC,CAAC,CAAC,GAAG,KAAK,CAAC;QAClB,GAAG,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE,CAAC;YACvC,MAAM,CAAC,CAAC,CAAC,GAAG,MAAM,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,IAAI,CAAC;QACnC,CAAC;QAED,MAAM,CAAC,QAAQ,CAAC,QAAQ,CAAC,MAAM,EAAE,SAAS,CAAC,CAAC;IAC9C,CAAC;IAoBM,cAAK,GAAZ,UACI,KAAa,EAAE,IAAY,EAAE,IAAQ,EACrC,KAAoC;QADP,qBAAA,EAAA,QAAQ;QACrC,sBAAA,EAAA,iBAAoC;QACtC,EAAE,CAAC,CAAC,IAAI,KAAK,CAAC,CAAC,CAAC,CAAC;YACf,MAAM,IAAI,KAAK,CAAC,4BAA4B,CAAC,CAAC;QAChD,CAAC;QAED,IAAM,aAAa,GAAG,KAAK,KAAK,IAAI,CAAC;QACrC,IAAM,2BAA2B,GAAG,KAAK,GAAG,IAAI,IAAI,IAAI,GAAG,CAAC,CAAC;QAC7D,IAAM,2BAA2B,GAAG,IAAI,GAAG,KAAK,IAAI,IAAI,GAAG,CAAC,CAAC;QAE7D,EAAE,CAAC,CAAC,aAAa,IAAI,2BAA2B;YAC5C,2BAA2B,CAAC,CAAC,CAAC;YAChC,MAAM,CAAC,QAAQ,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,EAAE,KAAK,CAAC,CAAC;QACpC,CAAC;QAED,IAAM,WAAW,GAAG,IAAI,CAAC,GAAG,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC,IAAI,GAAG,KAAK,CAAC,GAAG,IAAI,CAAC,CAAC,CAAC;QAC/D,IAAM,MAAM,GAAG,mBAAmB,CAAC,WAAW,EAAE,KAAK,CAAC,CAAC;QAEvD,EAAE,CAAC,CAAC,IAAI,GAAG,KAAK,IAAI,IAAI,KAAK,CAAC,CAAC,CAAC,CAAC;YAG/B,IAAI,GAAG,CAAC,CAAC,CAAC;QACZ,CAAC;QAED,MAAM,CAAC,CAAC,CAAC,GAAG,KAAK,CAAC;QAClB,GAAG,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE,CAAC;YACvC,MAAM,CAAC,CAAC,CAAC,GAAG,MAAM,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,IAAI,CAAC;QACnC,CAAC;QAED,MAAM,CAAC,QAAQ,CAAC,QAAQ,CAAC,MAAM,EAAE,KAAK,CAAC,CAAC;IAC1C,CAAC;IA4BM,eAAM,GAAb,UACI,KAAkB,EAAE,KAA2B,EAAE,MAAmB;QAAhD,sBAAA,EAAA,iBAA2B;QAEjD,MAAM,CAAC,IAAI,qBAAY,CAAI,KAAK,EAAE,KAAK,EAAE,MAAM,CAAC,CAAC;IACnD,CAAC;IAcM,cAAK,GAAZ,UAA+B,CAAI,EAAE,OAAe;QAAf,wBAAA,EAAA,eAAe;QAClD,OAAO,CAAC,GAAG,CAAC,WAAW,CAAC,cAAc,CAAC,CAAC,EAAE,OAAO,CAAC,CAAC,CAAC;IACtD,CAAC;IAjqCD;QADC,SAAG,CAAC,EAAC,OAAO,EAAE,SAAS,EAAE,UAAU,EAAE,UAAU,EAAC,CAAC;gCAmBjD;IAgBD;QADC,SAAG,CAAC,EAAC,OAAO,EAAE,SAAS,EAAE,UAAU,EAAE,UAAU,EAAC,CAAC;gCAQjD;IAiBD;QADC,SAAG,CAAC,EAAC,OAAO,EAAE,SAAS,EAAE,UAAU,EAAE,UAAU,EAAC,CAAC;kCAOjD;IAwBD;QADC,SAAG,CAAC,EAAC,OAAO,EAAE,SAAS,EAAE,UAAU,EAAE,UAAU,EAAC,CAAC;kCAmBjD;IAwBD;QADC,SAAG,CAAC,EAAC,OAAO,EAAE,SAAS,EAAE,UAAU,EAAE,UAAU,EAAC,CAAC;kCAmBjD;IAwBD;QADC,SAAG,CAAC,EAAC,OAAO,EAAE,SAAS,EAAE,UAAU,EAAE,UAAU,EAAC,CAAC;kCAmBjD;IAeD;QAFC,SAAG,CAAC,EAAC,OAAO,EAAE,SAAS,EAAE,UAAU,EAAE,UAAU,EAAC,CAAC;QACjD,qBAAS;8BAKT;IAeD;QAFC,SAAG,CAAC,EAAC,OAAO,EAAE,SAAS,EAAE,UAAU,EAAE,UAAU,EAAC,CAAC;QACjD,qBAAS;+BAKT;IAgBD;QAFC,SAAG,CAAC,EAAC,OAAO,EAAE,SAAS,EAAE,UAAU,EAAE,UAAU,EAAC,CAAC;QACjD,qBAAS;8BAQT;IAcD;QAFC,SAAG,CAAC,EAAC,OAAO,EAAE,SAAS,EAAE,UAAU,EAAE,UAAU,EAAC,CAAC;QACjD,qBAAS;kCAIT;IAeD;QAFC,SAAG,CAAC,EAAC,OAAO,EAAE,SAAS,EAAE,UAAU,EAAE,UAAU,EAAC,CAAC;QACjD,qBAAS;mCAIT;IAgBD;QAFC,SAAG,CAAC,EAAC,OAAO,EAAE,SAAS,EAAE,UAAU,EAAE,UAAU,EAAC,CAAC;QACjD,qBAAS;+BAWT;IAiBD;QAFC,SAAG,CAAC,EAAC,OAAO,EAAE,SAAS,EAAE,UAAU,EAAE,UAAU,EAAC,CAAC;QACjD,qBAAS;sCAcT;IAsBD;QAFC,SAAG,CAAC,EAAC,OAAO,EAAE,SAAS,EAAE,UAAU,EAAE,UAAU,EAAC,CAAC;QACjD,qBAAS;yCAcT;IAsBD;QAFC,SAAG,CAAC,EAAC,OAAO,EAAE,SAAS,EAAE,UAAU,EAAE,UAAU,EAAC,CAAC;QACjD,qBAAS;uCAST;IAYD;QADC,qBAAS;8BAqBT;IAqBD;QADC,qBAAS;qCAuBT;IAoBD;QAFC,SAAG,CAAC,EAAC,OAAO,EAAE,SAAS,EAAE,UAAU,EAAE,UAAU,EAAC,CAAC;QACjD,qBAAS;gCAUT;IAsBD;QAFC,SAAG,CAAC,EAAC,OAAO,EAAE,SAAS,EAAE,UAAU,EAAE,UAAU,EAAC,CAAC;QACjD,qBAAS;oCAST;IAoBD;QADC,SAAG,CAAC,EAAC,OAAO,EAAE,eAAe,EAAC,CAAC;kCA6E/B;IA4BD;QAFC,SAAG,CAAC,EAAC,OAAO,EAAE,SAAS,EAAE,UAAU,EAAE,iBAAiB,EAAC,CAAC;QACxD,qBAAS;iCAcT;IAgBD;QADC,SAAG,CAAC,EAAC,OAAO,EAAE,SAAS,EAAE,UAAU,EAAE,iBAAiB,EAAC,CAAC;iCAIxD;IAcD;QAFC,SAAG,CAAC,EAAC,OAAO,EAAE,SAAS,EAAE,UAAU,EAAE,iBAAiB,EAAC,CAAC;QACxD,qBAAS;8BAST;IA2BD;QAFC,SAAG,CAAC,EAAC,OAAO,EAAE,SAAS,EAAE,UAAU,EAAE,qBAAqB,EAAC,CAAC;QAC5D,qBAAS;8BA2DT;IAwBD;QAFC,SAAG,CAAC,EAAC,OAAO,EAAE,SAAS,EAAE,UAAU,EAAE,qBAAqB,EAAC,CAAC;QAC5D,qBAAS;gCAQT;IA4ED;QAFC,SAAG,CAAC,EAAC,OAAO,EAAE,SAAS,EAAE,UAAU,EAAE,iBAAiB,EAAC,CAAC;QACxD,qBAAS;6BAiBT;IAiBD;QAFC,SAAG,CAAC,EAAC,OAAO,EAAE,SAAS,EAAE,UAAU,EAAE,qBAAqB,EAAC,CAAC;QAC5D,qBAAS;+BA2BT;IAoCD;QAFC,SAAG,CAAC,EAAC,OAAO,EAAE,SAAS,EAAE,UAAU,EAAE,qBAAqB,EAAC,CAAC;QAC5D,qBAAS;+BA0BT;IAkBD;QAFC,SAAG,CAAC,EAAC,OAAO,EAAE,SAAS,EAAE,UAAU,EAAE,iBAAiB,EAAC,CAAC;QACxD,qBAAS;oCAQT;IAgBD;QAFC,qBAAS;QACT,SAAG,CAAC,EAAC,OAAO,EAAE,SAAS,EAAE,UAAU,EAAE,UAAU,EAAC,CAAC;kCAejD;IAoBD;QAFC,qBAAS;QACT,SAAG,CAAC,EAAC,OAAO,EAAE,SAAS,EAAE,UAAU,EAAE,UAAU,EAAC,CAAC;+BAgCjD;IA4BD;QADC,SAAG,CAAC,EAAC,OAAO,EAAE,SAAS,EAAE,UAAU,EAAE,UAAU,EAAC,CAAC;gCAKjD;IAcD;QADC,SAAG,CAAC,EAAC,OAAO,EAAE,SAAS,EAAE,UAAU,EAAE,UAAU,EAAC,CAAC;+BAGjD;IACH,eAAC;CAAA,AA7rCD,IA6rCC;AA7rCY,4BAAQ;AA+rCrB,6BACI,IAAY,EAAE,KAAQ;IACxB,EAAE,CAAC,CAAC,KAAK,IAAI,IAAI,IAAI,KAAK,KAAK,SAAS,CAAC,CAAC,CAAC;QACzC,MAAM,CAAC,IAAI,YAAY,CAAC,IAAI,CAAC,CAAC;IAChC,CAAC;IAAC,IAAI,CAAC,EAAE,CAAC,CAAC,KAAK,KAAK,OAAO,CAAC,CAAC,CAAC;QAC7B,MAAM,CAAC,IAAI,UAAU,CAAC,IAAI,CAAC,CAAC;IAC9B,CAAC;IAAC,IAAI,CAAC,EAAE,CAAC,CAAC,KAAK,KAAK,MAAM,CAAC,CAAC,CAAC;QAC5B,MAAM,CAAC,IAAI,UAAU,CAAC,IAAI,CAAC,CAAC;IAC9B,CAAC;IAAC,IAAI,CAAC,CAAC;QACN,MAAM,IAAI,KAAK,CAAC,6BAA6B,CAAC,CAAC;IACjD,CAAC;AACH,CAAC;AAED,4BACI,IAAY,EAAE,KAAQ;IACxB,IAAM,KAAK,GAAG,mBAAmB,CAAC,IAAI,EAAE,KAAK,CAAC,CAAC;IAC/C,GAAG,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,KAAK,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE,CAAC;QACtC,KAAK,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC;IACf,CAAC;IACD,MAAM,CAAC,KAAK,CAAC;AACf,CAAC;AAED,sBACI,CAAe,EAAE,KAAQ;IAC3B,EAAE,CAAC,CAAC,kBAAkB,CAAC,CAAC,EAAE,KAAK,CAAC,CAAC,CAAC,CAAC;QACjC,MAAM,CAAC,CAAmB,CAAC;IAC7B,CAAC;IACD,EAAE,CAAC,CAAC,KAAK,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QACrB,CAAC,GAAG,IAAI,CAAC,OAAO,CAAC,CAAa,CAAC,CAAC;IAClC,CAAC;IACD,MAAM,CAAC,IAAI,CAAC,cAAc,CAAC,CAAC,EAAE,KAAK,CAAC,CAAC;AACvC,CAAC;AAED,4BACI,CAAe,EAAE,KAAQ;IAC3B,MAAM,CAAC,CAAC,CAAC,YAAY,YAAY,IAAI,KAAK,KAAK,SAAS,CAAC;QACrD,CAAC,CAAC,YAAY,UAAU,IAAI,KAAK,KAAK,OAAO,CAAC;QAC9C,CAAC,CAAC,YAAY,UAAU,IAAI,KAAK,KAAK,MAAM,CAAC,CAAC;AACpD,CAAC","sourcesContent":["/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {doc} from '../doc';\n// import {ForwardFunc} from '../engine';\nimport {ENV} from '../environment';\n// tslint:disable-next-line:max-line-length\nimport {Scalar, Tensor, Tensor1D, Tensor2D, Tensor3D, Tensor4D, TensorBuffer} from '../tensor';\nimport * as tensor_util from '../tensor_util';\n// tslint:disable-next-line:max-line-length\nimport {ArrayData, DataType, DataTypeMap, Rank, ShapeMap, TensorLike, TensorLike1D, TensorLike2D, TensorLike3D, TensorLike4D, TypedArray} from '../types';\nimport * as util from '../util';\nimport {parseAxisParam} from './axis_util';\nimport {ConcatOps} from './concat';\nimport {operation} from './operation';\nimport {MPRandGauss} from './rand';\n\nexport class ArrayOps {\n  /**\n   * Creates a `Tensor` with the provided values, shape and dtype.\n   *\n   * ```js\n   * // Pass an array of values to create a vector.\n   * tf.tensor([1, 2, 3, 4]).print();\n   * ```\n   *\n   * ```js\n   * // Pass a nested array of values to make a matrix or a higher\n   * // dimensional tensor.\n   * tf.tensor([[1, 2], [3, 4]]).print();\n   * ```\n   *\n   * ```js\n   * // Pass a flat array and specify a shape yourself.\n   * tf.tensor([1, 2, 3, 4], [2, 2]).print();\n   * ```\n   *\n   * @param values The values of the tensor. Can be nested array of numbers,\n   *     or a flat array, or a `TypedArray`.\n   * @param shape The shape of the tensor. Optional. If not provided,\n   *   it is inferred from `values`.\n   * @param dtype The data type.\n   */\n  @doc({heading: 'Tensors', subheading: 'Creation'})\n  static tensor<R extends Rank>(\n      values: TensorLike, shape?: ShapeMap[R], dtype: DataType = 'float32'):\n      Tensor<R> {\n    const inferredShape = util.inferShape(values);\n    if (shape != null && inferredShape.length !== 1) {\n      util.assertShapesMatch(\n          shape, inferredShape,\n          `Error creating a new Tensor. ` +\n              `Inferred shape (${inferredShape}) does not match the ` +\n              `provided shape (${shape}). `);\n    }\n    if (!util.isTypedArray(values) && !Array.isArray(values)) {\n      values = [values] as number[];\n    }\n    shape = shape || inferredShape;\n    return Tensor.make(\n        shape, {values: toTypedArray(values as ArrayData<DataType>, dtype)},\n        dtype);\n  }\n\n  /**\n   * Creates rank-0 `Tensor` (scalar) with the provided value and dtype.\n   *\n   * The same functionality can be achieved with `tensor`, but in general\n   * we recommend using `scalar` as it makes the code more readable.\n   *\n   * ```js\n   * tf.scalar(3.14).print();\n   * ```\n   *\n   * @param value The value of the scalar.\n   * @param dtype The data type.\n   */\n  @doc({heading: 'Tensors', subheading: 'Creation'})\n  static scalar(value: number|boolean, dtype: DataType = 'float32'): Scalar {\n    if (util.isTypedArray(value) || Array.isArray(value)) {\n      throw new Error(\n          'Error creating a new Scalar: value must be a primitive ' +\n          '(number|boolean)');\n    }\n    return ArrayOps.tensor(value, [], dtype);\n  }\n\n  /**\n   * Creates rank-1 `Tensor` with the provided values, shape and dtype.\n   *\n   * The same functionality can be achieved with `tensor`, but in general\n   * we recommend using `tensor1d` as it makes the code more readable.\n   *\n   * ```js\n   * tf.tensor1d([1, 2, 3]).print();\n   * ```\n   *\n   * @param values The values of the tensor. Can be array of numbers,\n   *     or a `TypedArray`.\n   * @param dtype The data type.\n   */\n  @doc({heading: 'Tensors', subheading: 'Creation'})\n  static tensor1d(values: TensorLike1D, dtype: DataType = 'float32'): Tensor1D {\n    const inferredShape = util.inferShape(values);\n    if (inferredShape.length !== 1) {\n      throw new Error('tensor1d() requires values to be a flat/TypedArray');\n    }\n    return ArrayOps.tensor(values, inferredShape as [number], dtype);\n  }\n\n  /**\n   * Creates rank-2 `Tensor` with the provided values, shape and dtype.\n   *\n   * The same functionality can be achieved with `tensor`, but in general\n   * we recommend using `tensor2d` as it makes the code more readable.\n   *\n   *  ```js\n   * // Pass a nested array.\n   * tf.tensor2d([[1, 2], [3, 4]]).print();\n   * ```\n   * ```js\n   * // Pass a flat array and specify a shape.\n   * tf.tensor2d([1, 2, 3, 4], [2, 2]).print();\n   * ```\n   *\n   * @param values The values of the tensor. Can be nested array of numbers,\n   *     or a flat array, or a `TypedArray`.\n   * @param shape The shape of the tensor. If not provided, it is inferred from\n   *     `values`.\n   * @param dtype The data type.\n   */\n  @doc({heading: 'Tensors', subheading: 'Creation'})\n  static tensor2d(\n      values: TensorLike2D, shape?: [number, number],\n      dtype: DataType = 'float32'): Tensor2D {\n    if (shape != null && shape.length !== 2) {\n      throw new Error('tensor2d() requires shape to have two numbers');\n    }\n    const inferredShape = util.inferShape(values);\n    if (inferredShape.length !== 2 && inferredShape.length !== 1) {\n      throw new Error(\n          'tensor2d() requires values to be number[][] or flat/TypedArray');\n    }\n    if (inferredShape.length === 1 && shape == null) {\n      throw new Error(\n          'tensor2d() requires shape to be provided when `values` ' +\n          'are a flat/TypedArray');\n    }\n    shape = shape || inferredShape as [number, number];\n    return ArrayOps.tensor(values, shape, dtype);\n  }\n\n  /**\n   * Creates rank-3 `Tensor` with the provided values, shape and dtype.\n   *\n   * The same functionality can be achieved with `tensor`, but in general\n   * we recommend using `tensor3d` as it makes the code more readable.\n   *\n   *  ```js\n   * // Pass a nested array.\n   * tf.tensor3d([[[1], [2]], [[3], [4]]]).print();\n   * ```\n   * ```js\n   * // Pass a flat array and specify a shape.\n   * tf.tensor3d([1, 2, 3, 4], [2, 2, 1]).print();\n   * ```\n   *\n   * @param values The values of the tensor. Can be nested array of numbers,\n   *     or a flat array, or a `TypedArray`.\n   * @param shape The shape of the tensor. If not provided,  it is inferred from\n   *     `values`.\n   * @param dtype The data type.\n   */\n  @doc({heading: 'Tensors', subheading: 'Creation'})\n  static tensor3d(\n      values: TensorLike3D, shape?: [number, number, number],\n      dtype: DataType = 'float32'): Tensor3D {\n    if (shape != null && shape.length !== 3) {\n      throw new Error('tensor3d() requires shape to have three numbers');\n    }\n    const inferredShape = util.inferShape(values);\n    if (inferredShape.length !== 3 && inferredShape.length !== 1) {\n      throw new Error(\n          'tensor3d() requires values to be number[][][] or flat/TypedArray');\n    }\n    if (inferredShape.length === 1 && shape == null) {\n      throw new Error(\n          'tensor3d() requires shape to be provided when `values` ' +\n          'are a flat array');\n    }\n    shape = shape || inferredShape as [number, number, number];\n    return ArrayOps.tensor(values, shape, dtype);\n  }\n\n  /**\n   * Creates rank-4 `Tensor` with the provided values, shape and dtype.\n   *\n   * The same functionality can be achieved with `tensor`, but in general\n   * we recommend using `tensor4d` as it makes the code more readable.\n   *\n   *  ```js\n   * // Pass a nested array.\n   * tf.tensor4d([[[[1], [2]], [[3], [4]]]]).print();\n   * ```\n   * ```js\n   * // Pass a flat array and specify a shape.\n   * tf.tensor4d([1, 2, 3, 4], [1, 2, 2, 1]).print();\n   * ```\n   *\n   * @param values The values of the tensor. Can be nested array of numbers,\n   *     or a flat array, or a `TypedArray`.\n   * @param shape The shape of the tensor. Optional. If not provided,\n   *   it is inferred from `values`.\n   * @param dtype The data type.\n   */\n  @doc({heading: 'Tensors', subheading: 'Creation'})\n  static tensor4d(\n      values: TensorLike4D, shape?: [number, number, number, number],\n      dtype: DataType = 'float32'): Tensor4D {\n    if (shape != null && shape.length !== 4) {\n      throw new Error('tensor4d() requires shape to have four numbers');\n    }\n    const inferredShape = util.inferShape(values);\n    if (inferredShape.length !== 4 && inferredShape.length !== 1) {\n      throw new Error(\n          'tensor4d() requires values to be number[][][][] or flat/TypedArray');\n    }\n    if (inferredShape.length === 1 && shape == null) {\n      throw new Error(\n          'tensor4d() requires shape to be provided when `values` ' +\n          'are a flat array');\n    }\n    shape = shape || inferredShape as [number, number, number, number];\n    return ArrayOps.tensor(values, shape, dtype);\n  }\n\n  /**\n   * Creates a `Tensor` with all elements set to 1.\n   *\n   * ```js\n   * tf.ones([2, 2]).print();\n   * ```\n   *\n   * @param shape An array of integers defining the output tensor shape.\n   * @param dtype The type of an element in the resulting tensor. Defaults to\n   *     'float'.\n   */\n  @doc({heading: 'Tensors', subheading: 'Creation'})\n  @operation\n  static ones<R extends Rank>(shape: ShapeMap[R], dtype: DataType = 'float32'):\n      Tensor<R> {\n    const values = makeOnesTypedArray(util.sizeFromShape(shape), dtype);\n    return Tensor.make(shape, {values}, dtype);\n  }\n\n  /**\n   * Creates a `Tensor` with all elements set to 0.\n   *\n   * ```js\n   * tf.zeros([2, 2]).print();\n   * ```\n   *\n   * @param shape An array of integers defining the output tensor shape.\n   * @param dtype The type of an element in the resulting tensor. Can\n   *     be 'float32', 'int32' or 'bool'. Defaults to 'float'.\n   */\n  @doc({heading: 'Tensors', subheading: 'Creation'})\n  @operation\n  static zeros<R extends Rank>(shape: ShapeMap[R], dtype: DataType = 'float32'):\n      Tensor<R> {\n    const values = makeZerosTypedArray(util.sizeFromShape(shape), dtype);\n    return Tensor.make(shape, {values}, dtype);\n  }\n\n  /**\n   * Creates a `Tensor` filled with a scalar value.\n   *\n   * ```js\n   * tf.fill([2, 2], 4).print();\n   * ```\n   *\n   * @param shape An array of integers defining the output tensor shape.\n   * @param value The scalar value to fill the tensor with.\n   * @param dtype The type of an element in the resulting tensor. Defaults to\n   * 'float'.\n   */\n  @doc({heading: 'Tensors', subheading: 'Creation'})\n  @operation\n  static fill<R extends Rank>(\n      shape: ShapeMap[R], value: number, dtype: DataType = 'float32'):\n      Tensor<R> {\n    const values =\n        util.getTypedArrayFromDType(dtype, util.sizeFromShape(shape));\n    values.fill(value);\n    return Tensor.make(shape, {values}, dtype);\n  }\n\n  /**\n   * Creates a `Tensor` with all elements set to 1 with the same shape as the\n   * given tensor.\n   *\n   * ```js\n   * const x = tf.tensor([1, 2]);\n   * tf.onesLike(x).print();\n   * ```\n   * @param x A tensor.\n   */\n  @doc({heading: 'Tensors', subheading: 'Creation'})\n  @operation\n  static onesLike<T extends Tensor>(x: T): T {\n    util.assertArgumentsAreTensors({x}, 'onesLike');\n    return ArrayOps.ones(x.shape, x.dtype) as T;\n  }\n\n  /**\n   * Creates a `Tensor` with all elements set to 0 with the same shape as the\n   * given tensor.\n   *\n   * ```js\n   * const x = tf.tensor([1, 2]);\n   * tf.zerosLike(x).print();\n   * ```\n   *\n   * @param x The tensor of required shape.\n   */\n  @doc({heading: 'Tensors', subheading: 'Creation'})\n  @operation\n  static zerosLike<T extends Tensor>(x: T): T {\n    util.assertArgumentsAreTensors({x}, 'zerosLike');\n    return ArrayOps.zeros(x.shape, x.dtype) as T;\n  }\n\n  /**\n   * Creates a new tensor with the same values and shape as the specified\n   * tensor.\n   *\n   * ```js\n   * const x = tf.tensor([1, 2]);\n   *\n   * x.clone().print();\n   * ```\n   *\n   * @param x The tensor to clone.\n   */\n  @doc({heading: 'Tensors', subheading: 'Creation'})\n  @operation\n  static clone<T extends Tensor>(x: T): T {\n    util.assertArgumentsAreTensors({x}, 'clone');\n    const der = (dy: T) => {\n      return {x: () => dy.toFloat()};\n    };\n\n    return ENV.engine.runKernel(\n               backend =>\n                   Tensor.make(x.shape, {dataId: x.dataId}, x.dtype) as T,\n               {x}, der) as T;\n  }\n\n  /**\n   * Creates a `Tensor` with values sampled from a normal distribution.\n   *\n   * ```js\n   * tf.randomNormal([2, 2]).print();\n   * ```\n   *\n   * @param shape An array of integers defining the output tensor shape.\n   * @param mean The mean of the normal distribution.\n   * @param stdDev The standard deviation of the normal distribution.\n   * @param dtype The data type of the output.\n   * @param seed The seed for the random number generator.\n   */\n  @doc({heading: 'Tensors', subheading: 'Creation'})\n  @operation\n  static randomNormal<R extends Rank>(\n      shape: ShapeMap[R], mean = 0, stdDev = 1, dtype?: 'float32'|'int32',\n      seed?: number): Tensor<R> {\n    if (dtype != null && (dtype as DataType) === 'bool') {\n      throw new Error(`Unsupported data type ${dtype}`);\n    }\n    const randGauss =\n        new MPRandGauss(mean, stdDev, dtype, false /* truncated */, seed);\n    const res = ArrayOps.buffer(shape, dtype);\n    for (let i = 0; i < res.values.length; i++) {\n      res.values[i] = randGauss.nextValue();\n    }\n    return res.toTensor();\n  }\n\n  /**\n   * Creates a `Tensor` with values sampled from a truncated normal\n   * distribution.\n   *\n   * ```js\n   * tf.truncatedNormal([2, 2]).print();\n   * ```\n   *\n   * The generated values follow a normal distribution with specified mean and\n   * standard deviation, except that values whose magnitude is more than 2\n   * standard deviations from the mean are dropped and re-picked.\n   *\n   * @param shape An array of integers defining the output tensor shape.\n   * @param mean The mean of the normal distribution.\n   * @param stdDev The standard deviation of the normal distribution.\n   * @param dtype The data type of the output tensor.\n   * @param seed The seed for the random number generator.\n   */\n  @doc({heading: 'Tensors', subheading: 'Creation'})\n  @operation\n  static truncatedNormal<R extends Rank>(\n      shape: ShapeMap[R], mean = 0, stdDev = 1, dtype?: 'float32'|'int32',\n      seed?: number): Tensor<R> {\n    if (dtype != null && (dtype as DataType) === 'bool') {\n      throw new Error(`Unsupported data type ${dtype}`);\n    }\n    const randGauss =\n        new MPRandGauss(mean, stdDev, dtype, true /* truncated */, seed);\n    const res = ArrayOps.buffer(shape, dtype);\n    for (let i = 0; i < res.values.length; i++) {\n      res.values[i] = randGauss.nextValue();\n    }\n    return res.toTensor();\n  }\n\n  /**\n   * Creates a `Tensor` with values sampled from a uniform distribution.\n   *\n   * The generated values follow a uniform distribution in the range [minval,\n   * maxval). The lower bound minval is included in the range, while the upper\n   * bound maxval is excluded.\n   *\n   * ```js\n   * tf.randomUniform([2, 2]).print();\n   * ```\n   *\n   * @param shape An array of integers defining the output tensor shape.\n   * @param minval The lower bound on the range of random values to generate.\n   *   Defaults to 0.\n   * @param maxval The upper bound on the range of random values to generate.\n   *   Defaults to 1.\n   * @param dtype The data type of the output tensor. Defaults to 'float32'.\n   */\n  @doc({heading: 'Tensors', subheading: 'Creation'})\n  @operation\n  static randomUniform<R extends Rank>(\n      shape: ShapeMap[R], minval = 0, maxval = 1, dtype: DataType = 'float32'):\n      Tensor<R> {\n    const res = ArrayOps.buffer(shape, dtype);\n    for (let i = 0; i < res.values.length; i++) {\n      res.values[i] = util.randUniform(minval, maxval);\n    }\n    return res.toTensor();\n  }\n\n  /**\n   * Creates a `Tensor` with values sampled from a random number generator\n   * function defined by the user.\n   *\n   * @param shape An array of integers defining the output tensor shape.\n   * @param randFunction A random number generator function which is called for\n   * each element in the output tensor.\n   * @param dtype The data type of the output tensor. Defaults to 'float32'.\n   */\n  @operation\n  static rand<R extends Rank>(\n      shape: ShapeMap[R], randFunction: () => number, dtype?: DataType):\n      Tensor<R> {\n    const size = util.sizeFromShape(shape);\n\n    let values = null;\n    if (dtype == null || dtype === 'float32') {\n      values = new Float32Array(size);\n    } else if (dtype === 'int32') {\n      values = new Int32Array(size);\n    } else if (dtype === 'bool') {\n      values = new Uint8Array(size);\n    } else {\n      throw new Error(`Unknown data type ${dtype}`);\n    }\n\n    for (let i = 0; i < size; i++) {\n      values[i] = randFunction();\n    }\n    return Tensor.make(shape, {values}, dtype);\n  }\n\n  /**\n   * Creates a `Tensor` with values drawn from a multinomial distribution.\n   *\n   * ```js\n   * const probs = tf.tensor([.75, .25]);\n   * tf.multinomial(probs, 3).print();\n   * ```\n   *\n   * @param logits 1D array with unnormalized log-probabilities, or\n   *     2D array of shape `[batchSize, numOutcomes]`. See the `normalized`\n   *     parameter.\n   * @param numSamples Number of samples to draw for each row slice.\n   * @param seed The seed number.\n   * @param normalized Whether the provided `logits` are normalized true\n   *     probabilities (sum to 1). Defaults to false.\n   * @return 1D array of shape `[numSamples]`, or 2D array of shape\n   *     `[batchSize, numSamples]`, depending on the rank of the input.\n   */\n  @operation\n  static multinomial(\n      logits: Tensor1D|Tensor2D, numSamples: number, seed?: number,\n      normalized = false): Tensor1D|Tensor2D {\n    util.assertArgumentsAreTensors({logits}, 'multinomial');\n    const numOutcomes = logits.size;\n    const origRank = logits.rank;\n    if (numOutcomes < 2) {\n      throw new Error(\n          `Error in multinomial: you need at least 2 outcomes, but got ` +\n          `${numOutcomes}.`);\n    }\n    if (origRank > 2) {\n      throw new Error(\n          `Rank of probabilities must be 1 or 2, but is ${origRank}`);\n    }\n    seed = seed || Math.random();\n    const logits2D = origRank === 1 ? logits.as2D(1, -1) : logits as Tensor2D;\n    const res = ENV.engine.runKernel(\n        backend => backend.multinomial(logits2D, normalized, numSamples, seed),\n        {logits2D});\n\n    return origRank === 1 ? res.as1D() : res;\n  }\n\n  /**\n   * Creates a one-hot `Tensor`. The locations represented by `indices` take\n   * value `onValue` (defaults to 1), while all other locations take value\n   * `offValue` (defaults to 0).\n   *\n   * ```js\n   * tf.oneHot(tf.tensor1d([0, 1], 'int32'), 3).print();\n   * ```\n   *\n   * @param indices `Tensor1D` of indices with dtype `int32`.\n   * @param depth The depth of the one hot dimension.\n   * @param onValue A number used to fill in output when the index matches\n   * the location.\n   * @param offValue A number used to fill in the output when the index does\n   *     not match the location.\n   */\n  @doc({heading: 'Tensors', subheading: 'Creation'})\n  @operation\n  static oneHot(indices: Tensor1D, depth: number, onValue = 1, offValue = 0):\n      Tensor2D {\n    util.assert(indices.dtype === 'int32', 'Indices must be of dtype `int32`');\n    if (depth < 2) {\n      throw new Error(`Error in oneHot: depth must be >=2, but it is ${depth}`);\n    }\n    return ENV.engine.runKernel(\n        backend => backend.oneHot(indices, depth, onValue, offValue),\n        {indices});\n  }\n\n  /**\n   * Creates a `Tensor` from an image.\n   *\n   * ```js\n   * const image = new ImageData(1, 1);\n   * image.data[0] = 100;\n   * image.data[1] = 150;\n   * image.data[2] = 200;\n   * image.data[3] = 255;\n   *\n   * tf.fromPixels(image).print();\n   * ```\n   *\n   * @param pixels The input image to construct the tensor from.\n   * @param numChannels The number of channels of the output tensor. The\n   * supported image types are all 4-channel by default, a numChannels value\n   * less than 4 allows you to ignore channels.\n   */\n  @doc({heading: 'Tensors', subheading: 'Creation'})\n  @operation\n  static fromPixels(\n      pixels: ImageData|HTMLImageElement|HTMLCanvasElement|HTMLVideoElement,\n      numChannels = 3): Tensor3D {\n    if (numChannels > 4) {\n      throw new Error(\n          'Cannot construct Tensor with more than 4 channels from pixels.');\n    }\n    return ENV.engine.fromPixels(pixels, numChannels);\n  }\n\n  /**\n   * Draws a `Tensor` of pixel values to a byte array or optionally a\n   * canvas.\n   *\n   * When the dtype of the input is 'float32', we assume values in the range\n   * [0-1]. Otherwise, when input is 'int32', we assume values in the range\n   * [0-255].\n   *\n   * Returns a promise that resolves when the canvas has been drawn to.\n   *\n   * @param img A rank-2 or rank-3 tensor. If rank-2, draws grayscale. If\n   *     rank-3, must have depth of 1, 3 or 4. When depth of 1, draws grayscale.\n   *     When depth of 3, we draw with the first three components of the depth\n   *     dimension corresponding to r, g, b and alpha = 1. When depth of 4,\n   *     all four components of the depth dimension correspond to r, g, b, a.\n   * @param canvas The canvas to draw to.\n   */\n  @doc({heading: 'Visualization'})\n  static async toPixels(img: Tensor2D|Tensor3D, canvas?: HTMLCanvasElement):\n      Promise<Uint8ClampedArray> {\n    util.assertArgumentsAreTensors({img}, 'toPixels');\n\n    if (img.rank !== 2 && img.rank !== 3) {\n      throw new Error(\n          `toPixels only supports rank 2 or 3 tensors, got rank ${img.rank}.`);\n    }\n    const [height, width] = img.shape.slice(0, 2);\n    const depth = img.rank === 2 ? 1 : img.shape[2];\n\n    if (depth > 4 || depth === 2) {\n      throw new Error(\n          `toPixels only supports depth of size ` +\n          `1, 3 or 4 but got ${depth}`);\n    }\n\n    const min = (await img.min().data())[0];\n    const max = (await img.max().data())[0];\n    if (img.dtype === 'float32') {\n      if (min < 0 || max > 1) {\n        throw new Error(\n            `Tensor values for a float32 Tensor must be in the ` +\n            `range [0 - 1] but got range [${min} - ${max}].`);\n      }\n    } else if (img.dtype === 'int32') {\n      if (min < 0 || max > 255) {\n        throw new Error(\n            `Tensor values for a int32 Tensor must be in the ` +\n            `range [0 - 255] but got range [${min} - ${max}].`);\n      }\n    } else {\n      throw new Error(\n          `Unsupported type for toPixels: ${img.dtype}.` +\n          ` Please use float32 or int32 tensors.`);\n    }\n\n    const data = await img.data();\n    const multiplier = img.dtype === 'float32' ? 255 : 1;\n    const bytes = new Uint8ClampedArray(width * height * 4);\n\n    for (let i = 0; i < height * width; ++i) {\n      let r, g, b, a;\n      if (depth === 1) {\n        r = data[i] * multiplier;\n        g = data[i] * multiplier;\n        b = data[i] * multiplier;\n        a = 255;\n      } else if (depth === 3) {\n        r = data[i * 3] * multiplier;\n        g = data[i * 3 + 1] * multiplier;\n        b = data[i * 3 + 2] * multiplier;\n        a = 255;\n      } else if (depth === 4) {\n        r = data[i * 4] * multiplier;\n        g = data[i * 4 + 1] * multiplier;\n        b = data[i * 4 + 2] * multiplier;\n        a = data[i * 4 + 3] * multiplier;\n      }\n\n      const j = i * 4;\n      bytes[j + 0] = Math.round(r);\n      bytes[j + 1] = Math.round(g);\n      bytes[j + 2] = Math.round(b);\n      bytes[j + 3] = Math.round(a);\n    }\n\n    if (canvas != null) {\n      canvas.width = width;\n      canvas.height = height;\n      const ctx = canvas.getContext('2d');\n      const imageData = new ImageData(bytes, width, height);\n      ctx.putImageData(imageData, 0, 0);\n    }\n\n    return bytes;\n  }\n\n  /**\n   * Reshapes a `Tensor` to a given shape.\n   *\n   * Given a input tensor, returns a new tensor with the same values as the\n   * input tensor with shape `shape`.\n   *\n   * If one component of shape is the special value -1, the size of that\n   * dimension is computed so that the total size remains constant. In\n   * particular, a shape of [-1] flattens into 1-D. At most one component of\n   * shape can be -1.\n   *\n   * If shape is 1-D or higher, then the operation returns a tensor with shape\n   * shape filled with the values of tensor. In this case, the number of\n   * elements implied by shape must be the same as the number of elements in\n   * tensor.\n   *\n   * ```js\n   * const x = tf.tensor1d([1, 2, 3, 4]);\n   * x.reshape([2, 2]).print();\n   * ```\n   *\n   * @param x The input tensor to be reshaped.\n   * @param shape An array of integers defining the output tensor shape.\n   */\n  @doc({heading: 'Tensors', subheading: 'Transformations'})\n  @operation\n  static reshape<R2 extends Rank>(x: Tensor, shape: ShapeMap[R2]): Tensor<R2> {\n    util.assertArgumentsAreTensors({x}, 'reshape');\n\n    shape = util.inferFromImplicitShape(shape, x.size);\n    util.assert(\n        x.size === util.sizeFromShape(shape),\n        'new shape and old shape must have the same number of elements.');\n\n    const grad = (dy: Tensor<R2>) => {\n      return {x: () => dy.reshape(x.shape)};\n    };\n    return ENV.engine.runKernel(\n        backend => backend.reshape(x, shape), {x}, grad);\n  }\n\n  /**\n   * Removes dimensions of size 1 from the shape of a `Tensor`.\n   *\n   * ```js\n   * const x = tf.tensor([1, 2, 3, 4], [1, 1, 4]);\n   * x.squeeze().print();\n   * ```\n   *\n   * @param x The input tensor to be squeezed.\n   * @param axis An optional list of numbers. If specified, only\n   *     squeezes the dimensions listed. The dimension index starts at 0. It is\n   *     an error to squeeze a dimension that is not 1.\n   */\n  @doc({heading: 'Tensors', subheading: 'Transformations'})\n  static squeeze<T extends Tensor>(x: Tensor, axis?: number[]): T {\n    util.assertArgumentsAreTensors({x}, 'squeeze');\n    return ArrayOps.reshape(x, util.squeezeShape(x.shape, axis).newShape) as T;\n  }\n\n  /**\n   * Casts a `Tensor` to a new dtype.\n   *\n   * ```js\n   * const x = tf.tensor1d([1.5, 2.5, 3]);\n   * tf.cast(x, 'int32').print();\n   * ```\n   * @param x The input tensor to be casted.\n   * @param dtype The dtype to cast the input tensor to.\n   */\n  @doc({heading: 'Tensors', subheading: 'Transformations'})\n  @operation\n  static cast<T extends Tensor>(x: T, dtype: DataType): T {\n    util.assertArgumentsAreTensors({x}, 'cast');\n\n    const grad = (dy: T) => {\n      return {x: () => dy.clone()};\n    };\n    return ENV.engine.runKernel(backend => backend.cast(x, dtype), {x}, grad) as\n        T;\n  }\n\n  /**\n   * Construct an tensor by repeating it the number of times given by reps.\n   *\n   * This operation creates a new tensor by replicating `input` `reps`\n   * times. The output tensor's i'th dimension has `input.shape[i] *\n   * reps[i]` elements, and the values of `input` are replicated\n   * `reps[i]` times along the i'th dimension. For example, tiling\n   * `[a, b, c, d]` by `[2]` produces `[a, b, c, d, a, b, c, d]`.\n   *\n   * ```js\n   * const a = tf.tensor1d([1, 2]);\n   *\n   * a.tile([2]).print();    // or a.tile([2])\n   * ```\n   *\n   * ```js\n   * const a = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n   *\n   * a.tile([1, 2]).print();  // or a.tile([1, 2])\n   * ```\n   * @param x The tensor to transpose.\n   * @param reps Determines the number of replications per dimension.\n   */\n  @doc({heading: 'Tensors', subheading: 'Slicing and Joining'})\n  @operation\n  static tile<T extends Tensor>(x: T, reps: number[]): T {\n    util.assertArgumentsAreTensors({x}, 'tile');\n\n    util.assert(\n        x.rank === reps.length,\n        `Error in transpose: rank of input ${x.rank} ` +\n            `must match length of reps ${reps}.`);\n    const grad = (dy: T) => {\n      const derX = () => {\n        let xGrad = ArrayOps.zerosLike(x);\n        // TODO(cais): Maybe reduce memory footprint by avoiding repeated\n        // slicing.\n        if (x.rank === 1) {\n          for (let i = 0; i < reps[0]; ++i) {\n            xGrad = xGrad.add(dy.slice([i * x.shape[0]], [x.shape[0]]));\n          }\n        } else if (x.rank === 2) {\n          for (let i = 0; i < reps[0]; ++i) {\n            for (let j = 0; j < reps[1]; ++j) {\n              xGrad = xGrad.add(dy.slice(\n                  [i * x.shape[0], j * x.shape[1]], [x.shape[0], x.shape[1]]));\n            }\n          }\n        } else if (x.rank === 3) {\n          for (let i = 0; i < reps[0]; ++i) {\n            for (let j = 0; j < reps[1]; ++j) {\n              for (let k = 0; k < reps[2]; ++k) {\n                xGrad = xGrad.add(dy.slice(\n                    [i * x.shape[0], j * x.shape[1], k * x.shape[2]],\n                    [x.shape[0], x.shape[1], x.shape[2]]));\n              }\n            }\n          }\n        } else if (x.rank === 4) {\n          for (let i = 0; i < reps[0]; ++i) {\n            for (let j = 0; j < reps[1]; ++j) {\n              for (let k = 0; k < reps[2]; ++k) {\n                for (let l = 0; l < reps[3]; ++l) {\n                  xGrad = xGrad.add(dy.slice(\n                      [\n                        i * x.shape[0], j * x.shape[1], k * x.shape[2],\n                        l * x.shape[3]\n                      ],\n                      [x.shape[0], x.shape[1], x.shape[2], x.shape[3]]));\n                }\n              }\n            }\n          }\n        } else {\n          throw new Error(\n              `Gradient for tile operation is not implemented for rank-` +\n              `${x.rank} tensors yet.`);\n        }\n        return xGrad;\n      };\n      return {x: derX};\n    };\n    return ENV.engine.runKernel(backend => backend.tile(x, reps), {x}, grad);\n  }\n\n  /**\n   * Gather slices from tensor `x`'s axis `axis` according to `indices`.\n   *\n   * ```js\n   * const x = tf.tensor1d([1, 2, 3, 4]);\n   * const indices = tf.tensor1d([1, 3, 3], 'int32');\n   *\n   * x.gather(indices).print();\n   * ```\n   *\n   * ```js\n   * const x = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n   * const indices = tf.tensor1d([1, 1, 0], 'int32');\n   *\n   * x.gather(indices).print();\n   * ```\n   * @param x The input tensor whose slices to be gathered.\n   * @param indices The indices of the values to extract.\n   * @param axis The axis over which to select values. Defaults to 0.\n   */\n  @doc({heading: 'Tensors', subheading: 'Slicing and Joining'})\n  @operation\n  static gather<T extends Tensor>(x: T, indices: Tensor1D, axis = 0): T {\n    util.assertArgumentsAreTensors({x, indices}, 'gather');\n\n    util.assert(indices.dtype === 'int32', 'Indices must be of dtype `int32`');\n    const axes = parseAxisParam(axis, x.shape);\n    return ENV.engine.runKernel(\n        backend => backend.gather(x, indices, axes[0]), {x, indices});\n  }\n\n  /**\n   * Pads a `Tensor1D` with a given value and paddings. See `pad` for details.\n   */\n  static pad1d(x: Tensor1D, paddings: [number, number], constantValue = 0):\n      Tensor1D {\n    util.assert(\n        paddings.length === 2,\n        'Invalid number of paddings. Must be length of 2.');\n    return ArrayOps.pad(x, [paddings], constantValue);\n  }\n\n  /**\n   * Pads a `Tensor2D` with a given value and paddings. See `pad` for details.\n   */\n  static pad2d(\n      x: Tensor2D, paddings: [[number, number], [number, number]],\n      constantValue = 0): Tensor2D {\n    util.assert(\n        paddings.length === 2 && paddings[0].length === 2 &&\n            paddings[1].length === 2,\n        'Invalid number of paddings. Must be length of 2 each.');\n    return ArrayOps.pad(x, paddings, constantValue);\n  }\n\n  /**\n   * Pads a `Tensor3D` with a given value and paddings. See `pad` for details.\n   */\n  static pad3d(\n      x: Tensor3D,\n      paddings: [[number, number], [number, number], [number, number]],\n      constantValue = 0): Tensor3D {\n    util.assert(\n        paddings.length === 3 && paddings[0].length === 2 &&\n            paddings[1].length === 2 && paddings[2].length === 2,\n        'Invalid number of paddings. Must be length of 2 each.');\n    return ArrayOps.pad(x, paddings, constantValue);\n  }\n\n  /**\n   * Pads a `Tensor4D` with a given value and paddings. See `pad` for details.\n   */\n  static pad4d(\n      x: Tensor4D,\n      paddings:\n          [\n            [number, number], [number, number], [number, number],\n            [number, number]\n          ],\n      constantValue = 0): Tensor4D {\n    util.assert(\n        paddings.length === 4 && paddings[0].length === 2 &&\n            paddings[1].length === 2 && paddings[2].length === 2 &&\n            paddings[3].length === 2,\n        'Invalid number of paddings. Must be length of 2 each.');\n    return ArrayOps.pad(x, paddings, constantValue);\n  }\n\n  /**\n   * Pads a `Tensor` with a given value and paddings.\n   *\n   * This operation currently only implements the `CONSTANT` mode.\n   *\n   * ```js\n   * const x = tf.tensor1d([1, 2, 3, 4]);\n   * x.pad([[1, 2]]).print();\n   * ```\n   * @param x The tensor to pad.\n   * @param paddings An array of length `R` (the rank of the tensor), where each\n   *     element is a length-2 tuple of ints `[padBefore, padAfter]`, specifying\n   *     how much to pad along each dimension of the tensor.\n   * @param constantValue The pad value to use. Defaults to 0.\n   */\n  @doc({heading: 'Tensors', subheading: 'Transformations'})\n  @operation\n  static pad<T extends Tensor>(\n      x: T, paddings: Array<[number, number]>, constantValue = 0): T {\n    util.assertArgumentsAreTensors({x}, 'pad');\n\n    if (x.rank === 0) {\n      throw new Error('pad(scalar) is not defined. Pass non-scalar to pad');\n    }\n    // Pad introduces values around the original tensor, so the gradient slices\n    // the original shape out of the gradient.\n    const begin = paddings.map(p => p[0]);\n    const grad = (dy: T) => {\n      return {x: () => dy.slice(begin, x.shape)};\n    };\n    return ENV.engine.runKernel(\n               backend => backend.pad(x, paddings, constantValue), {x}, grad) as\n        T;\n  }\n\n  /**\n   * Stacks a list of rank-`R` `Tensor`s into one rank-`(R+1)` `Tensor`.\n   *\n   * ```js\n   * const a = tf.tensor1d([1, 2]);\n   * const b = tf.tensor1d([3, 4]);\n   * const c = tf.tensor1d([5, 6]);\n   * tf.stack([a, b, c]).print();\n   * ```\n   *\n   * @param tensors A list of tensor objects with the same shape and dtype.\n   * @param axis The axis to stack along. Defaults to 0 (the first dim).\n   */\n  @doc({heading: 'Tensors', subheading: 'Slicing and Joining'})\n  @operation\n  static stack<T extends Tensor>(tensors: T[], axis = 0): Tensor {\n    util.assertArgumentsAreTensors({tensors}, 'stack');\n\n    util.assert(tensors.length >= 1, 'Pass at least one tensor to tf.stack');\n    if (tensors.length === 1) {\n      return tensors[0].expandDims(axis);\n    }\n    const rank = tensors[0].rank;\n    const shape = tensors[0].shape;\n    const dtype = tensors[0].dtype;\n\n    util.assert(axis <= rank, 'Axis must be <= rank of the tensor');\n\n    tensors.forEach(t => {\n      util.assertShapesMatch(\n          shape, t.shape,\n          'All tensors passed to stack must have matching shapes');\n    });\n\n    tensors.forEach(t => {\n      util.assert(\n          dtype === t.dtype,\n          'All tensors passed to stack must have matching dtypes');\n    });\n    const expandedTensors = tensors.map(t => t.expandDims(axis));\n    return ConcatOps.concat(expandedTensors, axis);\n  }\n\n  /**\n   * Splits a `Tensor` into sub tensors.\n   *\n   * If `numOrSizeSplits` is a number, splits `x` along dimension `axis`\n   * into `numOrSizeSplits` smaller tensors.\n   * Requires that `numOrSizeSplits` evenly divides `x.shape[axis]`.\n   *\n   * If `numOrSizeSplits` is a number array, splits `x` into\n   * `(numOrSizeSplits.length` pieces. The shape of the `i`-th piece has the\n   * same size as `x` except along dimension `axis` where the size is\n   * `numOrSizeSplits[i]`.\n   *\n   * ```js\n   * const x = tf.tensor2d([1, 2, 3, 4, 5, 6, 7, 8], [2, 4]);\n   * const [a, b] = tf.split(x, 2, 1);\n   * a.print();\n   * b.print();\n   *\n   * const [c, d, e] = tf.split(x, [1, 2, 1], 1);\n   * c.print();\n   * d.print();\n   * e.print();\n   * ```\n   *\n   * @param x The input tensor to split.\n   * @param numOrSizeSplits Either an integer indicating the number of\n   * splits along the axis or an array of integers containing the sizes of each\n   * output tensor along the axis. If a number then it must evenly divide\n   * `x.shape[axis]`; otherwise the sum of sizes must match `x.shape[axis]`.\n   * @param axis The dimension along which to split. Defaults to 0 (the first\n   * dim).\n   */\n  @doc({heading: 'Tensors', subheading: 'Slicing and Joining'})\n  @operation\n  static split<T extends Tensor>(\n      x: T, numOrSizeSplits: number[]|number, axis = 0): T[] {\n    util.assertArgumentsAreTensors({x}, 'split');\n\n    axis = parseAxisParam(axis, x.shape)[0];\n    let splitSizes: number[];\n    if (typeof (numOrSizeSplits) === 'number') {\n      util.assert(\n          x.shape[axis] % numOrSizeSplits === 0,\n          'Number of splits must evenly divide the axis.');\n      splitSizes = Array(numOrSizeSplits).fill(x.shape[axis] / numOrSizeSplits);\n    } else {\n      util.assert(\n          x.shape[axis] === numOrSizeSplits.reduce((a, b) => a + b),\n          'The sum of sizes must match the size of the axis dimension.');\n      splitSizes = numOrSizeSplits;\n    }\n    const begin = Array(x.rank).fill(0);\n    const size = x.shape.slice();\n    return splitSizes.map(s => {\n      size[axis] = s;\n      const slice = x.slice(begin, size);\n      begin[axis] += s;\n      return slice;\n    });\n  }\n\n  /**\n   * Returns a `Tensor` that has expanded rank, by inserting a dimension\n   * into the tensor's shape.\n   *\n   * ```js\n   * const x = tf.tensor1d([1, 2, 3, 4]);\n   * const axis = 1;\n   * x.expandDims(axis).print();\n   * ```\n   *\n   * @param x The input tensor whose dimensions to be expanded.\n   * @param axis The dimension index at which to insert shape of `1`. Defaults\n   *     to 0 (the first dimension).\n   */\n  @doc({heading: 'Tensors', subheading: 'Transformations'})\n  @operation\n  static expandDims<R2 extends Rank>(x: Tensor, axis = 0): Tensor<R2> {\n    util.assertArgumentsAreTensors({x}, 'expandDims');\n\n    util.assert(axis <= x.rank, 'Axis must be <= rank of the tensor');\n    const newShape = x.shape.slice();\n    newShape.splice(axis, 0, 1);\n    return ArrayOps.reshape(x, newShape);\n  }\n\n  /**\n   * Return an evenly spaced sequence of numbers over the given interval.\n   *\n   * ```js\n   * tf.linspace(0, 9, 10).print();\n   * ```\n   * @param start The start value of the sequence.\n   * @param stop The end value of the sequence.\n   * @param num The number of values to generate.\n   * @param endpoint Determines whether stop is included in the\n   * sequence. Defaults to true.\n   */\n  @operation\n  @doc({heading: 'Tensors', subheading: 'Creation'})\n  static linspace(start: number, stop: number, num: number): Tensor1D {\n    if (num === 0) {\n      throw new Error('Cannot request zero samples');\n    }\n\n    const step = (stop - start) / (num - 1);\n\n    const values = makeZerosTypedArray(num, 'float32');\n    values[0] = start;\n    for (let i = 1; i < values.length; i++) {\n      values[i] = values[i - 1] + step;\n    }\n\n    return ArrayOps.tensor1d(values, 'float32');\n  }\n\n  /**\n   * Creates a new `Tensor1D` filled with the numbers in the range provided.\n   *\n   * The tensor is a is half-open interval meaning it includes start, but\n   * excludes stop. Decrementing ranges and negative step values are also\n   * supported.\n   *\n   * ```js\n   * tf.range(0, 9, 2).print();\n   * ```\n   *\n   * @param start An integer start value\n   * @param stop An integer stop value\n   * @param step An integer increment (will default to 1 or -1)\n   * @param dtype The data type of the output tensor. Defaults to 'float32'.\n   */\n  @operation\n  @doc({heading: 'Tensors', subheading: 'Creation'})\n  static range(\n      start: number, stop: number, step = 1,\n      dtype: 'float32'|'int32' = 'float32'): Tensor1D {\n    if (step === 0) {\n      throw new Error('Cannot have a step of zero');\n    }\n\n    const sameStartStop = start === stop;\n    const increasingRangeNegativeStep = start < stop && step < 0;\n    const decreasingRangePositiveStep = stop < start && step > 1;\n\n    if (sameStartStop || increasingRangeNegativeStep ||\n        decreasingRangePositiveStep) {\n      return ArrayOps.zeros([0], dtype);\n    }\n\n    const numElements = Math.abs(Math.ceil((stop - start) / step));\n    const values = makeZerosTypedArray(numElements, dtype);\n\n    if (stop < start && step === 1) {\n      // Auto adjust the step's sign if it hasn't been set\n      // (or was set to 1)\n      step = -1;\n    }\n\n    values[0] = start;\n    for (let i = 1; i < values.length; i++) {\n      values[i] = values[i - 1] + step;\n    }\n\n    return ArrayOps.tensor1d(values, dtype);\n  }\n\n  /**\n   * Creates an empty `TensorBuffer` with the specified `shape` and `dtype`.\n   *\n   * The values are stored in cpu as `TypedArray`. Fill the buffer using\n   * `buffer.set()`, or by modifying directly `buffer.values`. When done,\n   * call `buffer.toTensor()` to get an immutable `Tensor` with those values.\n   *\n   * When done, call `buffer.toTensor()` to get an immutable `Tensor` with\n   * those values.\n   *\n   * ```js\n   * // Create a buffer and set values at particular indices.\n   * const buffer = tf.buffer([2, 2]);\n   * buffer.set(3, 0, 0);\n   * buffer.set(5, 1, 0);\n   *\n   * // Convert the buffer back to a tensor.\n   * buffer.toTensor().print();\n   * ```\n   *\n   * @param shape An array of integers defining the output tensor shape.\n   * @param dtype The dtype of the buffer. Defaults to 'float32'.\n   * @param values The values of the buffer as `TypedArray`. Defaults to\n   * zeros.\n   */\n  @doc({heading: 'Tensors', subheading: 'Creation'})\n  static buffer<R extends Rank>(\n      shape: ShapeMap[R], dtype: DataType = 'float32', values?: TypedArray):\n      TensorBuffer<R> {\n    return new TensorBuffer<R>(shape, dtype, values);\n  }\n\n  /**\n   * Prints information about the `Tensor` including its data.\n   *\n   * ```js\n   * const verbose = true;\n   * tf.tensor2d([1, 2, 3, 4], [2, 2]).print(verbose);\n   * ```\n   * @param x The tensor to be printed.\n   * @param verbose Whether to print verbose information about the ` Tensor`,\n   * including dtype and size.\n   */\n  @doc({heading: 'Tensors', subheading: 'Creation'})\n  static print<T extends Tensor>(x: T, verbose = false): void {\n    console.log(tensor_util.tensorToString(x, verbose));\n  }\n}\n\nfunction makeZerosTypedArray<D extends DataType>(\n    size: number, dtype: D): DataTypeMap[D] {\n  if (dtype == null || dtype === 'float32') {\n    return new Float32Array(size);\n  } else if (dtype === 'int32') {\n    return new Int32Array(size);\n  } else if (dtype === 'bool') {\n    return new Uint8Array(size);\n  } else {\n    throw new Error(`Unknown data type $ {dtype}`);\n  }\n}\n\nfunction makeOnesTypedArray<D extends DataType>(\n    size: number, dtype: D): DataTypeMap[D] {\n  const array = makeZerosTypedArray(size, dtype);\n  for (let i = 0; i < array.length; i++) {\n    array[i] = 1;\n  }\n  return array;\n}\n\nfunction toTypedArray<D extends DataType>(\n    a: ArrayData<D>, dtype: D): DataTypeMap[D] {\n  if (noConversionNeeded(a, dtype)) {\n    return a as DataTypeMap[D];\n  }\n  if (Array.isArray(a)) {\n    a = util.flatten(a as number[]);\n  }\n  return util.copyTypedArray(a, dtype);\n}\n\nfunction noConversionNeeded<D extends DataType>(\n    a: ArrayData<D>, dtype: D): boolean {\n  return (a instanceof Float32Array && dtype === 'float32') ||\n      (a instanceof Int32Array && dtype === 'int32') ||\n      (a instanceof Uint8Array && dtype === 'bool');\n}\n"]}},"hash":"894cca4d02c50a5ba00f455f996ce689","cacheData":{"env":{}}}